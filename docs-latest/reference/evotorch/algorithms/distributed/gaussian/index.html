
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="EvoTorch is an open source evolutionary computation library developed at NNAISENSE, built on top of PyTorch.">
      
      
      
      
        <link rel="prev" href="../">
      
      
        <link rel="next" href="../../restarter/">
      
      <link rel="icon" href="../../../../../assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-9.0.13">
    
    
      
        <title>Gaussian - EvoTorch</title>
      
    
    
      <link rel="stylesheet" href="../../../../../assets/stylesheets/main.ffa9267a.min.css">
      
        
        <link rel="stylesheet" href="../../../../../assets/stylesheets/palette.a0c5b2b5.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../../../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="orange" data-md-color-accent="orange">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#evotorch.algorithms.distributed.gaussian" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
          <aside class="md-banner md-banner--warning">
            <div class="md-banner__inner md-grid md-typeset">
              
  You're not viewing the latest version.
  <a href="../../../../../..">
    <strong>Click here to go to latest.</strong>
  </a>

            </div>
            <script>var el=document.querySelector("[data-md-component=outdated]"),outdated=__md_get("__outdated",sessionStorage);!0===outdated&&el&&(el.hidden=!1)</script>
          </aside>
        
      </div>
    
    
      

  

<header class="md-header md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="https://evotorch.ai" title="EvoTorch" class="md-header__button md-logo" aria-label="EvoTorch" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            EvoTorch
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Gaussian
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="orange" data-md-color-accent="orange"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"/></svg>
            </label>
          
        
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="deep-orange" data-md-color-accent="deep-orange"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
            </label>
          
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/nnaisense/evotorch" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    evotorch
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../../../../.." class="md-tabs__link">
      Home
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../../../../../quickstart/" class="md-tabs__link">
      Quickstart
    </a>
  </li>

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../user_guide/general_usage/" class="md-tabs__link">
        User Guide
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../advanced_usage/solution_batch/" class="md-tabs__link">
        Advanced Usage
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../examples/" class="md-tabs__link">
        Examples
      </a>
    </li>
  

      
        
  
  
    
  


  
  
  
    

  
  
  
    <li class="md-tabs__item">
      <a href="../../../" class="md-tabs__link md-tabs__link--active">
        API Reference
      </a>
    </li>
  

  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="https://evotorch.ai" title="EvoTorch" class="md-nav__button md-logo" aria-label="EvoTorch" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    EvoTorch
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/nnaisense/evotorch" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    evotorch
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../../../quickstart/" class="md-nav__link">
        Quickstart
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
          User Guide
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          User Guide
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../user_guide/general_usage/" class="md-nav__link">
        General Usage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../user_guide/algorithm_usage/" class="md-nav__link">
        Algorithm Usage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../user_guide/algorithms_tour/" class="md-nav__link">
        Algorithms Tour
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../user_guide/problems/" class="md-nav__link">
        Defining Problems
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../user_guide/problem_parallelization/" class="md-nav__link">
        Problem Parallelization
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../user_guide/logging/" class="md-nav__link">
        Logging
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../user_guide/neuroevolution/" class="md-nav__link">
        Neuroevolution
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../user_guide/gym/" class="md-nav__link">
        Neuroevolution for Gym
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../user_guide/supervised_ne/" class="md-nav__link">
        Supervised Neuroevolution
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
          Advanced Usage
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Advanced Usage
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../advanced_usage/solution_batch/" class="md-nav__link">
        Manipulating Solutions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../advanced_usage/hooks/" class="md-nav__link">
        Using Hooks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../advanced_usage/dist_based/" class="md-nav__link">
        Distributed Evolution Strategies
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../advanced_usage/custom_ea/" class="md-nav__link">
        Custom Searchers
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../advanced_usage/custom_logger/" class="md-nav__link">
        Custom Loggers
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../advanced_usage/ray_cluster/" class="md-nav__link">
        Using Ray Clusters
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
      
      
        
          
            
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../../../examples/">Examples</a>
          
            <label for="__nav_5">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Examples
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2" >
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
          Notebooks
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2">
          <span class="md-nav__icon md-icon"></span>
          Notebooks
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../examples/notebooks/Brax_Experiments_with_PGPE/" class="md-nav__link">
        Solving a Brax environment using EvoTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../examples/notebooks/Feature_Space_Illumination_with_MAPElites/" class="md-nav__link">
        Feature Space Illumination with MAPElites
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../examples/notebooks/Genetic_Programming/" class="md-nav__link">
        Genetic Programming using EvoTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../examples/notebooks/Gym_Experiments_with_PGPE_and_CoSyNE/" class="md-nav__link">
        Gym Experiments with PGPE and CoSyNE
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../examples/notebooks/Minimizing_Lennard-Jones_Atom_Cluster_Potentials/" class="md-nav__link">
        Minimising Lennard-Jones Atom Cluster Potentials with Evolution
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../examples/notebooks/Training_MNIST30K/" class="md-nav__link">
        Training MNIST30K
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../examples/notebooks/Variational_Quantum_Eigensolvers_with_SNES/" class="md-nav__link">
        Variational Quantum Eigensolvers with SNES
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../examples/notebooks/reacher_mpc/" class="md-nav__link">
        Model Predictive Control (MPC) with EvoTorch
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" checked>
      
      
        
          
        
      
      
        <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
          API Reference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          API Reference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_1" checked>
      
      
        
          
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../">Evotorch</a>
          
            <label for="__nav_6_1">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_1_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_6_1">
          <span class="md-nav__icon md-icon"></span>
          Evotorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../core/" class="md-nav__link">
        Core
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../decorators/" class="md-nav__link">
        Decorators
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../distributions/" class="md-nav__link">
        Distributions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../logging/" class="md-nav__link">
        Logging
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../optimizers/" class="md-nav__link">
        Optimizers
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../testing/" class="md-nav__link">
        Testing
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_1_8" checked>
      
      
        
          
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../">Algorithms</a>
          
            <label for="__nav_6_1_8">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_1_8_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_6_1_8">
          <span class="md-nav__icon md-icon"></span>
          Algorithms
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../cmaes/" class="md-nav__link">
        Cmaes
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../ga/" class="md-nav__link">
        Ga
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mapelites/" class="md-nav__link">
        Mapelites
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pycmaes/" class="md-nav__link">
        Pycmaes
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../searchalgorithm/" class="md-nav__link">
        Searchalgorithm
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_1_8_7" checked>
      
      
        
          
            
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../">Distributed</a>
          
            <label for="__nav_6_1_8_7">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_6_1_8_7_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_6_1_8_7">
          <span class="md-nav__icon md-icon"></span>
          Distributed
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Gaussian
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Gaussian
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian" class="md-nav__link">
    evotorch.algorithms.distributed.gaussian
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.CEM" class="md-nav__link">
    CEM
  </a>
  
    <nav class="md-nav" aria-label="CEM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.CEM.DISTRIBUTION_TYPE" class="md-nav__link">
    DISTRIBUTION_TYPE
  </a>
  
    <nav class="md-nav" aria-label="DISTRIBUTION_TYPE">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.CEM.DISTRIBUTION_TYPE.update_parameters" class="md-nav__link">
    update_parameters()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.CEM.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.GaussianSearchAlgorithm" class="md-nav__link">
    GaussianSearchAlgorithm
  </a>
  
    <nav class="md-nav" aria-label="GaussianSearchAlgorithm">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.GaussianSearchAlgorithm.obj_index" class="md-nav__link">
    obj_index
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.GaussianSearchAlgorithm.population" class="md-nav__link">
    population
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.PGPE" class="md-nav__link">
    PGPE
  </a>
  
    <nav class="md-nav" aria-label="PGPE">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.PGPE.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.SNES" class="md-nav__link">
    SNES
  </a>
  
    <nav class="md-nav" aria-label="SNES">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.SNES.DISTRIBUTION_TYPE" class="md-nav__link">
    DISTRIBUTION_TYPE
  </a>
  
    <nav class="md-nav" aria-label="DISTRIBUTION_TYPE">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.SNES.DISTRIBUTION_TYPE.update_parameters" class="md-nav__link">
    update_parameters()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.SNES.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.XNES" class="md-nav__link">
    XNES
  </a>
  
    <nav class="md-nav" aria-label="XNES">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE" class="md-nav__link">
    DISTRIBUTION_TYPE
  </a>
  
    <nav class="md-nav" aria-label="DISTRIBUTION_TYPE">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.A" class="md-nav__link">
    A
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.A_inv" class="md-nav__link">
    A_inv
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.cov" class="md-nav__link">
    cov
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.mu" class="md-nav__link">
    mu
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.sigma" class="md-nav__link">
    sigma
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.sigma_inv" class="md-nav__link">
    sigma_inv
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.to_global_coordinates" class="md-nav__link">
    to_global_coordinates()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.to_local_coordinates" class="md-nav__link">
    to_local_coordinates()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.update_parameters" class="md-nav__link">
    update_parameters()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.XNES.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_1_8_8" >
      
      
        
          
            
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../restarter/">Restarter</a>
          
            <label for="__nav_6_1_8_8">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_6_1_8_8_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6_1_8_8">
          <span class="md-nav__icon md-icon"></span>
          Restarter
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../restarter/modify_restart/" class="md-nav__link">
        Modify restart
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../restarter/restart/" class="md-nav__link">
        Restart
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_1_9" >
      
      
        
          
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../neuroevolution/">Neuroevolution</a>
          
            <label for="__nav_6_1_9">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_1_9_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6_1_9">
          <span class="md-nav__icon md-icon"></span>
          Neuroevolution
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../neuroevolution/baseneproblem/" class="md-nav__link">
        Baseneproblem
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../neuroevolution/gymne/" class="md-nav__link">
        Gymne
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../neuroevolution/neproblem/" class="md-nav__link">
        Neproblem
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../neuroevolution/supervisedne/" class="md-nav__link">
        Supervisedne
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../neuroevolution/vecgymne/" class="md-nav__link">
        Vecgymne
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_1_9_7" >
      
      
        
          
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../neuroevolution/net/">Net</a>
          
            <label for="__nav_6_1_9_7">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_6_1_9_7_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6_1_9_7">
          <span class="md-nav__icon md-icon"></span>
          Net
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../neuroevolution/net/functional/" class="md-nav__link">
        Functional
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../neuroevolution/net/layers/" class="md-nav__link">
        Layers
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../neuroevolution/net/misc/" class="md-nav__link">
        Misc
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../neuroevolution/net/multilayered/" class="md-nav__link">
        Multilayered
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../neuroevolution/net/parser/" class="md-nav__link">
        Parser
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../neuroevolution/net/rl/" class="md-nav__link">
        Rl
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../neuroevolution/net/runningnorm/" class="md-nav__link">
        Runningnorm
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../neuroevolution/net/runningstat/" class="md-nav__link">
        Runningstat
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../neuroevolution/net/statefulmodule/" class="md-nav__link">
        Statefulmodule
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../neuroevolution/net/vecrl/" class="md-nav__link">
        Vecrl
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_1_10" >
      
      
        
          
            
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../operators/">Operators</a>
          
            <label for="__nav_6_1_10">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_1_10_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6_1_10">
          <span class="md-nav__icon md-icon"></span>
          Operators
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../operators/base/" class="md-nav__link">
        Base
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../operators/real/" class="md-nav__link">
        Real
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../operators/sequence/" class="md-nav__link">
        Sequence
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_1_11" >
      
      
        
          
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../tools/">Tools</a>
          
            <label for="__nav_6_1_11">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_1_11_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6_1_11">
          <span class="md-nav__icon md-icon"></span>
          Tools
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../tools/cloning/" class="md-nav__link">
        Cloning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../tools/hook/" class="md-nav__link">
        Hook
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../tools/immutable/" class="md-nav__link">
        Immutable
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../tools/misc/" class="md-nav__link">
        Misc
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../tools/objectarray/" class="md-nav__link">
        Objectarray
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../tools/ranking/" class="md-nav__link">
        Ranking
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../tools/readonlytensor/" class="md-nav__link">
        Readonlytensor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../tools/recursiveprintable/" class="md-nav__link">
        Recursiveprintable
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../tools/structures/" class="md-nav__link">
        Structures
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../tools/tensormaker/" class="md-nav__link">
        Tensormaker
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian" class="md-nav__link">
    evotorch.algorithms.distributed.gaussian
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.CEM" class="md-nav__link">
    CEM
  </a>
  
    <nav class="md-nav" aria-label="CEM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.CEM.DISTRIBUTION_TYPE" class="md-nav__link">
    DISTRIBUTION_TYPE
  </a>
  
    <nav class="md-nav" aria-label="DISTRIBUTION_TYPE">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.CEM.DISTRIBUTION_TYPE.update_parameters" class="md-nav__link">
    update_parameters()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.CEM.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.GaussianSearchAlgorithm" class="md-nav__link">
    GaussianSearchAlgorithm
  </a>
  
    <nav class="md-nav" aria-label="GaussianSearchAlgorithm">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.GaussianSearchAlgorithm.obj_index" class="md-nav__link">
    obj_index
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.GaussianSearchAlgorithm.population" class="md-nav__link">
    population
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.PGPE" class="md-nav__link">
    PGPE
  </a>
  
    <nav class="md-nav" aria-label="PGPE">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.PGPE.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.SNES" class="md-nav__link">
    SNES
  </a>
  
    <nav class="md-nav" aria-label="SNES">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.SNES.DISTRIBUTION_TYPE" class="md-nav__link">
    DISTRIBUTION_TYPE
  </a>
  
    <nav class="md-nav" aria-label="DISTRIBUTION_TYPE">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.SNES.DISTRIBUTION_TYPE.update_parameters" class="md-nav__link">
    update_parameters()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.SNES.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.XNES" class="md-nav__link">
    XNES
  </a>
  
    <nav class="md-nav" aria-label="XNES">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE" class="md-nav__link">
    DISTRIBUTION_TYPE
  </a>
  
    <nav class="md-nav" aria-label="DISTRIBUTION_TYPE">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.A" class="md-nav__link">
    A
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.A_inv" class="md-nav__link">
    A_inv
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.cov" class="md-nav__link">
    cov
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.mu" class="md-nav__link">
    mu
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.sigma" class="md-nav__link">
    sigma
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.sigma_inv" class="md-nav__link">
    sigma_inv
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.to_global_coordinates" class="md-nav__link">
    to_global_coordinates()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.to_local_coordinates" class="md-nav__link">
    to_local_coordinates()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.update_parameters" class="md-nav__link">
    update_parameters()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.algorithms.distributed.gaussian.XNES.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>Gaussian</h1>

<div class="doc doc-object doc-module">

<a id="evotorch.algorithms.distributed.gaussian"></a>
    <div class="doc doc-contents first">




  <div class="doc doc-children">







  <div class="doc doc-object doc-class">



<h2 id="evotorch.algorithms.distributed.gaussian.CEM" class="doc doc-heading">
        <code>
CEM            (<a class="autorefs autorefs-internal" title="evotorch.algorithms.distributed.gaussian.GaussianSearchAlgorithm" href="#evotorch.algorithms.distributed.gaussian.GaussianSearchAlgorithm">GaussianSearchAlgorithm</a>)
        </code>



<a href="#evotorch.algorithms.distributed.gaussian.CEM" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents ">

      <p>The cross-entropy method (CEM) (Rubinstein, 1999).</p>
<p>This CEM implementation is focused on continuous optimization,
and follows the variant explained in Duan et al. (2016).</p>
<p>The adaptive population size mechanism explained in Toklu et al. (2020)
(and previously used in the accompanying source code of the study
Salimans et al. (2017)) is supported, where the population size in an
iteration keeps increasing until a certain numberof interactions with
the simulator of the reinforcement learning environment is made.
See the initialization arguments <code>num_interactions</code>, <code>popsize_max</code>.</p>
<p>References:</p>
<div class="highlight"><pre><span></span><code>Rubinstein, R. (1999). The cross-entropy method for combinatorial
and continuous optimization.
Methodology and computing in applied probability, 1(2), 127-190.

Duan, Y., Chen, X., Houthooft, R., Schulman, J., Abbeel, P. (2016).
Benchmarking deep reinforcement learning for continuous control.
International conference on machine learning. PMLR, 2016.

Salimans, T., Ho, J., Chen, X., Sidor, S. and Sutskever, I. (2017).
Evolution Strategies as a Scalable Alternative to
Reinforcement Learning.

Toklu, N.E., Liskowski, P., Srivastava, R.K. (2020).
ClipUp: A Simple and Powerful Optimizer
for Distribution-based Policy Evolution.
Parallel Problem Solving from Nature (PPSN 2020).
</code></pre></div>

        <details class="quote">
          <summary>Source code in <code>evotorch/algorithms/distributed/gaussian.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">class</span> <span class="nc">CEM</span><span class="p">(</span><span class="n">GaussianSearchAlgorithm</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="sd">    The cross-entropy method (CEM) (Rubinstein, 1999).</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">    This CEM implementation is focused on continuous optimization,</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">    and follows the variant explained in Duan et al. (2016).</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="sd">    The adaptive population size mechanism explained in Toklu et al. (2020)</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">    (and previously used in the accompanying source code of the study</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">    Salimans et al. (2017)) is supported, where the population size in an</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="sd">    iteration keeps increasing until a certain numberof interactions with</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="sd">    the simulator of the reinforcement learning environment is made.</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a><span class="sd">    See the initialization arguments `num_interactions`, `popsize_max`.</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a><span class="sd">    References:</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a><span class="sd">        Rubinstein, R. (1999). The cross-entropy method for combinatorial</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a><span class="sd">        and continuous optimization.</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a><span class="sd">        Methodology and computing in applied probability, 1(2), 127-190.</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a><span class="sd">        Duan, Y., Chen, X., Houthooft, R., Schulman, J., Abbeel, P. (2016).</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a><span class="sd">        Benchmarking deep reinforcement learning for continuous control.</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a><span class="sd">        International conference on machine learning. PMLR, 2016.</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a><span class="sd">        Salimans, T., Ho, J., Chen, X., Sidor, S. and Sutskever, I. (2017).</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a><span class="sd">        Evolution Strategies as a Scalable Alternative to</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a><span class="sd">        Reinforcement Learning.</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a><span class="sd">        Toklu, N.E., Liskowski, P., Srivastava, R.K. (2020).</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a><span class="sd">        ClipUp: A Simple and Powerful Optimizer</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a><span class="sd">        for Distribution-based Policy Evolution.</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a><span class="sd">        Parallel Problem Solving from Nature (PPSN 2020).</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>    <span class="n">DISTRIBUTION_TYPE</span> <span class="o">=</span> <span class="n">SeparableGaussian</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a>    <span class="n">DISTRIBUTION_PARAMS</span> <span class="o">=</span> <span class="bp">NotImplemented</span>  <span class="c1"># To be filled by the CEM instance</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>        <span class="n">problem</span><span class="p">:</span> <span class="n">Problem</span><span class="p">,</span>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>        <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a>        <span class="n">popsize</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a>        <span class="n">parenthood_ratio</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a>        <span class="n">stdev_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a>        <span class="n">radius_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a>        <span class="n">num_interactions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a>        <span class="n">popsize_max</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a>        <span class="n">center_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a>        <span class="n">stdev_min</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a>        <span class="n">stdev_max</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a>        <span class="n">stdev_max_change</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">RealOrVector</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a>        <span class="n">obj_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a>        <span class="n">distributed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a>        <span class="n">popsize_weighted_grad_avg</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a>    <span class="p">):</span>
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a><span class="sd">        `__init__(...)`: Initialize the search algorithm.</span>
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a>
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a><span class="sd">            problem: The problem object to work on.</span>
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a><span class="sd">            popsize: The population size.</span>
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#__codelineno-0-62"></a><span class="sd">            parenthood_ratio: Expected as a float larger than 0 and smaller</span>
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#__codelineno-0-63"></a><span class="sd">                than 1. For example, setting this value to 0.1 means that</span>
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#__codelineno-0-64"></a><span class="sd">                the top 10% of the population will be declared as the parents,</span>
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#__codelineno-0-65"></a><span class="sd">                and those parents will be used for updating the population.</span>
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#__codelineno-0-66"></a><span class="sd">                The amount of parents is always computed according to the</span>
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#__codelineno-0-67"></a><span class="sd">                specified `popsize`, not according to the adapted population</span>
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#__codelineno-0-68"></a><span class="sd">                size, and not according to `popsize_max`.</span>
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#__codelineno-0-69"></a><span class="sd">            stdev_init: The initial standard deviation of the search</span>
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#__codelineno-0-70"></a><span class="sd">                distribution, expressed as a scalar or as an array.</span>
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#__codelineno-0-71"></a><span class="sd">                Determines the initial coverage area of the search</span>
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#__codelineno-0-72"></a><span class="sd">                distribution.</span>
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#__codelineno-0-73"></a><span class="sd">                If one wishes to configure the coverage area via the</span>
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#__codelineno-0-74"></a><span class="sd">                argument `radius_init` instead, then `stdev_init` is expected</span>
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#__codelineno-0-75"></a><span class="sd">                as None.</span>
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#__codelineno-0-76"></a><span class="sd">            radius_init: The initial radius of the search distribution,</span>
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#__codelineno-0-77"></a><span class="sd">                expressed as a scalar.</span>
<a id="__codelineno-0-78" name="__codelineno-0-78" href="#__codelineno-0-78"></a><span class="sd">                Determines the initial coverage area of the search</span>
<a id="__codelineno-0-79" name="__codelineno-0-79" href="#__codelineno-0-79"></a><span class="sd">                distribution.</span>
<a id="__codelineno-0-80" name="__codelineno-0-80" href="#__codelineno-0-80"></a><span class="sd">                Here, &quot;radius&quot; is defined as the norm of the search</span>
<a id="__codelineno-0-81" name="__codelineno-0-81" href="#__codelineno-0-81"></a><span class="sd">                distribution.</span>
<a id="__codelineno-0-82" name="__codelineno-0-82" href="#__codelineno-0-82"></a><span class="sd">                If one wishes to configure the coverage area via the</span>
<a id="__codelineno-0-83" name="__codelineno-0-83" href="#__codelineno-0-83"></a><span class="sd">                argument `stdev_init` instead, then `radius_init` is expected</span>
<a id="__codelineno-0-84" name="__codelineno-0-84" href="#__codelineno-0-84"></a><span class="sd">                as None.</span>
<a id="__codelineno-0-85" name="__codelineno-0-85" href="#__codelineno-0-85"></a><span class="sd">            num_interactions: When given as an integer n,</span>
<a id="__codelineno-0-86" name="__codelineno-0-86" href="#__codelineno-0-86"></a><span class="sd">                it is ensured that a population has interacted with</span>
<a id="__codelineno-0-87" name="__codelineno-0-87" href="#__codelineno-0-87"></a><span class="sd">                the GymProblem&#39;s environment n times. If this target</span>
<a id="__codelineno-0-88" name="__codelineno-0-88" href="#__codelineno-0-88"></a><span class="sd">                has not been reached yet, then the population is declared</span>
<a id="__codelineno-0-89" name="__codelineno-0-89" href="#__codelineno-0-89"></a><span class="sd">                too small, and gets extended with more samples,</span>
<a id="__codelineno-0-90" name="__codelineno-0-90" href="#__codelineno-0-90"></a><span class="sd">                until n amount of interactions is reached.</span>
<a id="__codelineno-0-91" name="__codelineno-0-91" href="#__codelineno-0-91"></a><span class="sd">                When given as None, popsize is the only configuration</span>
<a id="__codelineno-0-92" name="__codelineno-0-92" href="#__codelineno-0-92"></a><span class="sd">                affecting the size of a population.</span>
<a id="__codelineno-0-93" name="__codelineno-0-93" href="#__codelineno-0-93"></a><span class="sd">            popsize_max: Having `num_interactions` set as an integer</span>
<a id="__codelineno-0-94" name="__codelineno-0-94" href="#__codelineno-0-94"></a><span class="sd">                might cause the effective population size jump to</span>
<a id="__codelineno-0-95" name="__codelineno-0-95" href="#__codelineno-0-95"></a><span class="sd">                unnecesarily large numbers. To prevent this,</span>
<a id="__codelineno-0-96" name="__codelineno-0-96" href="#__codelineno-0-96"></a><span class="sd">                one can set `popsize_max` to specify an upper</span>
<a id="__codelineno-0-97" name="__codelineno-0-97" href="#__codelineno-0-97"></a><span class="sd">                bound for the effective population size.</span>
<a id="__codelineno-0-98" name="__codelineno-0-98" href="#__codelineno-0-98"></a><span class="sd">            center_init: The initial center solution.</span>
<a id="__codelineno-0-99" name="__codelineno-0-99" href="#__codelineno-0-99"></a><span class="sd">                Can be left as None.</span>
<a id="__codelineno-0-100" name="__codelineno-0-100" href="#__codelineno-0-100"></a><span class="sd">            stdev_min: The minimum value for the standard deviation</span>
<a id="__codelineno-0-101" name="__codelineno-0-101" href="#__codelineno-0-101"></a><span class="sd">                values of the Gaussian search distribution.</span>
<a id="__codelineno-0-102" name="__codelineno-0-102" href="#__codelineno-0-102"></a><span class="sd">                Can be left as None (which is the default),</span>
<a id="__codelineno-0-103" name="__codelineno-0-103" href="#__codelineno-0-103"></a><span class="sd">                or can be given as a scalar or as a 1-dimensional array.</span>
<a id="__codelineno-0-104" name="__codelineno-0-104" href="#__codelineno-0-104"></a><span class="sd">            stdev_max: The maximum value for the standard deviation</span>
<a id="__codelineno-0-105" name="__codelineno-0-105" href="#__codelineno-0-105"></a><span class="sd">                values of the Gaussian search distribution.</span>
<a id="__codelineno-0-106" name="__codelineno-0-106" href="#__codelineno-0-106"></a><span class="sd">                Can be left as None (which is the default),</span>
<a id="__codelineno-0-107" name="__codelineno-0-107" href="#__codelineno-0-107"></a><span class="sd">                or can be given as a scalar or as a 1-dimensional array.</span>
<a id="__codelineno-0-108" name="__codelineno-0-108" href="#__codelineno-0-108"></a><span class="sd">            stdev_max_change: The maximum update ratio allowed on the</span>
<a id="__codelineno-0-109" name="__codelineno-0-109" href="#__codelineno-0-109"></a><span class="sd">                standard deviation. Expected as None if no such limiter</span>
<a id="__codelineno-0-110" name="__codelineno-0-110" href="#__codelineno-0-110"></a><span class="sd">                is needed, or as a real number within 0.0 and 1.0 otherwise.</span>
<a id="__codelineno-0-111" name="__codelineno-0-111" href="#__codelineno-0-111"></a><span class="sd">                In the PGPE implementation of Ha (2017, 2018), a value of</span>
<a id="__codelineno-0-112" name="__codelineno-0-112" href="#__codelineno-0-112"></a><span class="sd">                0.2 (20%) was used.</span>
<a id="__codelineno-0-113" name="__codelineno-0-113" href="#__codelineno-0-113"></a><span class="sd">                For this CEM implementation, the default is None.</span>
<a id="__codelineno-0-114" name="__codelineno-0-114" href="#__codelineno-0-114"></a><span class="sd">            obj_index: Index of the objective according to which the</span>
<a id="__codelineno-0-115" name="__codelineno-0-115" href="#__codelineno-0-115"></a><span class="sd">                gradient estimations will be done.</span>
<a id="__codelineno-0-116" name="__codelineno-0-116" href="#__codelineno-0-116"></a><span class="sd">                For single-objective problems, this can be left as None.</span>
<a id="__codelineno-0-117" name="__codelineno-0-117" href="#__codelineno-0-117"></a><span class="sd">            distributed: Whether or not the gradient computation will</span>
<a id="__codelineno-0-118" name="__codelineno-0-118" href="#__codelineno-0-118"></a><span class="sd">                be distributed. If `distributed` is given as False and</span>
<a id="__codelineno-0-119" name="__codelineno-0-119" href="#__codelineno-0-119"></a><span class="sd">                the problem is not parallelized, then everything will</span>
<a id="__codelineno-0-120" name="__codelineno-0-120" href="#__codelineno-0-120"></a><span class="sd">                be centralized (i.e. the entire computation will happen</span>
<a id="__codelineno-0-121" name="__codelineno-0-121" href="#__codelineno-0-121"></a><span class="sd">                in the main process).</span>
<a id="__codelineno-0-122" name="__codelineno-0-122" href="#__codelineno-0-122"></a><span class="sd">                If `distributed` is given as False, and the problem</span>
<a id="__codelineno-0-123" name="__codelineno-0-123" href="#__codelineno-0-123"></a><span class="sd">                is parallelized, then the population will be created</span>
<a id="__codelineno-0-124" name="__codelineno-0-124" href="#__codelineno-0-124"></a><span class="sd">                in the main process and then sent to remote workers</span>
<a id="__codelineno-0-125" name="__codelineno-0-125" href="#__codelineno-0-125"></a><span class="sd">                for parallelized evaluation, and then the remote fitnesses</span>
<a id="__codelineno-0-126" name="__codelineno-0-126" href="#__codelineno-0-126"></a><span class="sd">                will be collected by the main process again for computing</span>
<a id="__codelineno-0-127" name="__codelineno-0-127" href="#__codelineno-0-127"></a><span class="sd">                the search gradients.</span>
<a id="__codelineno-0-128" name="__codelineno-0-128" href="#__codelineno-0-128"></a><span class="sd">                If `distributed` is given as True, and the problem</span>
<a id="__codelineno-0-129" name="__codelineno-0-129" href="#__codelineno-0-129"></a><span class="sd">                is parallelized, then the search algorithm itself will</span>
<a id="__codelineno-0-130" name="__codelineno-0-130" href="#__codelineno-0-130"></a><span class="sd">                be distributed, in the sense that each remote actor will</span>
<a id="__codelineno-0-131" name="__codelineno-0-131" href="#__codelineno-0-131"></a><span class="sd">                generate its own population (such that the total population</span>
<a id="__codelineno-0-132" name="__codelineno-0-132" href="#__codelineno-0-132"></a><span class="sd">                size across all these actors becomes equal to `popsize`)</span>
<a id="__codelineno-0-133" name="__codelineno-0-133" href="#__codelineno-0-133"></a><span class="sd">                and will compute its own gradient, and then the main process</span>
<a id="__codelineno-0-134" name="__codelineno-0-134" href="#__codelineno-0-134"></a><span class="sd">                will collect these gradients, compute the averaged gradients</span>
<a id="__codelineno-0-135" name="__codelineno-0-135" href="#__codelineno-0-135"></a><span class="sd">                and update the main search distribution.</span>
<a id="__codelineno-0-136" name="__codelineno-0-136" href="#__codelineno-0-136"></a><span class="sd">                Non-distributed mode has the advantage of keeping the</span>
<a id="__codelineno-0-137" name="__codelineno-0-137" href="#__codelineno-0-137"></a><span class="sd">                population in the main process, which is good when one wishes</span>
<a id="__codelineno-0-138" name="__codelineno-0-138" href="#__codelineno-0-138"></a><span class="sd">                to do detailed monitoring during the evolutionary process,</span>
<a id="__codelineno-0-139" name="__codelineno-0-139" href="#__codelineno-0-139"></a><span class="sd">                but has the disadvantage of having to pass the solutions to</span>
<a id="__codelineno-0-140" name="__codelineno-0-140" href="#__codelineno-0-140"></a><span class="sd">                the remote actors and having to collect fitnesses, which</span>
<a id="__codelineno-0-141" name="__codelineno-0-141" href="#__codelineno-0-141"></a><span class="sd">                might result in increased interprocess communication traffic.</span>
<a id="__codelineno-0-142" name="__codelineno-0-142" href="#__codelineno-0-142"></a><span class="sd">                On the other hand, while it is not possible to monitor the</span>
<a id="__codelineno-0-143" name="__codelineno-0-143" href="#__codelineno-0-143"></a><span class="sd">                population in distributed mode, the distributed mode has the</span>
<a id="__codelineno-0-144" name="__codelineno-0-144" href="#__codelineno-0-144"></a><span class="sd">                advantage of significantly reducing the interprocess</span>
<a id="__codelineno-0-145" name="__codelineno-0-145" href="#__codelineno-0-145"></a><span class="sd">                communication traffic, since the only things communicated</span>
<a id="__codelineno-0-146" name="__codelineno-0-146" href="#__codelineno-0-146"></a><span class="sd">                with the remote actors are the search distributions (not the</span>
<a id="__codelineno-0-147" name="__codelineno-0-147" href="#__codelineno-0-147"></a><span class="sd">                solutions) and the gradients.</span>
<a id="__codelineno-0-148" name="__codelineno-0-148" href="#__codelineno-0-148"></a><span class="sd">            popsize_weighted_grad_avg: Only to be used in distributed mode.</span>
<a id="__codelineno-0-149" name="__codelineno-0-149" href="#__codelineno-0-149"></a><span class="sd">                (where being in distributed mode means `distributed` is given</span>
<a id="__codelineno-0-150" name="__codelineno-0-150" href="#__codelineno-0-150"></a><span class="sd">                as True). In distributed mode, each actor remotely samples</span>
<a id="__codelineno-0-151" name="__codelineno-0-151" href="#__codelineno-0-151"></a><span class="sd">                its own solution batches and computes its own gradients.</span>
<a id="__codelineno-0-152" name="__codelineno-0-152" href="#__codelineno-0-152"></a><span class="sd">                These gradients are then collected, and a final average</span>
<a id="__codelineno-0-153" name="__codelineno-0-153" href="#__codelineno-0-153"></a><span class="sd">                gradient is computed.</span>
<a id="__codelineno-0-154" name="__codelineno-0-154" href="#__codelineno-0-154"></a><span class="sd">                If `popsize_weighted_grad_avg` is True, then, while averaging</span>
<a id="__codelineno-0-155" name="__codelineno-0-155" href="#__codelineno-0-155"></a><span class="sd">                over the gradients, each gradient will have its own weight</span>
<a id="__codelineno-0-156" name="__codelineno-0-156" href="#__codelineno-0-156"></a><span class="sd">                that is computed according to how many solutions were sampled</span>
<a id="__codelineno-0-157" name="__codelineno-0-157" href="#__codelineno-0-157"></a><span class="sd">                by the actor that produced the gradient.</span>
<a id="__codelineno-0-158" name="__codelineno-0-158" href="#__codelineno-0-158"></a><span class="sd">                If `popsize_weighted_grad_avg` is False, then, there will not</span>
<a id="__codelineno-0-159" name="__codelineno-0-159" href="#__codelineno-0-159"></a><span class="sd">                be weighted averaging (or, each gradient will have equal</span>
<a id="__codelineno-0-160" name="__codelineno-0-160" href="#__codelineno-0-160"></a><span class="sd">                weight).</span>
<a id="__codelineno-0-161" name="__codelineno-0-161" href="#__codelineno-0-161"></a><span class="sd">                If `popsize_weighted_grad_avg` is None, then, the gradient</span>
<a id="__codelineno-0-162" name="__codelineno-0-162" href="#__codelineno-0-162"></a><span class="sd">                weights will be equal a value for `num_interactions` is given</span>
<a id="__codelineno-0-163" name="__codelineno-0-163" href="#__codelineno-0-163"></a><span class="sd">                (because `num_interactions` affects the number of solutions</span>
<a id="__codelineno-0-164" name="__codelineno-0-164" href="#__codelineno-0-164"></a><span class="sd">                according to the episode lengths, and popsize-weighting the</span>
<a id="__codelineno-0-165" name="__codelineno-0-165" href="#__codelineno-0-165"></a><span class="sd">                gradients could be misleading); and the gradient weights will</span>
<a id="__codelineno-0-166" name="__codelineno-0-166" href="#__codelineno-0-166"></a><span class="sd">                be weighted according to the sub-population (i.e. sub-batch)</span>
<a id="__codelineno-0-167" name="__codelineno-0-167" href="#__codelineno-0-167"></a><span class="sd">                sizes if `num_interactions` is left as None.</span>
<a id="__codelineno-0-168" name="__codelineno-0-168" href="#__codelineno-0-168"></a><span class="sd">                The default value for `popsize_weighted_grad_avg` is None.</span>
<a id="__codelineno-0-169" name="__codelineno-0-169" href="#__codelineno-0-169"></a><span class="sd">                When the distributed mode is disabled (i.e. when `distributed`</span>
<a id="__codelineno-0-170" name="__codelineno-0-170" href="#__codelineno-0-170"></a><span class="sd">                is False), then the argument `popsize_weighted_grad_avg` is</span>
<a id="__codelineno-0-171" name="__codelineno-0-171" href="#__codelineno-0-171"></a><span class="sd">                expected as None.</span>
<a id="__codelineno-0-172" name="__codelineno-0-172" href="#__codelineno-0-172"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-173" name="__codelineno-0-173" href="#__codelineno-0-173"></a>
<a id="__codelineno-0-174" name="__codelineno-0-174" href="#__codelineno-0-174"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">DISTRIBUTION_PARAMS</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;parenthood_ratio&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">parenthood_ratio</span><span class="p">)}</span>
<a id="__codelineno-0-175" name="__codelineno-0-175" href="#__codelineno-0-175"></a>
<a id="__codelineno-0-176" name="__codelineno-0-176" href="#__codelineno-0-176"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-177" name="__codelineno-0-177" href="#__codelineno-0-177"></a>            <span class="n">problem</span><span class="p">,</span>
<a id="__codelineno-0-178" name="__codelineno-0-178" href="#__codelineno-0-178"></a>            <span class="n">popsize</span><span class="o">=</span><span class="n">popsize</span><span class="p">,</span>
<a id="__codelineno-0-179" name="__codelineno-0-179" href="#__codelineno-0-179"></a>            <span class="n">center_learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-180" name="__codelineno-0-180" href="#__codelineno-0-180"></a>            <span class="n">stdev_learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-181" name="__codelineno-0-181" href="#__codelineno-0-181"></a>            <span class="n">stdev_init</span><span class="o">=</span><span class="n">stdev_init</span><span class="p">,</span>
<a id="__codelineno-0-182" name="__codelineno-0-182" href="#__codelineno-0-182"></a>            <span class="n">radius_init</span><span class="o">=</span><span class="n">radius_init</span><span class="p">,</span>
<a id="__codelineno-0-183" name="__codelineno-0-183" href="#__codelineno-0-183"></a>            <span class="n">popsize_max</span><span class="o">=</span><span class="n">popsize_max</span><span class="p">,</span>
<a id="__codelineno-0-184" name="__codelineno-0-184" href="#__codelineno-0-184"></a>            <span class="n">num_interactions</span><span class="o">=</span><span class="n">num_interactions</span><span class="p">,</span>
<a id="__codelineno-0-185" name="__codelineno-0-185" href="#__codelineno-0-185"></a>            <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-186" name="__codelineno-0-186" href="#__codelineno-0-186"></a>            <span class="n">optimizer_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-187" name="__codelineno-0-187" href="#__codelineno-0-187"></a>            <span class="n">ranking_method</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-188" name="__codelineno-0-188" href="#__codelineno-0-188"></a>            <span class="n">center_init</span><span class="o">=</span><span class="n">center_init</span><span class="p">,</span>
<a id="__codelineno-0-189" name="__codelineno-0-189" href="#__codelineno-0-189"></a>            <span class="n">stdev_min</span><span class="o">=</span><span class="n">stdev_min</span><span class="p">,</span>
<a id="__codelineno-0-190" name="__codelineno-0-190" href="#__codelineno-0-190"></a>            <span class="n">stdev_max</span><span class="o">=</span><span class="n">stdev_max</span><span class="p">,</span>
<a id="__codelineno-0-191" name="__codelineno-0-191" href="#__codelineno-0-191"></a>            <span class="n">stdev_max_change</span><span class="o">=</span><span class="n">stdev_max_change</span><span class="p">,</span>
<a id="__codelineno-0-192" name="__codelineno-0-192" href="#__codelineno-0-192"></a>            <span class="n">obj_index</span><span class="o">=</span><span class="n">obj_index</span><span class="p">,</span>
<a id="__codelineno-0-193" name="__codelineno-0-193" href="#__codelineno-0-193"></a>            <span class="n">distributed</span><span class="o">=</span><span class="n">distributed</span><span class="p">,</span>
<a id="__codelineno-0-194" name="__codelineno-0-194" href="#__codelineno-0-194"></a>            <span class="n">popsize_weighted_grad_avg</span><span class="o">=</span><span class="n">popsize_weighted_grad_avg</span><span class="p">,</span>
<a id="__codelineno-0-195" name="__codelineno-0-195" href="#__codelineno-0-195"></a>        <span class="p">)</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">








  <div class="doc doc-object doc-class">



<h3 id="evotorch.algorithms.distributed.gaussian.CEM.DISTRIBUTION_TYPE" class="doc doc-heading">
        <code>
DISTRIBUTION_TYPE            (<a class="autorefs autorefs-internal" title="evotorch.distributions.Distribution" href="../../../distributions/#evotorch.distributions.Distribution">Distribution</a>)
        </code>



<a href="#evotorch.algorithms.distributed.gaussian.CEM.DISTRIBUTION_TYPE" class="headerlink" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p>Separable Multivariate Gaussian, as used by PGPE</p>

        <details class="quote">
          <summary>Source code in <code>evotorch/algorithms/distributed/gaussian.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">class</span> <span class="nc">SeparableGaussian</span><span class="p">(</span><span class="n">Distribution</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Separable Multivariate Gaussian, as used by PGPE&quot;&quot;&quot;</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">MANDATORY_PARAMETERS</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;mu&quot;</span><span class="p">,</span> <span class="s2">&quot;sigma&quot;</span><span class="p">}</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">OPTIONAL_PARAMETERS</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;divide_mu_grad_by&quot;</span><span class="p">,</span> <span class="s2">&quot;divide_sigma_grad_by&quot;</span><span class="p">,</span> <span class="s2">&quot;parenthood_ratio&quot;</span><span class="p">}</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>        <span class="n">parameters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>        <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>        <span class="n">solution_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>        <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>        <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="p">):</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>        <span class="p">[</span><span class="n">mu_length</span><span class="p">]</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>        <span class="p">[</span><span class="n">sigma_length</span><span class="p">]</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>        <span class="k">if</span> <span class="n">solution_length</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>            <span class="n">solution_length</span> <span class="o">=</span> <span class="n">mu_length</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>            <span class="k">if</span> <span class="n">solution_length</span> <span class="o">!=</span> <span class="n">mu_length</span><span class="p">:</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>                    <span class="sa">f</span><span class="s2">&quot;The argument `solution_length` does not match the length of `mu` provided in `parameters`.&quot;</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>                    <span class="sa">f</span><span class="s2">&quot; solution_length=</span><span class="si">{</span><span class="n">solution_length</span><span class="si">}</span><span class="s2">,&quot;</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>                    <span class="sa">f</span><span class="s1">&#39; parameters[&quot;mu&quot;]=</span><span class="si">{</span><span class="n">mu_length</span><span class="si">}</span><span class="s1">.&#39;</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>                <span class="p">)</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>        <span class="k">if</span> <span class="n">mu_length</span> <span class="o">!=</span> <span class="n">sigma_length</span><span class="p">:</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>                <span class="sa">f</span><span class="s2">&quot;The tensors `mu` and `sigma` provided within `parameters` have mismatching lengths.&quot;</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>                <span class="sa">f</span><span class="s1">&#39; parameters[&quot;mu&quot;]=</span><span class="si">{</span><span class="n">mu_length</span><span class="si">}</span><span class="s1">,&#39;</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>                <span class="sa">f</span><span class="s1">&#39; parameters[&quot;sigma&quot;]=</span><span class="si">{</span><span class="n">sigma_length</span><span class="si">}</span><span class="s1">.&#39;</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>            <span class="p">)</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a>            <span class="n">solution_length</span><span class="o">=</span><span class="n">solution_length</span><span class="p">,</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>            <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a>            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>        <span class="p">)</span>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a>    <span class="k">def</span> <span class="nf">mu</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">]</span>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a>    <span class="nd">@mu</span><span class="o">.</span><span class="n">setter</span>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a>    <span class="k">def</span> <span class="nf">mu</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_mu</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">):</span>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">new_mu</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a>
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a>    <span class="k">def</span> <span class="nf">sigma</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">]</span>
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a>
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a>    <span class="nd">@sigma</span><span class="o">.</span><span class="n">setter</span>
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a>    <span class="k">def</span> <span class="nf">sigma</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_sigma</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">):</span>
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">new_sigma</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a>
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a>    <span class="k">def</span> <span class="nf">_fill</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">out</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">generator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">make_gaussian</span><span class="p">(</span><span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">,</span> <span class="n">stdev</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sigma</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">)</span>
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a>
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a>    <span class="k">def</span> <span class="nf">_divide_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">grad</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#__codelineno-0-62"></a>        <span class="n">option</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;divide_</span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="s2">_grad_by&quot;</span>
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#__codelineno-0-63"></a>        <span class="k">if</span> <span class="n">option</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">:</span>
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#__codelineno-0-64"></a>            <span class="n">div_by_what</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="n">option</span><span class="p">]</span>
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#__codelineno-0-65"></a>            <span class="k">if</span> <span class="n">div_by_what</span> <span class="o">==</span> <span class="s2">&quot;num_solutions&quot;</span><span class="p">:</span>
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#__codelineno-0-66"></a>                <span class="p">[</span><span class="n">num_solutions</span><span class="p">]</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#__codelineno-0-67"></a>                <span class="n">grad</span> <span class="o">=</span> <span class="n">grad</span> <span class="o">/</span> <span class="n">num_solutions</span>
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#__codelineno-0-68"></a>            <span class="k">elif</span> <span class="n">div_by_what</span> <span class="o">==</span> <span class="s2">&quot;num_directions&quot;</span><span class="p">:</span>
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#__codelineno-0-69"></a>                <span class="p">[</span><span class="n">num_solutions</span><span class="p">]</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#__codelineno-0-70"></a>                <span class="n">num_directions</span> <span class="o">=</span> <span class="n">num_solutions</span> <span class="o">//</span> <span class="mi">2</span>
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#__codelineno-0-71"></a>                <span class="n">grad</span> <span class="o">=</span> <span class="n">grad</span> <span class="o">/</span> <span class="n">num_directions</span>
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#__codelineno-0-72"></a>            <span class="k">elif</span> <span class="n">div_by_what</span> <span class="o">==</span> <span class="s2">&quot;total_weight&quot;</span><span class="p">:</span>
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#__codelineno-0-73"></a>                <span class="n">total_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">weights</span><span class="p">))</span>
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#__codelineno-0-74"></a>                <span class="n">grad</span> <span class="o">=</span> <span class="n">grad</span> <span class="o">/</span> <span class="n">total_weight</span>
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#__codelineno-0-75"></a>            <span class="k">elif</span> <span class="n">div_by_what</span> <span class="o">==</span> <span class="s2">&quot;weight_stdev&quot;</span><span class="p">:</span>
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#__codelineno-0-76"></a>                <span class="n">weight_stdev</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#__codelineno-0-77"></a>                <span class="n">grad</span> <span class="o">=</span> <span class="n">grad</span> <span class="o">/</span> <span class="n">weight_stdev</span>
<a id="__codelineno-0-78" name="__codelineno-0-78" href="#__codelineno-0-78"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-79" name="__codelineno-0-79" href="#__codelineno-0-79"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The parameter </span><span class="si">{</span><span class="n">option</span><span class="si">}</span><span class="s2"> has an unrecognized value: </span><span class="si">{</span><span class="n">div_by_what</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<a id="__codelineno-0-80" name="__codelineno-0-80" href="#__codelineno-0-80"></a>        <span class="k">return</span> <span class="n">grad</span>
<a id="__codelineno-0-81" name="__codelineno-0-81" href="#__codelineno-0-81"></a>
<a id="__codelineno-0-82" name="__codelineno-0-82" href="#__codelineno-0-82"></a>    <span class="k">def</span> <span class="nf">_compute_gradients_via_parenthood_ratio</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<a id="__codelineno-0-83" name="__codelineno-0-83" href="#__codelineno-0-83"></a>        <span class="p">[</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">_</span><span class="p">]</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-84" name="__codelineno-0-84" href="#__codelineno-0-84"></a>        <span class="n">num_elites</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">num_samples</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;parenthood_ratio&quot;</span><span class="p">])</span>
<a id="__codelineno-0-85" name="__codelineno-0-85" href="#__codelineno-0-85"></a>        <span class="n">elite_indices</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="n">num_elites</span><span class="p">]</span>
<a id="__codelineno-0-86" name="__codelineno-0-86" href="#__codelineno-0-86"></a>        <span class="n">elites</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="n">elite_indices</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-87" name="__codelineno-0-87" href="#__codelineno-0-87"></a>        <span class="k">return</span> <span class="p">{</span>
<a id="__codelineno-0-88" name="__codelineno-0-88" href="#__codelineno-0-88"></a>            <span class="s2">&quot;mu&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">elites</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">],</span>
<a id="__codelineno-0-89" name="__codelineno-0-89" href="#__codelineno-0-89"></a>            <span class="s2">&quot;sigma&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">elites</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">],</span>
<a id="__codelineno-0-90" name="__codelineno-0-90" href="#__codelineno-0-90"></a>        <span class="p">}</span>
<a id="__codelineno-0-91" name="__codelineno-0-91" href="#__codelineno-0-91"></a>
<a id="__codelineno-0-92" name="__codelineno-0-92" href="#__codelineno-0-92"></a>    <span class="k">def</span> <span class="nf">_compute_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">ranking_used</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<a id="__codelineno-0-93" name="__codelineno-0-93" href="#__codelineno-0-93"></a>        <span class="k">if</span> <span class="s2">&quot;parenthood_ratio&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">:</span>
<a id="__codelineno-0-94" name="__codelineno-0-94" href="#__codelineno-0-94"></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_gradients_via_parenthood_ratio</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
<a id="__codelineno-0-95" name="__codelineno-0-95" href="#__codelineno-0-95"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-96" name="__codelineno-0-96" href="#__codelineno-0-96"></a>            <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span>
<a id="__codelineno-0-97" name="__codelineno-0-97" href="#__codelineno-0-97"></a>            <span class="n">sigma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span>
<a id="__codelineno-0-98" name="__codelineno-0-98" href="#__codelineno-0-98"></a>
<a id="__codelineno-0-99" name="__codelineno-0-99" href="#__codelineno-0-99"></a>            <span class="c1"># Compute the scaled noises, that is, the noise vectors which</span>
<a id="__codelineno-0-100" name="__codelineno-0-100" href="#__codelineno-0-100"></a>            <span class="c1"># were used for generating the solutions</span>
<a id="__codelineno-0-101" name="__codelineno-0-101" href="#__codelineno-0-101"></a>            <span class="c1"># (solution = scaled_noise + center)</span>
<a id="__codelineno-0-102" name="__codelineno-0-102" href="#__codelineno-0-102"></a>            <span class="n">scaled_noises</span> <span class="o">=</span> <span class="n">samples</span> <span class="o">-</span> <span class="n">mu</span>
<a id="__codelineno-0-103" name="__codelineno-0-103" href="#__codelineno-0-103"></a>
<a id="__codelineno-0-104" name="__codelineno-0-104" href="#__codelineno-0-104"></a>            <span class="c1"># Make sure that the weights (utilities) are 0-centered</span>
<a id="__codelineno-0-105" name="__codelineno-0-105" href="#__codelineno-0-105"></a>            <span class="c1"># (Otherwise the formulations would have to consider a bias term)</span>
<a id="__codelineno-0-106" name="__codelineno-0-106" href="#__codelineno-0-106"></a>            <span class="k">if</span> <span class="n">ranking_used</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;centered&quot;</span><span class="p">,</span> <span class="s2">&quot;normalized&quot;</span><span class="p">):</span>
<a id="__codelineno-0-107" name="__codelineno-0-107" href="#__codelineno-0-107"></a>                <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
<a id="__codelineno-0-108" name="__codelineno-0-108" href="#__codelineno-0-108"></a>
<a id="__codelineno-0-109" name="__codelineno-0-109" href="#__codelineno-0-109"></a>            <span class="n">mu_grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_divide_grad</span><span class="p">(</span>
<a id="__codelineno-0-110" name="__codelineno-0-110" href="#__codelineno-0-110"></a>                <span class="s2">&quot;mu&quot;</span><span class="p">,</span>
<a id="__codelineno-0-111" name="__codelineno-0-111" href="#__codelineno-0-111"></a>                <span class="n">total</span><span class="p">(</span><span class="n">dot</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">scaled_noises</span><span class="p">)),</span>
<a id="__codelineno-0-112" name="__codelineno-0-112" href="#__codelineno-0-112"></a>                <span class="n">weights</span><span class="p">,</span>
<a id="__codelineno-0-113" name="__codelineno-0-113" href="#__codelineno-0-113"></a>            <span class="p">)</span>
<a id="__codelineno-0-114" name="__codelineno-0-114" href="#__codelineno-0-114"></a>            <span class="n">sigma_grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_divide_grad</span><span class="p">(</span>
<a id="__codelineno-0-115" name="__codelineno-0-115" href="#__codelineno-0-115"></a>                <span class="s2">&quot;sigma&quot;</span><span class="p">,</span>
<a id="__codelineno-0-116" name="__codelineno-0-116" href="#__codelineno-0-116"></a>                <span class="n">total</span><span class="p">(</span><span class="n">dot</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="p">((</span><span class="n">scaled_noises</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="n">sigma</span><span class="p">)),</span>
<a id="__codelineno-0-117" name="__codelineno-0-117" href="#__codelineno-0-117"></a>                <span class="n">weights</span><span class="p">,</span>
<a id="__codelineno-0-118" name="__codelineno-0-118" href="#__codelineno-0-118"></a>            <span class="p">)</span>
<a id="__codelineno-0-119" name="__codelineno-0-119" href="#__codelineno-0-119"></a>
<a id="__codelineno-0-120" name="__codelineno-0-120" href="#__codelineno-0-120"></a>            <span class="k">return</span> <span class="p">{</span>
<a id="__codelineno-0-121" name="__codelineno-0-121" href="#__codelineno-0-121"></a>                <span class="s2">&quot;mu&quot;</span><span class="p">:</span> <span class="n">mu_grad</span><span class="p">,</span>
<a id="__codelineno-0-122" name="__codelineno-0-122" href="#__codelineno-0-122"></a>                <span class="s2">&quot;sigma&quot;</span><span class="p">:</span> <span class="n">sigma_grad</span><span class="p">,</span>
<a id="__codelineno-0-123" name="__codelineno-0-123" href="#__codelineno-0-123"></a>            <span class="p">}</span>
<a id="__codelineno-0-124" name="__codelineno-0-124" href="#__codelineno-0-124"></a>
<a id="__codelineno-0-125" name="__codelineno-0-125" href="#__codelineno-0-125"></a>    <span class="k">def</span> <span class="nf">update_parameters</span><span class="p">(</span>
<a id="__codelineno-0-126" name="__codelineno-0-126" href="#__codelineno-0-126"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-127" name="__codelineno-0-127" href="#__codelineno-0-127"></a>        <span class="n">gradients</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
<a id="__codelineno-0-128" name="__codelineno-0-128" href="#__codelineno-0-128"></a>        <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-129" name="__codelineno-0-129" href="#__codelineno-0-129"></a>        <span class="n">learning_rates</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-130" name="__codelineno-0-130" href="#__codelineno-0-130"></a>        <span class="n">optimizers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-131" name="__codelineno-0-131" href="#__codelineno-0-131"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;SeparableGaussian&quot;</span><span class="p">:</span>
<a id="__codelineno-0-132" name="__codelineno-0-132" href="#__codelineno-0-132"></a>        <span class="n">mu_grad</span> <span class="o">=</span> <span class="n">gradients</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">]</span>
<a id="__codelineno-0-133" name="__codelineno-0-133" href="#__codelineno-0-133"></a>        <span class="n">sigma_grad</span> <span class="o">=</span> <span class="n">gradients</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">]</span>
<a id="__codelineno-0-134" name="__codelineno-0-134" href="#__codelineno-0-134"></a>
<a id="__codelineno-0-135" name="__codelineno-0-135" href="#__codelineno-0-135"></a>        <span class="n">new_mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_follow_gradient</span><span class="p">(</span><span class="s2">&quot;mu&quot;</span><span class="p">,</span> <span class="n">mu_grad</span><span class="p">,</span> <span class="n">learning_rates</span><span class="o">=</span><span class="n">learning_rates</span><span class="p">,</span> <span class="n">optimizers</span><span class="o">=</span><span class="n">optimizers</span><span class="p">)</span>
<a id="__codelineno-0-136" name="__codelineno-0-136" href="#__codelineno-0-136"></a>        <span class="n">new_sigma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_follow_gradient</span><span class="p">(</span>
<a id="__codelineno-0-137" name="__codelineno-0-137" href="#__codelineno-0-137"></a>            <span class="s2">&quot;sigma&quot;</span><span class="p">,</span> <span class="n">sigma_grad</span><span class="p">,</span> <span class="n">learning_rates</span><span class="o">=</span><span class="n">learning_rates</span><span class="p">,</span> <span class="n">optimizers</span><span class="o">=</span><span class="n">optimizers</span>
<a id="__codelineno-0-138" name="__codelineno-0-138" href="#__codelineno-0-138"></a>        <span class="p">)</span>
<a id="__codelineno-0-139" name="__codelineno-0-139" href="#__codelineno-0-139"></a>
<a id="__codelineno-0-140" name="__codelineno-0-140" href="#__codelineno-0-140"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">modified_copy</span><span class="p">(</span><span class="n">mu</span><span class="o">=</span><span class="n">new_mu</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">new_sigma</span><span class="p">)</span>
<a id="__codelineno-0-141" name="__codelineno-0-141" href="#__codelineno-0-141"></a>
<a id="__codelineno-0-142" name="__codelineno-0-142" href="#__codelineno-0-142"></a>    <span class="k">def</span> <span class="nf">relative_entropy</span><span class="p">(</span><span class="n">dist_0</span><span class="p">:</span> <span class="s2">&quot;SeparableGaussian&quot;</span><span class="p">,</span> <span class="n">dist_1</span><span class="p">:</span> <span class="s2">&quot;SeparableGaussian&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<a id="__codelineno-0-143" name="__codelineno-0-143" href="#__codelineno-0-143"></a>        <span class="n">mu_0</span> <span class="o">=</span> <span class="n">dist_0</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">]</span>
<a id="__codelineno-0-144" name="__codelineno-0-144" href="#__codelineno-0-144"></a>        <span class="n">mu_1</span> <span class="o">=</span> <span class="n">dist_1</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">]</span>
<a id="__codelineno-0-145" name="__codelineno-0-145" href="#__codelineno-0-145"></a>        <span class="n">sigma_0</span> <span class="o">=</span> <span class="n">dist_0</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">]</span>
<a id="__codelineno-0-146" name="__codelineno-0-146" href="#__codelineno-0-146"></a>        <span class="n">sigma_1</span> <span class="o">=</span> <span class="n">dist_1</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">]</span>
<a id="__codelineno-0-147" name="__codelineno-0-147" href="#__codelineno-0-147"></a>        <span class="n">cov_0</span> <span class="o">=</span> <span class="n">sigma_0</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span>
<a id="__codelineno-0-148" name="__codelineno-0-148" href="#__codelineno-0-148"></a>        <span class="n">cov_1</span> <span class="o">=</span> <span class="n">sigma_1</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span>
<a id="__codelineno-0-149" name="__codelineno-0-149" href="#__codelineno-0-149"></a>
<a id="__codelineno-0-150" name="__codelineno-0-150" href="#__codelineno-0-150"></a>        <span class="n">mu_delta</span> <span class="o">=</span> <span class="n">mu_1</span> <span class="o">-</span> <span class="n">mu_0</span>
<a id="__codelineno-0-151" name="__codelineno-0-151" href="#__codelineno-0-151"></a>
<a id="__codelineno-0-152" name="__codelineno-0-152" href="#__codelineno-0-152"></a>        <span class="n">trace_cov</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">cov_0</span> <span class="o">/</span> <span class="n">cov_1</span><span class="p">)</span>
<a id="__codelineno-0-153" name="__codelineno-0-153" href="#__codelineno-0-153"></a>        <span class="n">k</span> <span class="o">=</span> <span class="n">dist_0</span><span class="o">.</span><span class="n">solution_length</span>
<a id="__codelineno-0-154" name="__codelineno-0-154" href="#__codelineno-0-154"></a>        <span class="n">scaled_mu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mu_delta</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span> <span class="o">/</span> <span class="n">cov_1</span><span class="p">)</span>
<a id="__codelineno-0-155" name="__codelineno-0-155" href="#__codelineno-0-155"></a>        <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">cov_1</span><span class="p">))</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">cov_0</span><span class="p">))</span>
<a id="__codelineno-0-156" name="__codelineno-0-156" href="#__codelineno-0-156"></a>
<a id="__codelineno-0-157" name="__codelineno-0-157" href="#__codelineno-0-157"></a>        <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">trace_cov</span> <span class="o">-</span> <span class="n">k</span> <span class="o">+</span> <span class="n">scaled_mu</span> <span class="o">+</span> <span class="n">log_det</span><span class="p">)</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">















  <div class="doc doc-object doc-method">



<h4 id="evotorch.algorithms.distributed.gaussian.CEM.DISTRIBUTION_TYPE.update_parameters" class="doc doc-heading">
<code class="highlight language-python"><span class="n">update_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">learning_rates</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">optimizers</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>


<a href="#evotorch.algorithms.distributed.gaussian.CEM.DISTRIBUTION_TYPE.update_parameters" class="headerlink" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>Do an update on the distribution by following the given gradients.</p>
<p>It is expected that the inheriting class has its own implementation
for this method.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>gradients</code></td>
        <td><code>dict</code></td>
        <td><p>Gradients, as a dictionary, which will be used for
computing the necessary updates.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>learning_rates</code></td>
        <td><code>Optional[dict]</code></td>
        <td><p>A dictionary which contains learning rates
for parameters that will be updated using a learning rate
coefficient.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>optimizers</code></td>
        <td><code>Optional[dict]</code></td>
        <td><p>A dictionary which contains optimizer objects
for parameters that will be updated using an adaptive
optimizer.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>SeparableGaussian</code></td>
      <td><p>The updated copy of the distribution.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>evotorch/algorithms/distributed/gaussian.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">update_parameters</span><span class="p">(</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">gradients</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">learning_rates</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">optimizers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;SeparableGaussian&quot;</span><span class="p">:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n">mu_grad</span> <span class="o">=</span> <span class="n">gradients</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">]</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="n">sigma_grad</span> <span class="o">=</span> <span class="n">gradients</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">]</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="n">new_mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_follow_gradient</span><span class="p">(</span><span class="s2">&quot;mu&quot;</span><span class="p">,</span> <span class="n">mu_grad</span><span class="p">,</span> <span class="n">learning_rates</span><span class="o">=</span><span class="n">learning_rates</span><span class="p">,</span> <span class="n">optimizers</span><span class="o">=</span><span class="n">optimizers</span><span class="p">)</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="n">new_sigma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_follow_gradient</span><span class="p">(</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>        <span class="s2">&quot;sigma&quot;</span><span class="p">,</span> <span class="n">sigma_grad</span><span class="p">,</span> <span class="n">learning_rates</span><span class="o">=</span><span class="n">learning_rates</span><span class="p">,</span> <span class="n">optimizers</span><span class="o">=</span><span class="n">optimizers</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="p">)</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">modified_copy</span><span class="p">(</span><span class="n">mu</span><span class="o">=</span><span class="n">new_mu</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">new_sigma</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>





  <div class="doc doc-object doc-method">



<h3 id="evotorch.algorithms.distributed.gaussian.CEM.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">problem</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">popsize</span><span class="p">,</span> <span class="n">parenthood_ratio</span><span class="p">,</span> <span class="n">stdev_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">radius_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_interactions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">popsize_max</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">center_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stdev_min</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stdev_max</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stdev_max_change</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">obj_index</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">distributed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">popsize_weighted_grad_avg</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

<a href="#evotorch.algorithms.distributed.gaussian.CEM.__init__" class="headerlink" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p><code>__init__(...)</code>: Initialize the search algorithm.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>problem</code></td>
        <td><code>Problem</code></td>
        <td><p>The problem object to work on.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>popsize</code></td>
        <td><code>int</code></td>
        <td><p>The population size.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>parenthood_ratio</code></td>
        <td><code>float</code></td>
        <td><p>Expected as a float larger than 0 and smaller
than 1. For example, setting this value to 0.1 means that
the top 10% of the population will be declared as the parents,
and those parents will be used for updating the population.
The amount of parents is always computed according to the
specified <code>popsize</code>, not according to the adapted population
size, and not according to <code>popsize_max</code>.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>stdev_init</code></td>
        <td><code>Union[float, Iterable[float], torch.Tensor]</code></td>
        <td><p>The initial standard deviation of the search
distribution, expressed as a scalar or as an array.
Determines the initial coverage area of the search
distribution.
If one wishes to configure the coverage area via the
argument <code>radius_init</code> instead, then <code>stdev_init</code> is expected
as None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>radius_init</code></td>
        <td><code>Union[float, Iterable[float], torch.Tensor]</code></td>
        <td><p>The initial radius of the search distribution,
expressed as a scalar.
Determines the initial coverage area of the search
distribution.
Here, "radius" is defined as the norm of the search
distribution.
If one wishes to configure the coverage area via the
argument <code>stdev_init</code> instead, then <code>radius_init</code> is expected
as None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>num_interactions</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>When given as an integer n,
it is ensured that a population has interacted with
the GymProblem's environment n times. If this target
has not been reached yet, then the population is declared
too small, and gets extended with more samples,
until n amount of interactions is reached.
When given as None, popsize is the only configuration
affecting the size of a population.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>popsize_max</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>Having <code>num_interactions</code> set as an integer
might cause the effective population size jump to
unnecesarily large numbers. To prevent this,
one can set <code>popsize_max</code> to specify an upper
bound for the effective population size.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>center_init</code></td>
        <td><code>Union[float, Iterable[float], torch.Tensor]</code></td>
        <td><p>The initial center solution.
Can be left as None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>stdev_min</code></td>
        <td><code>Union[float, Iterable[float], torch.Tensor]</code></td>
        <td><p>The minimum value for the standard deviation
values of the Gaussian search distribution.
Can be left as None (which is the default),
or can be given as a scalar or as a 1-dimensional array.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>stdev_max</code></td>
        <td><code>Union[float, Iterable[float], torch.Tensor]</code></td>
        <td><p>The maximum value for the standard deviation
values of the Gaussian search distribution.
Can be left as None (which is the default),
or can be given as a scalar or as a 1-dimensional array.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>stdev_max_change</code></td>
        <td><code>Union[float, Iterable[float], torch.Tensor]</code></td>
        <td><p>The maximum update ratio allowed on the
standard deviation. Expected as None if no such limiter
is needed, or as a real number within 0.0 and 1.0 otherwise.
In the PGPE implementation of Ha (2017, 2018), a value of
0.2 (20%) was used.
For this CEM implementation, the default is None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>obj_index</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>Index of the objective according to which the
gradient estimations will be done.
For single-objective problems, this can be left as None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>distributed</code></td>
        <td><code>bool</code></td>
        <td><p>Whether or not the gradient computation will
be distributed. If <code>distributed</code> is given as False and
the problem is not parallelized, then everything will
be centralized (i.e. the entire computation will happen
in the main process).
If <code>distributed</code> is given as False, and the problem
is parallelized, then the population will be created
in the main process and then sent to remote workers
for parallelized evaluation, and then the remote fitnesses
will be collected by the main process again for computing
the search gradients.
If <code>distributed</code> is given as True, and the problem
is parallelized, then the search algorithm itself will
be distributed, in the sense that each remote actor will
generate its own population (such that the total population
size across all these actors becomes equal to <code>popsize</code>)
and will compute its own gradient, and then the main process
will collect these gradients, compute the averaged gradients
and update the main search distribution.
Non-distributed mode has the advantage of keeping the
population in the main process, which is good when one wishes
to do detailed monitoring during the evolutionary process,
but has the disadvantage of having to pass the solutions to
the remote actors and having to collect fitnesses, which
might result in increased interprocess communication traffic.
On the other hand, while it is not possible to monitor the
population in distributed mode, the distributed mode has the
advantage of significantly reducing the interprocess
communication traffic, since the only things communicated
with the remote actors are the search distributions (not the
solutions) and the gradients.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>popsize_weighted_grad_avg</code></td>
        <td><code>Optional[bool]</code></td>
        <td><p>Only to be used in distributed mode.
(where being in distributed mode means <code>distributed</code> is given
as True). In distributed mode, each actor remotely samples
its own solution batches and computes its own gradients.
These gradients are then collected, and a final average
gradient is computed.
If <code>popsize_weighted_grad_avg</code> is True, then, while averaging
over the gradients, each gradient will have its own weight
that is computed according to how many solutions were sampled
by the actor that produced the gradient.
If <code>popsize_weighted_grad_avg</code> is False, then, there will not
be weighted averaging (or, each gradient will have equal
weight).
If <code>popsize_weighted_grad_avg</code> is None, then, the gradient
weights will be equal a value for <code>num_interactions</code> is given
(because <code>num_interactions</code> affects the number of solutions
according to the episode lengths, and popsize-weighting the
gradients could be misleading); and the gradient weights will
be weighted according to the sub-population (i.e. sub-batch)
sizes if <code>num_interactions</code> is left as None.
The default value for <code>popsize_weighted_grad_avg</code> is None.
When the distributed mode is disabled (i.e. when <code>distributed</code>
is False), then the argument <code>popsize_weighted_grad_avg</code> is
expected as None.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>evotorch/algorithms/distributed/gaussian.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">problem</span><span class="p">:</span> <span class="n">Problem</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">popsize</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">parenthood_ratio</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">stdev_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n">radius_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="n">num_interactions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="n">popsize_max</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="n">center_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="n">stdev_min</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    <span class="n">stdev_max</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="n">stdev_max_change</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">RealOrVector</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="n">obj_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="n">distributed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>    <span class="n">popsize_weighted_grad_avg</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a><span class="p">):</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a><span class="sd">    `__init__(...)`: Initialize the search algorithm.</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a><span class="sd">        problem: The problem object to work on.</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a><span class="sd">        popsize: The population size.</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a><span class="sd">        parenthood_ratio: Expected as a float larger than 0 and smaller</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a><span class="sd">            than 1. For example, setting this value to 0.1 means that</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a><span class="sd">            the top 10% of the population will be declared as the parents,</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a><span class="sd">            and those parents will be used for updating the population.</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a><span class="sd">            The amount of parents is always computed according to the</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a><span class="sd">            specified `popsize`, not according to the adapted population</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a><span class="sd">            size, and not according to `popsize_max`.</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a><span class="sd">        stdev_init: The initial standard deviation of the search</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a><span class="sd">            distribution, expressed as a scalar or as an array.</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a><span class="sd">            Determines the initial coverage area of the search</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a><span class="sd">            distribution.</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a><span class="sd">            If one wishes to configure the coverage area via the</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a><span class="sd">            argument `radius_init` instead, then `stdev_init` is expected</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a><span class="sd">            as None.</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a><span class="sd">        radius_init: The initial radius of the search distribution,</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a><span class="sd">            expressed as a scalar.</span>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a><span class="sd">            Determines the initial coverage area of the search</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a><span class="sd">            distribution.</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a><span class="sd">            Here, &quot;radius&quot; is defined as the norm of the search</span>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a><span class="sd">            distribution.</span>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a><span class="sd">            If one wishes to configure the coverage area via the</span>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a><span class="sd">            argument `stdev_init` instead, then `radius_init` is expected</span>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a><span class="sd">            as None.</span>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a><span class="sd">        num_interactions: When given as an integer n,</span>
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a><span class="sd">            it is ensured that a population has interacted with</span>
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a><span class="sd">            the GymProblem&#39;s environment n times. If this target</span>
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a><span class="sd">            has not been reached yet, then the population is declared</span>
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a><span class="sd">            too small, and gets extended with more samples,</span>
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a><span class="sd">            until n amount of interactions is reached.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a><span class="sd">            When given as None, popsize is the only configuration</span>
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a><span class="sd">            affecting the size of a population.</span>
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a><span class="sd">        popsize_max: Having `num_interactions` set as an integer</span>
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a><span class="sd">            might cause the effective population size jump to</span>
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a><span class="sd">            unnecesarily large numbers. To prevent this,</span>
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a><span class="sd">            one can set `popsize_max` to specify an upper</span>
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a><span class="sd">            bound for the effective population size.</span>
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a><span class="sd">        center_init: The initial center solution.</span>
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#__codelineno-0-62"></a><span class="sd">            Can be left as None.</span>
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#__codelineno-0-63"></a><span class="sd">        stdev_min: The minimum value for the standard deviation</span>
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#__codelineno-0-64"></a><span class="sd">            values of the Gaussian search distribution.</span>
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#__codelineno-0-65"></a><span class="sd">            Can be left as None (which is the default),</span>
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#__codelineno-0-66"></a><span class="sd">            or can be given as a scalar or as a 1-dimensional array.</span>
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#__codelineno-0-67"></a><span class="sd">        stdev_max: The maximum value for the standard deviation</span>
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#__codelineno-0-68"></a><span class="sd">            values of the Gaussian search distribution.</span>
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#__codelineno-0-69"></a><span class="sd">            Can be left as None (which is the default),</span>
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#__codelineno-0-70"></a><span class="sd">            or can be given as a scalar or as a 1-dimensional array.</span>
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#__codelineno-0-71"></a><span class="sd">        stdev_max_change: The maximum update ratio allowed on the</span>
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#__codelineno-0-72"></a><span class="sd">            standard deviation. Expected as None if no such limiter</span>
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#__codelineno-0-73"></a><span class="sd">            is needed, or as a real number within 0.0 and 1.0 otherwise.</span>
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#__codelineno-0-74"></a><span class="sd">            In the PGPE implementation of Ha (2017, 2018), a value of</span>
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#__codelineno-0-75"></a><span class="sd">            0.2 (20%) was used.</span>
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#__codelineno-0-76"></a><span class="sd">            For this CEM implementation, the default is None.</span>
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#__codelineno-0-77"></a><span class="sd">        obj_index: Index of the objective according to which the</span>
<a id="__codelineno-0-78" name="__codelineno-0-78" href="#__codelineno-0-78"></a><span class="sd">            gradient estimations will be done.</span>
<a id="__codelineno-0-79" name="__codelineno-0-79" href="#__codelineno-0-79"></a><span class="sd">            For single-objective problems, this can be left as None.</span>
<a id="__codelineno-0-80" name="__codelineno-0-80" href="#__codelineno-0-80"></a><span class="sd">        distributed: Whether or not the gradient computation will</span>
<a id="__codelineno-0-81" name="__codelineno-0-81" href="#__codelineno-0-81"></a><span class="sd">            be distributed. If `distributed` is given as False and</span>
<a id="__codelineno-0-82" name="__codelineno-0-82" href="#__codelineno-0-82"></a><span class="sd">            the problem is not parallelized, then everything will</span>
<a id="__codelineno-0-83" name="__codelineno-0-83" href="#__codelineno-0-83"></a><span class="sd">            be centralized (i.e. the entire computation will happen</span>
<a id="__codelineno-0-84" name="__codelineno-0-84" href="#__codelineno-0-84"></a><span class="sd">            in the main process).</span>
<a id="__codelineno-0-85" name="__codelineno-0-85" href="#__codelineno-0-85"></a><span class="sd">            If `distributed` is given as False, and the problem</span>
<a id="__codelineno-0-86" name="__codelineno-0-86" href="#__codelineno-0-86"></a><span class="sd">            is parallelized, then the population will be created</span>
<a id="__codelineno-0-87" name="__codelineno-0-87" href="#__codelineno-0-87"></a><span class="sd">            in the main process and then sent to remote workers</span>
<a id="__codelineno-0-88" name="__codelineno-0-88" href="#__codelineno-0-88"></a><span class="sd">            for parallelized evaluation, and then the remote fitnesses</span>
<a id="__codelineno-0-89" name="__codelineno-0-89" href="#__codelineno-0-89"></a><span class="sd">            will be collected by the main process again for computing</span>
<a id="__codelineno-0-90" name="__codelineno-0-90" href="#__codelineno-0-90"></a><span class="sd">            the search gradients.</span>
<a id="__codelineno-0-91" name="__codelineno-0-91" href="#__codelineno-0-91"></a><span class="sd">            If `distributed` is given as True, and the problem</span>
<a id="__codelineno-0-92" name="__codelineno-0-92" href="#__codelineno-0-92"></a><span class="sd">            is parallelized, then the search algorithm itself will</span>
<a id="__codelineno-0-93" name="__codelineno-0-93" href="#__codelineno-0-93"></a><span class="sd">            be distributed, in the sense that each remote actor will</span>
<a id="__codelineno-0-94" name="__codelineno-0-94" href="#__codelineno-0-94"></a><span class="sd">            generate its own population (such that the total population</span>
<a id="__codelineno-0-95" name="__codelineno-0-95" href="#__codelineno-0-95"></a><span class="sd">            size across all these actors becomes equal to `popsize`)</span>
<a id="__codelineno-0-96" name="__codelineno-0-96" href="#__codelineno-0-96"></a><span class="sd">            and will compute its own gradient, and then the main process</span>
<a id="__codelineno-0-97" name="__codelineno-0-97" href="#__codelineno-0-97"></a><span class="sd">            will collect these gradients, compute the averaged gradients</span>
<a id="__codelineno-0-98" name="__codelineno-0-98" href="#__codelineno-0-98"></a><span class="sd">            and update the main search distribution.</span>
<a id="__codelineno-0-99" name="__codelineno-0-99" href="#__codelineno-0-99"></a><span class="sd">            Non-distributed mode has the advantage of keeping the</span>
<a id="__codelineno-0-100" name="__codelineno-0-100" href="#__codelineno-0-100"></a><span class="sd">            population in the main process, which is good when one wishes</span>
<a id="__codelineno-0-101" name="__codelineno-0-101" href="#__codelineno-0-101"></a><span class="sd">            to do detailed monitoring during the evolutionary process,</span>
<a id="__codelineno-0-102" name="__codelineno-0-102" href="#__codelineno-0-102"></a><span class="sd">            but has the disadvantage of having to pass the solutions to</span>
<a id="__codelineno-0-103" name="__codelineno-0-103" href="#__codelineno-0-103"></a><span class="sd">            the remote actors and having to collect fitnesses, which</span>
<a id="__codelineno-0-104" name="__codelineno-0-104" href="#__codelineno-0-104"></a><span class="sd">            might result in increased interprocess communication traffic.</span>
<a id="__codelineno-0-105" name="__codelineno-0-105" href="#__codelineno-0-105"></a><span class="sd">            On the other hand, while it is not possible to monitor the</span>
<a id="__codelineno-0-106" name="__codelineno-0-106" href="#__codelineno-0-106"></a><span class="sd">            population in distributed mode, the distributed mode has the</span>
<a id="__codelineno-0-107" name="__codelineno-0-107" href="#__codelineno-0-107"></a><span class="sd">            advantage of significantly reducing the interprocess</span>
<a id="__codelineno-0-108" name="__codelineno-0-108" href="#__codelineno-0-108"></a><span class="sd">            communication traffic, since the only things communicated</span>
<a id="__codelineno-0-109" name="__codelineno-0-109" href="#__codelineno-0-109"></a><span class="sd">            with the remote actors are the search distributions (not the</span>
<a id="__codelineno-0-110" name="__codelineno-0-110" href="#__codelineno-0-110"></a><span class="sd">            solutions) and the gradients.</span>
<a id="__codelineno-0-111" name="__codelineno-0-111" href="#__codelineno-0-111"></a><span class="sd">        popsize_weighted_grad_avg: Only to be used in distributed mode.</span>
<a id="__codelineno-0-112" name="__codelineno-0-112" href="#__codelineno-0-112"></a><span class="sd">            (where being in distributed mode means `distributed` is given</span>
<a id="__codelineno-0-113" name="__codelineno-0-113" href="#__codelineno-0-113"></a><span class="sd">            as True). In distributed mode, each actor remotely samples</span>
<a id="__codelineno-0-114" name="__codelineno-0-114" href="#__codelineno-0-114"></a><span class="sd">            its own solution batches and computes its own gradients.</span>
<a id="__codelineno-0-115" name="__codelineno-0-115" href="#__codelineno-0-115"></a><span class="sd">            These gradients are then collected, and a final average</span>
<a id="__codelineno-0-116" name="__codelineno-0-116" href="#__codelineno-0-116"></a><span class="sd">            gradient is computed.</span>
<a id="__codelineno-0-117" name="__codelineno-0-117" href="#__codelineno-0-117"></a><span class="sd">            If `popsize_weighted_grad_avg` is True, then, while averaging</span>
<a id="__codelineno-0-118" name="__codelineno-0-118" href="#__codelineno-0-118"></a><span class="sd">            over the gradients, each gradient will have its own weight</span>
<a id="__codelineno-0-119" name="__codelineno-0-119" href="#__codelineno-0-119"></a><span class="sd">            that is computed according to how many solutions were sampled</span>
<a id="__codelineno-0-120" name="__codelineno-0-120" href="#__codelineno-0-120"></a><span class="sd">            by the actor that produced the gradient.</span>
<a id="__codelineno-0-121" name="__codelineno-0-121" href="#__codelineno-0-121"></a><span class="sd">            If `popsize_weighted_grad_avg` is False, then, there will not</span>
<a id="__codelineno-0-122" name="__codelineno-0-122" href="#__codelineno-0-122"></a><span class="sd">            be weighted averaging (or, each gradient will have equal</span>
<a id="__codelineno-0-123" name="__codelineno-0-123" href="#__codelineno-0-123"></a><span class="sd">            weight).</span>
<a id="__codelineno-0-124" name="__codelineno-0-124" href="#__codelineno-0-124"></a><span class="sd">            If `popsize_weighted_grad_avg` is None, then, the gradient</span>
<a id="__codelineno-0-125" name="__codelineno-0-125" href="#__codelineno-0-125"></a><span class="sd">            weights will be equal a value for `num_interactions` is given</span>
<a id="__codelineno-0-126" name="__codelineno-0-126" href="#__codelineno-0-126"></a><span class="sd">            (because `num_interactions` affects the number of solutions</span>
<a id="__codelineno-0-127" name="__codelineno-0-127" href="#__codelineno-0-127"></a><span class="sd">            according to the episode lengths, and popsize-weighting the</span>
<a id="__codelineno-0-128" name="__codelineno-0-128" href="#__codelineno-0-128"></a><span class="sd">            gradients could be misleading); and the gradient weights will</span>
<a id="__codelineno-0-129" name="__codelineno-0-129" href="#__codelineno-0-129"></a><span class="sd">            be weighted according to the sub-population (i.e. sub-batch)</span>
<a id="__codelineno-0-130" name="__codelineno-0-130" href="#__codelineno-0-130"></a><span class="sd">            sizes if `num_interactions` is left as None.</span>
<a id="__codelineno-0-131" name="__codelineno-0-131" href="#__codelineno-0-131"></a><span class="sd">            The default value for `popsize_weighted_grad_avg` is None.</span>
<a id="__codelineno-0-132" name="__codelineno-0-132" href="#__codelineno-0-132"></a><span class="sd">            When the distributed mode is disabled (i.e. when `distributed`</span>
<a id="__codelineno-0-133" name="__codelineno-0-133" href="#__codelineno-0-133"></a><span class="sd">            is False), then the argument `popsize_weighted_grad_avg` is</span>
<a id="__codelineno-0-134" name="__codelineno-0-134" href="#__codelineno-0-134"></a><span class="sd">            expected as None.</span>
<a id="__codelineno-0-135" name="__codelineno-0-135" href="#__codelineno-0-135"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-136" name="__codelineno-0-136" href="#__codelineno-0-136"></a>
<a id="__codelineno-0-137" name="__codelineno-0-137" href="#__codelineno-0-137"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">DISTRIBUTION_PARAMS</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;parenthood_ratio&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">parenthood_ratio</span><span class="p">)}</span>
<a id="__codelineno-0-138" name="__codelineno-0-138" href="#__codelineno-0-138"></a>
<a id="__codelineno-0-139" name="__codelineno-0-139" href="#__codelineno-0-139"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-140" name="__codelineno-0-140" href="#__codelineno-0-140"></a>        <span class="n">problem</span><span class="p">,</span>
<a id="__codelineno-0-141" name="__codelineno-0-141" href="#__codelineno-0-141"></a>        <span class="n">popsize</span><span class="o">=</span><span class="n">popsize</span><span class="p">,</span>
<a id="__codelineno-0-142" name="__codelineno-0-142" href="#__codelineno-0-142"></a>        <span class="n">center_learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-143" name="__codelineno-0-143" href="#__codelineno-0-143"></a>        <span class="n">stdev_learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-144" name="__codelineno-0-144" href="#__codelineno-0-144"></a>        <span class="n">stdev_init</span><span class="o">=</span><span class="n">stdev_init</span><span class="p">,</span>
<a id="__codelineno-0-145" name="__codelineno-0-145" href="#__codelineno-0-145"></a>        <span class="n">radius_init</span><span class="o">=</span><span class="n">radius_init</span><span class="p">,</span>
<a id="__codelineno-0-146" name="__codelineno-0-146" href="#__codelineno-0-146"></a>        <span class="n">popsize_max</span><span class="o">=</span><span class="n">popsize_max</span><span class="p">,</span>
<a id="__codelineno-0-147" name="__codelineno-0-147" href="#__codelineno-0-147"></a>        <span class="n">num_interactions</span><span class="o">=</span><span class="n">num_interactions</span><span class="p">,</span>
<a id="__codelineno-0-148" name="__codelineno-0-148" href="#__codelineno-0-148"></a>        <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-149" name="__codelineno-0-149" href="#__codelineno-0-149"></a>        <span class="n">optimizer_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-150" name="__codelineno-0-150" href="#__codelineno-0-150"></a>        <span class="n">ranking_method</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-151" name="__codelineno-0-151" href="#__codelineno-0-151"></a>        <span class="n">center_init</span><span class="o">=</span><span class="n">center_init</span><span class="p">,</span>
<a id="__codelineno-0-152" name="__codelineno-0-152" href="#__codelineno-0-152"></a>        <span class="n">stdev_min</span><span class="o">=</span><span class="n">stdev_min</span><span class="p">,</span>
<a id="__codelineno-0-153" name="__codelineno-0-153" href="#__codelineno-0-153"></a>        <span class="n">stdev_max</span><span class="o">=</span><span class="n">stdev_max</span><span class="p">,</span>
<a id="__codelineno-0-154" name="__codelineno-0-154" href="#__codelineno-0-154"></a>        <span class="n">stdev_max_change</span><span class="o">=</span><span class="n">stdev_max_change</span><span class="p">,</span>
<a id="__codelineno-0-155" name="__codelineno-0-155" href="#__codelineno-0-155"></a>        <span class="n">obj_index</span><span class="o">=</span><span class="n">obj_index</span><span class="p">,</span>
<a id="__codelineno-0-156" name="__codelineno-0-156" href="#__codelineno-0-156"></a>        <span class="n">distributed</span><span class="o">=</span><span class="n">distributed</span><span class="p">,</span>
<a id="__codelineno-0-157" name="__codelineno-0-157" href="#__codelineno-0-157"></a>        <span class="n">popsize_weighted_grad_avg</span><span class="o">=</span><span class="n">popsize_weighted_grad_avg</span><span class="p">,</span>
<a id="__codelineno-0-158" name="__codelineno-0-158" href="#__codelineno-0-158"></a>    <span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h2 id="evotorch.algorithms.distributed.gaussian.GaussianSearchAlgorithm" class="doc doc-heading">
        <code>
GaussianSearchAlgorithm            (<a class="autorefs autorefs-internal" title="evotorch.algorithms.searchalgorithm.SearchAlgorithm" href="../../searchalgorithm/#evotorch.algorithms.searchalgorithm.SearchAlgorithm">SearchAlgorithm</a>, <a class="autorefs autorefs-internal" title="evotorch.algorithms.searchalgorithm.SinglePopulationAlgorithmMixin" href="../../searchalgorithm/#evotorch.algorithms.searchalgorithm.SinglePopulationAlgorithmMixin">SinglePopulationAlgorithmMixin</a>)
        </code>



<a href="#evotorch.algorithms.distributed.gaussian.GaussianSearchAlgorithm" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents ">

      <p>Base class for search algorithms based on Gaussian distribution.</p>

        <details class="quote">
          <summary>Source code in <code>evotorch/algorithms/distributed/gaussian.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">class</span> <span class="nc">GaussianSearchAlgorithm</span><span class="p">(</span><span class="n">SearchAlgorithm</span><span class="p">,</span> <span class="n">SinglePopulationAlgorithmMixin</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="sd">    Base class for search algorithms based on Gaussian distribution.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">DISTRIBUTION_TYPE</span> <span class="o">=</span> <span class="bp">NotImplemented</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">DISTRIBUTION_PARAMS</span> <span class="o">=</span> <span class="bp">NotImplemented</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>        <span class="n">problem</span><span class="p">:</span> <span class="n">Problem</span><span class="p">,</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>        <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>        <span class="n">popsize</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>        <span class="n">center_learning_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>        <span class="n">stdev_learning_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>        <span class="n">stdev_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>        <span class="n">radius_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>        <span class="n">num_interactions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>        <span class="n">popsize_max</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>        <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>        <span class="n">optimizer_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>        <span class="n">ranking_method</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>        <span class="n">center_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>        <span class="n">stdev_min</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>        <span class="n">stdev_max</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>        <span class="n">stdev_max_change</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>        <span class="n">obj_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>        <span class="n">distributed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>        <span class="n">popsize_weighted_grad_avg</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>        <span class="n">ensure_even_popsize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>    <span class="p">):</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>        <span class="c1"># Ensure that the problem is numeric</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>        <span class="n">problem</span><span class="o">.</span><span class="n">ensure_numeric</span><span class="p">()</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>        <span class="c1"># The distribution-based algorithms we consider here cannot handle strict lower and upper bound constraints.</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a>        <span class="c1"># Therefore, we ensure that the given problem is unbounded.</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>        <span class="n">problem</span><span class="o">.</span><span class="n">ensure_unbounded</span><span class="p">()</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a>        <span class="c1"># Initialize the SearchAlgorithm, which is the parent class</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>        <span class="n">SearchAlgorithm</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>            <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a>            <span class="n">problem</span><span class="p">,</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a>            <span class="n">center</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_mu</span><span class="p">,</span>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a>            <span class="n">stdev</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_sigma</span><span class="p">,</span>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a>            <span class="n">mean_eval</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_mean_eval</span><span class="p">,</span>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a>        <span class="p">)</span>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_even_popsize</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">ensure_even_popsize</span><span class="p">)</span>
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a>
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">distributed</span><span class="p">:</span>
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a>            <span class="c1"># self.add_status_getters({&quot;median_eval&quot;: self._get_median_eval})</span>
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a>            <span class="k">if</span> <span class="n">num_interactions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">add_status_getters</span><span class="p">({</span><span class="s2">&quot;popsize&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_popsize</span><span class="p">})</span>
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_even_popsize</span><span class="p">:</span>
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a>                <span class="k">if</span> <span class="p">(</span><span class="n">popsize</span> <span class="o">%</span> <span class="mi">2</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a>                        <span class="sa">f</span><span class="s2">&quot;`popsize` was expected as an even number. However, the received `popsize` is </span><span class="si">{</span><span class="n">popsize</span><span class="si">}</span><span class="s2">.&quot;</span>
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a>                    <span class="p">)</span>
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a>
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a>        <span class="k">if</span> <span class="n">center_init</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a>            <span class="c1"># If a starting point for the search distribution is not given,</span>
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#__codelineno-0-62"></a>            <span class="c1"># then we use the problem object to generate us one.</span>
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#__codelineno-0-63"></a>            <span class="n">mu</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">generate_values</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#__codelineno-0-64"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#__codelineno-0-65"></a>            <span class="c1"># If a starting point for the search distribution is given,</span>
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#__codelineno-0-66"></a>            <span class="c1"># then we make sure that its length, dtype, and device</span>
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#__codelineno-0-67"></a>            <span class="c1"># are correct.</span>
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#__codelineno-0-68"></a>            <span class="n">mu</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">ensure_tensor_length_and_dtype</span><span class="p">(</span><span class="n">center_init</span><span class="p">,</span> <span class="n">allow_scalar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">about</span><span class="o">=</span><span class="s2">&quot;center_init&quot;</span><span class="p">)</span>
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#__codelineno-0-69"></a>
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#__codelineno-0-70"></a>        <span class="c1"># Get the standard deviation or the radius configuration from the arguments</span>
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#__codelineno-0-71"></a>        <span class="n">stdev_init</span> <span class="o">=</span> <span class="n">to_stdev_init</span><span class="p">(</span>
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#__codelineno-0-72"></a>            <span class="n">solution_length</span><span class="o">=</span><span class="n">problem</span><span class="o">.</span><span class="n">solution_length</span><span class="p">,</span> <span class="n">stdev_init</span><span class="o">=</span><span class="n">stdev_init</span><span class="p">,</span> <span class="n">radius_init</span><span class="o">=</span><span class="n">radius_init</span>
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#__codelineno-0-73"></a>        <span class="p">)</span>
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#__codelineno-0-74"></a>
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#__codelineno-0-75"></a>        <span class="c1"># Make sure that the provided initial standard deviation is</span>
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#__codelineno-0-76"></a>        <span class="c1"># of correct length, dtype, and device.</span>
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#__codelineno-0-77"></a>        <span class="n">sigma</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">ensure_tensor_length_and_dtype</span><span class="p">(</span><span class="n">stdev_init</span><span class="p">,</span> <span class="n">about</span><span class="o">=</span><span class="s2">&quot;stdev_init&quot;</span><span class="p">,</span> <span class="n">allow_scalar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-78" name="__codelineno-0-78" href="#__codelineno-0-78"></a>
<a id="__codelineno-0-79" name="__codelineno-0-79" href="#__codelineno-0-79"></a>        <span class="c1"># Create the distribution</span>
<a id="__codelineno-0-80" name="__codelineno-0-80" href="#__codelineno-0-80"></a>        <span class="n">dist_cls</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">DISTRIBUTION_TYPE</span>
<a id="__codelineno-0-81" name="__codelineno-0-81" href="#__codelineno-0-81"></a>        <span class="n">dist_params</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DISTRIBUTION_PARAMS</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">DISTRIBUTION_PARAMS</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
<a id="__codelineno-0-82" name="__codelineno-0-82" href="#__codelineno-0-82"></a>        <span class="n">dist_params</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;mu&quot;</span><span class="p">:</span> <span class="n">mu</span><span class="p">,</span> <span class="s2">&quot;sigma&quot;</span><span class="p">:</span> <span class="n">sigma</span><span class="p">})</span>
<a id="__codelineno-0-83" name="__codelineno-0-83" href="#__codelineno-0-83"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_distribution</span><span class="p">:</span> <span class="n">Distribution</span> <span class="o">=</span> <span class="n">dist_cls</span><span class="p">(</span><span class="n">dist_params</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">problem</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">problem</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-84" name="__codelineno-0-84" href="#__codelineno-0-84"></a>
<a id="__codelineno-0-85" name="__codelineno-0-85" href="#__codelineno-0-85"></a>        <span class="c1"># Store the following keyword arguments to use later</span>
<a id="__codelineno-0-86" name="__codelineno-0-86" href="#__codelineno-0-86"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_popsize</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">popsize</span><span class="p">)</span>
<a id="__codelineno-0-87" name="__codelineno-0-87" href="#__codelineno-0-87"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_popsize_max</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">popsize_max</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">int</span><span class="p">(</span><span class="n">popsize_max</span><span class="p">)</span>
<a id="__codelineno-0-88" name="__codelineno-0-88" href="#__codelineno-0-88"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_num_interactions</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">num_interactions</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_interactions</span><span class="p">)</span>
<a id="__codelineno-0-89" name="__codelineno-0-89" href="#__codelineno-0-89"></a>
<a id="__codelineno-0-90" name="__codelineno-0-90" href="#__codelineno-0-90"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_center_learning_rate</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">center_learning_rate</span><span class="p">)</span>
<a id="__codelineno-0-91" name="__codelineno-0-91" href="#__codelineno-0-91"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_stdev_learning_rate</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">stdev_learning_rate</span><span class="p">)</span>
<a id="__codelineno-0-92" name="__codelineno-0-92" href="#__codelineno-0-92"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_center_learning_rate</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">optimizer_config</span><span class="p">)</span>
<a id="__codelineno-0-93" name="__codelineno-0-93" href="#__codelineno-0-93"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_ranking_method</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">ranking_method</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">str</span><span class="p">(</span><span class="n">ranking_method</span><span class="p">)</span>
<a id="__codelineno-0-94" name="__codelineno-0-94" href="#__codelineno-0-94"></a>
<a id="__codelineno-0-95" name="__codelineno-0-95" href="#__codelineno-0-95"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_stdev_min</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-96" name="__codelineno-0-96" href="#__codelineno-0-96"></a>            <span class="kc">None</span>
<a id="__codelineno-0-97" name="__codelineno-0-97" href="#__codelineno-0-97"></a>            <span class="k">if</span> <span class="n">stdev_min</span> <span class="ow">is</span> <span class="kc">None</span>
<a id="__codelineno-0-98" name="__codelineno-0-98" href="#__codelineno-0-98"></a>            <span class="k">else</span> <span class="n">problem</span><span class="o">.</span><span class="n">ensure_tensor_length_and_dtype</span><span class="p">(</span><span class="n">stdev_min</span><span class="p">,</span> <span class="n">about</span><span class="o">=</span><span class="s2">&quot;stdev_min&quot;</span><span class="p">,</span> <span class="n">allow_scalar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-99" name="__codelineno-0-99" href="#__codelineno-0-99"></a>        <span class="p">)</span>
<a id="__codelineno-0-100" name="__codelineno-0-100" href="#__codelineno-0-100"></a>
<a id="__codelineno-0-101" name="__codelineno-0-101" href="#__codelineno-0-101"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_stdev_max</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-102" name="__codelineno-0-102" href="#__codelineno-0-102"></a>            <span class="kc">None</span>
<a id="__codelineno-0-103" name="__codelineno-0-103" href="#__codelineno-0-103"></a>            <span class="k">if</span> <span class="n">stdev_max</span> <span class="ow">is</span> <span class="kc">None</span>
<a id="__codelineno-0-104" name="__codelineno-0-104" href="#__codelineno-0-104"></a>            <span class="k">else</span> <span class="n">problem</span><span class="o">.</span><span class="n">ensure_tensor_length_and_dtype</span><span class="p">(</span><span class="n">stdev_max</span><span class="p">,</span> <span class="n">about</span><span class="o">=</span><span class="s2">&quot;stdev_max&quot;</span><span class="p">,</span> <span class="n">allow_scalar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-105" name="__codelineno-0-105" href="#__codelineno-0-105"></a>        <span class="p">)</span>
<a id="__codelineno-0-106" name="__codelineno-0-106" href="#__codelineno-0-106"></a>
<a id="__codelineno-0-107" name="__codelineno-0-107" href="#__codelineno-0-107"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_stdev_max_change</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-108" name="__codelineno-0-108" href="#__codelineno-0-108"></a>            <span class="kc">None</span>
<a id="__codelineno-0-109" name="__codelineno-0-109" href="#__codelineno-0-109"></a>            <span class="k">if</span> <span class="n">stdev_max_change</span> <span class="ow">is</span> <span class="kc">None</span>
<a id="__codelineno-0-110" name="__codelineno-0-110" href="#__codelineno-0-110"></a>            <span class="k">else</span> <span class="n">problem</span><span class="o">.</span><span class="n">ensure_tensor_length_and_dtype</span><span class="p">(</span><span class="n">stdev_max_change</span><span class="p">,</span> <span class="n">about</span><span class="o">=</span><span class="s2">&quot;stdev_max_change&quot;</span><span class="p">,</span> <span class="n">allow_scalar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-111" name="__codelineno-0-111" href="#__codelineno-0-111"></a>        <span class="p">)</span>
<a id="__codelineno-0-112" name="__codelineno-0-112" href="#__codelineno-0-112"></a>
<a id="__codelineno-0-113" name="__codelineno-0-113" href="#__codelineno-0-113"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_obj_index</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">normalize_obj_index</span><span class="p">(</span><span class="n">obj_index</span><span class="p">)</span>
<a id="__codelineno-0-114" name="__codelineno-0-114" href="#__codelineno-0-114"></a>
<a id="__codelineno-0-115" name="__codelineno-0-115" href="#__codelineno-0-115"></a>        <span class="k">if</span> <span class="n">distributed</span> <span class="ow">and</span> <span class="p">(</span><span class="n">problem</span><span class="o">.</span><span class="n">num_actors</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">):</span>
<a id="__codelineno-0-116" name="__codelineno-0-116" href="#__codelineno-0-116"></a>            <span class="c1"># If the algorithm is initialized in distributed mode, and also if the problem is configured</span>
<a id="__codelineno-0-117" name="__codelineno-0-117" href="#__codelineno-0-117"></a>            <span class="c1"># for parallelization, then the _step method becomes an alias for _step_distributed</span>
<a id="__codelineno-0-118" name="__codelineno-0-118" href="#__codelineno-0-118"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_step_distributed</span>
<a id="__codelineno-0-119" name="__codelineno-0-119" href="#__codelineno-0-119"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-120" name="__codelineno-0-120" href="#__codelineno-0-120"></a>            <span class="c1"># Otherwise, the _step method becomes an alias for _step_non_distributed</span>
<a id="__codelineno-0-121" name="__codelineno-0-121" href="#__codelineno-0-121"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_step_non_distributed</span>
<a id="__codelineno-0-122" name="__codelineno-0-122" href="#__codelineno-0-122"></a>
<a id="__codelineno-0-123" name="__codelineno-0-123" href="#__codelineno-0-123"></a>        <span class="k">if</span> <span class="n">popsize_weighted_grad_avg</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-124" name="__codelineno-0-124" href="#__codelineno-0-124"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_popsize_weighted_grad_avg</span> <span class="o">=</span> <span class="n">num_interactions</span> <span class="ow">is</span> <span class="kc">None</span>
<a id="__codelineno-0-125" name="__codelineno-0-125" href="#__codelineno-0-125"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-126" name="__codelineno-0-126" href="#__codelineno-0-126"></a>            <span class="k">if</span> <span class="ow">not</span> <span class="n">distributed</span><span class="p">:</span>
<a id="__codelineno-0-127" name="__codelineno-0-127" href="#__codelineno-0-127"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-128" name="__codelineno-0-128" href="#__codelineno-0-128"></a>                    <span class="s2">&quot;The argument `popsize_weighted_grad_avg` can only be used in distributed mode.&quot;</span>
<a id="__codelineno-0-129" name="__codelineno-0-129" href="#__codelineno-0-129"></a>                    <span class="s2">&quot; (i.e. when the argument `distributed` is given as True).&quot;</span>
<a id="__codelineno-0-130" name="__codelineno-0-130" href="#__codelineno-0-130"></a>                    <span class="s2">&quot; When `distributed` is False, please leave `popsize_weighted_grad_avg` as None.&quot;</span>
<a id="__codelineno-0-131" name="__codelineno-0-131" href="#__codelineno-0-131"></a>                <span class="p">)</span>
<a id="__codelineno-0-132" name="__codelineno-0-132" href="#__codelineno-0-132"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_popsize_weighted_grad_avg</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">popsize_weighted_grad_avg</span><span class="p">)</span>
<a id="__codelineno-0-133" name="__codelineno-0-133" href="#__codelineno-0-133"></a>
<a id="__codelineno-0-134" name="__codelineno-0-134" href="#__codelineno-0-134"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_mean_eval</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-135" name="__codelineno-0-135" href="#__codelineno-0-135"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_population</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SolutionBatch</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-136" name="__codelineno-0-136" href="#__codelineno-0-136"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_first_iter</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-137" name="__codelineno-0-137" href="#__codelineno-0-137"></a>
<a id="__codelineno-0-138" name="__codelineno-0-138" href="#__codelineno-0-138"></a>        <span class="c1"># We would like to add the reporting capabilities of the mixin class `singlePopulationAlgorithmMixin`.</span>
<a id="__codelineno-0-139" name="__codelineno-0-139" href="#__codelineno-0-139"></a>        <span class="c1"># However, we exclude &quot;mean_eval&quot; from the reporting services requested from `SinglePopulationAlgorithmMixin`</span>
<a id="__codelineno-0-140" name="__codelineno-0-140" href="#__codelineno-0-140"></a>        <span class="c1"># because this class has its own reporting mechanism for `mean_eval`.</span>
<a id="__codelineno-0-141" name="__codelineno-0-141" href="#__codelineno-0-141"></a>        <span class="c1"># Additionally, we enable the reporting services of `SinglePopulationAlgorithmMixin` only when we are</span>
<a id="__codelineno-0-142" name="__codelineno-0-142" href="#__codelineno-0-142"></a>        <span class="c1"># in the non-distributed mode. This is because we do not have a centrally stored population at all in the</span>
<a id="__codelineno-0-143" name="__codelineno-0-143" href="#__codelineno-0-143"></a>        <span class="c1"># distributed mode.</span>
<a id="__codelineno-0-144" name="__codelineno-0-144" href="#__codelineno-0-144"></a>        <span class="n">SinglePopulationAlgorithmMixin</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exclude</span><span class="o">=</span><span class="s2">&quot;mean_eval&quot;</span><span class="p">,</span> <span class="n">enable</span><span class="o">=</span><span class="p">(</span><span class="ow">not</span> <span class="n">distributed</span><span class="p">))</span>
<a id="__codelineno-0-145" name="__codelineno-0-145" href="#__codelineno-0-145"></a>
<a id="__codelineno-0-146" name="__codelineno-0-146" href="#__codelineno-0-146"></a>    <span class="k">def</span> <span class="nf">_initialize_optimizer</span><span class="p">(</span>
<a id="__codelineno-0-147" name="__codelineno-0-147" href="#__codelineno-0-147"></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">optimizer_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-148" name="__codelineno-0-148" href="#__codelineno-0-148"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">object</span><span class="p">:</span>
<a id="__codelineno-0-149" name="__codelineno-0-149" href="#__codelineno-0-149"></a>        <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-150" name="__codelineno-0-150" href="#__codelineno-0-150"></a>            <span class="k">return</span> <span class="kc">None</span>
<a id="__codelineno-0-151" name="__codelineno-0-151" href="#__codelineno-0-151"></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
<a id="__codelineno-0-152" name="__codelineno-0-152" href="#__codelineno-0-152"></a>            <span class="n">center_optim_cls</span> <span class="o">=</span> <span class="n">get_optimizer_class</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">optimizer_config</span><span class="p">)</span>
<a id="__codelineno-0-153" name="__codelineno-0-153" href="#__codelineno-0-153"></a>            <span class="k">return</span> <span class="n">center_optim_cls</span><span class="p">(</span>
<a id="__codelineno-0-154" name="__codelineno-0-154" href="#__codelineno-0-154"></a>                <span class="n">stepsize</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">),</span>
<a id="__codelineno-0-155" name="__codelineno-0-155" href="#__codelineno-0-155"></a>                <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
<a id="__codelineno-0-156" name="__codelineno-0-156" href="#__codelineno-0-156"></a>                <span class="n">solution_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution</span><span class="o">.</span><span class="n">solution_length</span><span class="p">,</span>
<a id="__codelineno-0-157" name="__codelineno-0-157" href="#__codelineno-0-157"></a>                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
<a id="__codelineno-0-158" name="__codelineno-0-158" href="#__codelineno-0-158"></a>            <span class="p">)</span>
<a id="__codelineno-0-159" name="__codelineno-0-159" href="#__codelineno-0-159"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-160" name="__codelineno-0-160" href="#__codelineno-0-160"></a>            <span class="k">return</span> <span class="n">optimizer</span>
<a id="__codelineno-0-161" name="__codelineno-0-161" href="#__codelineno-0-161"></a>
<a id="__codelineno-0-162" name="__codelineno-0-162" href="#__codelineno-0-162"></a>    <span class="k">def</span> <span class="nf">_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-163" name="__codelineno-0-163" href="#__codelineno-0-163"></a>        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
<a id="__codelineno-0-164" name="__codelineno-0-164" href="#__codelineno-0-164"></a>
<a id="__codelineno-0-165" name="__codelineno-0-165" href="#__codelineno-0-165"></a>    <span class="k">def</span> <span class="nf">_step_distributed</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-166" name="__codelineno-0-166" href="#__codelineno-0-166"></a>        <span class="c1"># Use the problem object&#39;s `sample_and_compute_gradients` method</span>
<a id="__codelineno-0-167" name="__codelineno-0-167" href="#__codelineno-0-167"></a>        <span class="c1"># to do parallelized and distributed gradient computation</span>
<a id="__codelineno-0-168" name="__codelineno-0-168" href="#__codelineno-0-168"></a>        <span class="n">fetched</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">problem</span><span class="o">.</span><span class="n">sample_and_compute_gradients</span><span class="p">(</span>
<a id="__codelineno-0-169" name="__codelineno-0-169" href="#__codelineno-0-169"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_distribution</span><span class="p">,</span>
<a id="__codelineno-0-170" name="__codelineno-0-170" href="#__codelineno-0-170"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_popsize</span><span class="p">,</span>
<a id="__codelineno-0-171" name="__codelineno-0-171" href="#__codelineno-0-171"></a>            <span class="n">popsize_max</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_popsize_max</span><span class="p">,</span>
<a id="__codelineno-0-172" name="__codelineno-0-172" href="#__codelineno-0-172"></a>            <span class="n">obj_index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_obj_index</span><span class="p">,</span>
<a id="__codelineno-0-173" name="__codelineno-0-173" href="#__codelineno-0-173"></a>            <span class="n">num_interactions</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_interactions</span><span class="p">,</span>
<a id="__codelineno-0-174" name="__codelineno-0-174" href="#__codelineno-0-174"></a>            <span class="n">ranking_method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_ranking_method</span><span class="p">,</span>
<a id="__codelineno-0-175" name="__codelineno-0-175" href="#__codelineno-0-175"></a>            <span class="n">ensure_even_popsize</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_ensure_even_popsize</span><span class="p">,</span>
<a id="__codelineno-0-176" name="__codelineno-0-176" href="#__codelineno-0-176"></a>        <span class="p">)</span>
<a id="__codelineno-0-177" name="__codelineno-0-177" href="#__codelineno-0-177"></a>
<a id="__codelineno-0-178" name="__codelineno-0-178" href="#__codelineno-0-178"></a>        <span class="c1"># The method `sample_and_compute_gradients(...)` returns a list of dictionaries, each dictionary being</span>
<a id="__codelineno-0-179" name="__codelineno-0-179" href="#__codelineno-0-179"></a>        <span class="c1"># the result of a different remote computation.</span>
<a id="__codelineno-0-180" name="__codelineno-0-180" href="#__codelineno-0-180"></a>        <span class="c1"># For each remote computation, the list will contain a dictionary that looks like this:</span>
<a id="__codelineno-0-181" name="__codelineno-0-181" href="#__codelineno-0-181"></a>        <span class="c1"># {&quot;gradients&quot;: &lt;gradients dictionary here&gt;, &quot;num_solutions&quot;: ..., &quot;mean_eval&quot;: ...}</span>
<a id="__codelineno-0-182" name="__codelineno-0-182" href="#__codelineno-0-182"></a>
<a id="__codelineno-0-183" name="__codelineno-0-183" href="#__codelineno-0-183"></a>        <span class="c1"># We will now accumulate all the gradients, num_solutions, and mean_evals in their own lists.</span>
<a id="__codelineno-0-184" name="__codelineno-0-184" href="#__codelineno-0-184"></a>        <span class="c1"># So, in the end, we will have a list of gradients, a list of num_solutions, and a list of</span>
<a id="__codelineno-0-185" name="__codelineno-0-185" href="#__codelineno-0-185"></a>        <span class="c1"># mean_eval.</span>
<a id="__codelineno-0-186" name="__codelineno-0-186" href="#__codelineno-0-186"></a>        <span class="c1"># These lists will be stored by the following temporary class:</span>
<a id="__codelineno-0-187" name="__codelineno-0-187" href="#__codelineno-0-187"></a>        <span class="k">class</span> <span class="nc">list_of</span><span class="p">:</span>
<a id="__codelineno-0-188" name="__codelineno-0-188" href="#__codelineno-0-188"></a>            <span class="n">gradients</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-189" name="__codelineno-0-189" href="#__codelineno-0-189"></a>            <span class="n">num_solutions</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-190" name="__codelineno-0-190" href="#__codelineno-0-190"></a>            <span class="n">mean_eval</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-191" name="__codelineno-0-191" href="#__codelineno-0-191"></a>
<a id="__codelineno-0-192" name="__codelineno-0-192" href="#__codelineno-0-192"></a>        <span class="c1"># We are now filling the lists declared above</span>
<a id="__codelineno-0-193" name="__codelineno-0-193" href="#__codelineno-0-193"></a>        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">fetched</span><span class="p">)</span>
<a id="__codelineno-0-194" name="__codelineno-0-194" href="#__codelineno-0-194"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
<a id="__codelineno-0-195" name="__codelineno-0-195" href="#__codelineno-0-195"></a>            <span class="n">list_of</span><span class="o">.</span><span class="n">gradients</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fetched</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;gradients&quot;</span><span class="p">])</span>
<a id="__codelineno-0-196" name="__codelineno-0-196" href="#__codelineno-0-196"></a>            <span class="n">list_of</span><span class="o">.</span><span class="n">num_solutions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fetched</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;num_solutions&quot;</span><span class="p">])</span>
<a id="__codelineno-0-197" name="__codelineno-0-197" href="#__codelineno-0-197"></a>            <span class="n">list_of</span><span class="o">.</span><span class="n">mean_eval</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fetched</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;mean_eval&quot;</span><span class="p">])</span>
<a id="__codelineno-0-198" name="__codelineno-0-198" href="#__codelineno-0-198"></a>
<a id="__codelineno-0-199" name="__codelineno-0-199" href="#__codelineno-0-199"></a>        <span class="c1"># Here, we get the keys of our gradient dictionaries.</span>
<a id="__codelineno-0-200" name="__codelineno-0-200" href="#__codelineno-0-200"></a>        <span class="c1"># For most simple Gaussian distributions, grad_keys should be {&quot;mu&quot;, &quot;sigma&quot;}.</span>
<a id="__codelineno-0-201" name="__codelineno-0-201" href="#__codelineno-0-201"></a>        <span class="n">grad_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">list_of</span><span class="o">.</span><span class="n">gradients</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<a id="__codelineno-0-202" name="__codelineno-0-202" href="#__codelineno-0-202"></a>
<a id="__codelineno-0-203" name="__codelineno-0-203" href="#__codelineno-0-203"></a>        <span class="c1"># We now find the total number of solutions and the overall average mean_eval.</span>
<a id="__codelineno-0-204" name="__codelineno-0-204" href="#__codelineno-0-204"></a>        <span class="c1"># The overall average mean will be reported to the user.</span>
<a id="__codelineno-0-205" name="__codelineno-0-205" href="#__codelineno-0-205"></a>        <span class="n">total_num_solutions</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-206" name="__codelineno-0-206" href="#__codelineno-0-206"></a>        <span class="n">total_weighted_eval</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-207" name="__codelineno-0-207" href="#__codelineno-0-207"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
<a id="__codelineno-0-208" name="__codelineno-0-208" href="#__codelineno-0-208"></a>            <span class="n">total_num_solutions</span> <span class="o">+=</span> <span class="n">list_of</span><span class="o">.</span><span class="n">num_solutions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<a id="__codelineno-0-209" name="__codelineno-0-209" href="#__codelineno-0-209"></a>            <span class="n">total_weighted_eval</span> <span class="o">+=</span> <span class="nb">float</span><span class="p">(</span><span class="n">list_of</span><span class="o">.</span><span class="n">num_solutions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">list_of</span><span class="o">.</span><span class="n">mean_eval</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<a id="__codelineno-0-210" name="__codelineno-0-210" href="#__codelineno-0-210"></a>        <span class="n">avg_mean_eval</span> <span class="o">=</span> <span class="n">total_weighted_eval</span> <span class="o">/</span> <span class="n">total_num_solutions</span>
<a id="__codelineno-0-211" name="__codelineno-0-211" href="#__codelineno-0-211"></a>
<a id="__codelineno-0-212" name="__codelineno-0-212" href="#__codelineno-0-212"></a>        <span class="c1"># For each gradient (in most cases among &#39;mu&#39; and &#39;sigma&#39;), we allocate a new 0-filled tensor.</span>
<a id="__codelineno-0-213" name="__codelineno-0-213" href="#__codelineno-0-213"></a>        <span class="n">avg_gradients</span> <span class="o">=</span> <span class="p">{}</span>
<a id="__codelineno-0-214" name="__codelineno-0-214" href="#__codelineno-0-214"></a>        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">grad_keys</span><span class="p">:</span>
<a id="__codelineno-0-215" name="__codelineno-0-215" href="#__codelineno-0-215"></a>            <span class="n">avg_gradients</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribution</span><span class="o">.</span><span class="n">make_zeros</span><span class="p">(</span><span class="n">num_solutions</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-216" name="__codelineno-0-216" href="#__codelineno-0-216"></a>
<a id="__codelineno-0-217" name="__codelineno-0-217" href="#__codelineno-0-217"></a>        <span class="c1"># Below, we iterate over all collected results and add their gradients, in a weighted manner, onto the</span>
<a id="__codelineno-0-218" name="__codelineno-0-218" href="#__codelineno-0-218"></a>        <span class="c1"># `avg_gradients` we allocated above.</span>
<a id="__codelineno-0-219" name="__codelineno-0-219" href="#__codelineno-0-219"></a>        <span class="c1"># At the end, `avg_gradients` will store the weighted-averaged gradients to be followed by the algorithm.</span>
<a id="__codelineno-0-220" name="__codelineno-0-220" href="#__codelineno-0-220"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
<a id="__codelineno-0-221" name="__codelineno-0-221" href="#__codelineno-0-221"></a>            <span class="c1"># For each collected result, we compute a weight for the gradient, which is the number of solutions</span>
<a id="__codelineno-0-222" name="__codelineno-0-222" href="#__codelineno-0-222"></a>            <span class="c1"># sampled divided by the total number of sampled solutions.</span>
<a id="__codelineno-0-223" name="__codelineno-0-223" href="#__codelineno-0-223"></a>            <span class="n">num_solutions</span> <span class="o">=</span> <span class="n">list_of</span><span class="o">.</span><span class="n">num_solutions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<a id="__codelineno-0-224" name="__codelineno-0-224" href="#__codelineno-0-224"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_popsize_weighted_grad_avg</span><span class="p">:</span>
<a id="__codelineno-0-225" name="__codelineno-0-225" href="#__codelineno-0-225"></a>                <span class="c1"># If we are to weigh each gradient by its popsize (i.e. by its sample size)</span>
<a id="__codelineno-0-226" name="__codelineno-0-226" href="#__codelineno-0-226"></a>                <span class="c1"># then the its weight is computed as its number of solutions divided by the</span>
<a id="__codelineno-0-227" name="__codelineno-0-227" href="#__codelineno-0-227"></a>                <span class="c1"># total number of solutions</span>
<a id="__codelineno-0-228" name="__codelineno-0-228" href="#__codelineno-0-228"></a>                <span class="n">weight</span> <span class="o">=</span> <span class="n">num_solutions</span> <span class="o">/</span> <span class="n">total_num_solutions</span>
<a id="__codelineno-0-229" name="__codelineno-0-229" href="#__codelineno-0-229"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-230" name="__codelineno-0-230" href="#__codelineno-0-230"></a>                <span class="c1"># If we are NOT to weigh each gradient by its popsize (i.e. by its sample size)</span>
<a id="__codelineno-0-231" name="__codelineno-0-231" href="#__codelineno-0-231"></a>                <span class="c1"># then the weight of this gradient simply becomes 1 divided by the number of gradients.</span>
<a id="__codelineno-0-232" name="__codelineno-0-232" href="#__codelineno-0-232"></a>                <span class="n">weight</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">n</span>
<a id="__codelineno-0-233" name="__codelineno-0-233" href="#__codelineno-0-233"></a>            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">grad_keys</span><span class="p">:</span>
<a id="__codelineno-0-234" name="__codelineno-0-234" href="#__codelineno-0-234"></a>                <span class="n">grad</span> <span class="o">=</span> <span class="n">list_of</span><span class="o">.</span><span class="n">gradients</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">key</span><span class="p">]</span>
<a id="__codelineno-0-235" name="__codelineno-0-235" href="#__codelineno-0-235"></a>                <span class="n">avg_gradients</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+=</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">grad</span>
<a id="__codelineno-0-236" name="__codelineno-0-236" href="#__codelineno-0-236"></a>
<a id="__codelineno-0-237" name="__codelineno-0-237" href="#__codelineno-0-237"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_update_distribution</span><span class="p">(</span><span class="n">avg_gradients</span><span class="p">)</span>
<a id="__codelineno-0-238" name="__codelineno-0-238" href="#__codelineno-0-238"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_mean_eval</span> <span class="o">=</span> <span class="n">avg_mean_eval</span>
<a id="__codelineno-0-239" name="__codelineno-0-239" href="#__codelineno-0-239"></a>
<a id="__codelineno-0-240" name="__codelineno-0-240" href="#__codelineno-0-240"></a>    <span class="k">def</span> <span class="nf">_step_non_distributed</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-241" name="__codelineno-0-241" href="#__codelineno-0-241"></a>        <span class="c1"># First, we define an inner function which fills the current population by sampling from the distribution.</span>
<a id="__codelineno-0-242" name="__codelineno-0-242" href="#__codelineno-0-242"></a>        <span class="k">def</span> <span class="nf">fill_and_eval_pop</span><span class="p">():</span>
<a id="__codelineno-0-243" name="__codelineno-0-243" href="#__codelineno-0-243"></a>            <span class="c1"># This inner function is responsible for filling the main population with samples</span>
<a id="__codelineno-0-244" name="__codelineno-0-244" href="#__codelineno-0-244"></a>            <span class="c1"># and evaluate them.</span>
<a id="__codelineno-0-245" name="__codelineno-0-245" href="#__codelineno-0-245"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_interactions</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-246" name="__codelineno-0-246" href="#__codelineno-0-246"></a>                <span class="c1"># If num_interactions is configured as None, this means that we are not going to adapt</span>
<a id="__codelineno-0-247" name="__codelineno-0-247" href="#__codelineno-0-247"></a>                <span class="c1"># the population size according to the number of simulation interactions reported</span>
<a id="__codelineno-0-248" name="__codelineno-0-248" href="#__codelineno-0-248"></a>                <span class="c1"># by the problem object.</span>
<a id="__codelineno-0-249" name="__codelineno-0-249" href="#__codelineno-0-249"></a>
<a id="__codelineno-0-250" name="__codelineno-0-250" href="#__codelineno-0-250"></a>                <span class="c1"># We first make sure that the population (which is to be of constant size, since we are</span>
<a id="__codelineno-0-251" name="__codelineno-0-251" href="#__codelineno-0-251"></a>                <span class="c1"># not in the adaptive population size mode) is allocated.</span>
<a id="__codelineno-0-252" name="__codelineno-0-252" href="#__codelineno-0-252"></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_population</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-253" name="__codelineno-0-253" href="#__codelineno-0-253"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">_population</span> <span class="o">=</span> <span class="n">SolutionBatch</span><span class="p">(</span>
<a id="__codelineno-0-254" name="__codelineno-0-254" href="#__codelineno-0-254"></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">problem</span><span class="p">,</span> <span class="n">popsize</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_popsize</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">empty</span><span class="o">=</span><span class="kc">True</span>
<a id="__codelineno-0-255" name="__codelineno-0-255" href="#__codelineno-0-255"></a>                    <span class="p">)</span>
<a id="__codelineno-0-256" name="__codelineno-0-256" href="#__codelineno-0-256"></a>
<a id="__codelineno-0-257" name="__codelineno-0-257" href="#__codelineno-0-257"></a>                <span class="c1"># Now, we do in-place sampling on the population.</span>
<a id="__codelineno-0-258" name="__codelineno-0-258" href="#__codelineno-0-258"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">out</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_population</span><span class="o">.</span><span class="n">access_values</span><span class="p">(),</span> <span class="n">generator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">problem</span><span class="p">)</span>
<a id="__codelineno-0-259" name="__codelineno-0-259" href="#__codelineno-0-259"></a>
<a id="__codelineno-0-260" name="__codelineno-0-260" href="#__codelineno-0-260"></a>                <span class="c1"># Finally, here, the solutions are evaluated.</span>
<a id="__codelineno-0-261" name="__codelineno-0-261" href="#__codelineno-0-261"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">problem</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_population</span><span class="p">)</span>
<a id="__codelineno-0-262" name="__codelineno-0-262" href="#__codelineno-0-262"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-263" name="__codelineno-0-263" href="#__codelineno-0-263"></a>                <span class="c1"># If num_interactions is not None, then this means that we have a threshold for the number</span>
<a id="__codelineno-0-264" name="__codelineno-0-264" href="#__codelineno-0-264"></a>                <span class="c1"># of simulator interactions to reach before declaring the phase of sampling complete.</span>
<a id="__codelineno-0-265" name="__codelineno-0-265" href="#__codelineno-0-265"></a>                <span class="c1"># In other words, we have to adapt our population size according to the number of simulator</span>
<a id="__codelineno-0-266" name="__codelineno-0-266" href="#__codelineno-0-266"></a>                <span class="c1"># interactions reported by the problem object.</span>
<a id="__codelineno-0-267" name="__codelineno-0-267" href="#__codelineno-0-267"></a>
<a id="__codelineno-0-268" name="__codelineno-0-268" href="#__codelineno-0-268"></a>                <span class="c1"># The &#39;total_interaction_count&#39; status reported by the problem object shows the global interaction count.</span>
<a id="__codelineno-0-269" name="__codelineno-0-269" href="#__codelineno-0-269"></a>                <span class="c1"># Therefore, to properly count the simulator interactions we made during this generation, we need</span>
<a id="__codelineno-0-270" name="__codelineno-0-270" href="#__codelineno-0-270"></a>                <span class="c1"># to get the interaction count before starting our sampling and evaluation operations.</span>
<a id="__codelineno-0-271" name="__codelineno-0-271" href="#__codelineno-0-271"></a>                <span class="n">first_num_interactions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">problem</span><span class="o">.</span><span class="n">status</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;total_interaction_count&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-272" name="__codelineno-0-272" href="#__codelineno-0-272"></a>
<a id="__codelineno-0-273" name="__codelineno-0-273" href="#__codelineno-0-273"></a>                <span class="c1"># We will keep allocating and evaluating new populations until the interaction count threshold is reached.</span>
<a id="__codelineno-0-274" name="__codelineno-0-274" href="#__codelineno-0-274"></a>                <span class="c1"># These newly allocated populations will eventually concatenated into one.</span>
<a id="__codelineno-0-275" name="__codelineno-0-275" href="#__codelineno-0-275"></a>                <span class="c1"># The not-yet-concatenated populations and the total allocated population size will be stored below:</span>
<a id="__codelineno-0-276" name="__codelineno-0-276" href="#__codelineno-0-276"></a>                <span class="n">populations</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-277" name="__codelineno-0-277" href="#__codelineno-0-277"></a>                <span class="n">total_popsize</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-278" name="__codelineno-0-278" href="#__codelineno-0-278"></a>
<a id="__codelineno-0-279" name="__codelineno-0-279" href="#__codelineno-0-279"></a>                <span class="c1"># Below, we repeatedly allocate, sample, and evaluate, until our thresholds are reached.</span>
<a id="__codelineno-0-280" name="__codelineno-0-280" href="#__codelineno-0-280"></a>                <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
<a id="__codelineno-0-281" name="__codelineno-0-281" href="#__codelineno-0-281"></a>                    <span class="c1"># Allocate a new population</span>
<a id="__codelineno-0-282" name="__codelineno-0-282" href="#__codelineno-0-282"></a>                    <span class="n">newpop</span> <span class="o">=</span> <span class="n">SolutionBatch</span><span class="p">(</span>
<a id="__codelineno-0-283" name="__codelineno-0-283" href="#__codelineno-0-283"></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">problem</span><span class="p">,</span>
<a id="__codelineno-0-284" name="__codelineno-0-284" href="#__codelineno-0-284"></a>                        <span class="n">popsize</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_popsize</span><span class="p">,</span>
<a id="__codelineno-0-285" name="__codelineno-0-285" href="#__codelineno-0-285"></a>                        <span class="n">like</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_population</span><span class="p">,</span>
<a id="__codelineno-0-286" name="__codelineno-0-286" href="#__codelineno-0-286"></a>                        <span class="n">empty</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-287" name="__codelineno-0-287" href="#__codelineno-0-287"></a>                    <span class="p">)</span>
<a id="__codelineno-0-288" name="__codelineno-0-288" href="#__codelineno-0-288"></a>
<a id="__codelineno-0-289" name="__codelineno-0-289" href="#__codelineno-0-289"></a>                    <span class="c1"># Update the total population size</span>
<a id="__codelineno-0-290" name="__codelineno-0-290" href="#__codelineno-0-290"></a>                    <span class="n">total_popsize</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">newpop</span><span class="p">)</span>
<a id="__codelineno-0-291" name="__codelineno-0-291" href="#__codelineno-0-291"></a>
<a id="__codelineno-0-292" name="__codelineno-0-292" href="#__codelineno-0-292"></a>                    <span class="c1"># Sample new solutions within the newly allocated population</span>
<a id="__codelineno-0-293" name="__codelineno-0-293" href="#__codelineno-0-293"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">out</span><span class="o">=</span><span class="n">newpop</span><span class="o">.</span><span class="n">access_values</span><span class="p">(),</span> <span class="n">generator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">problem</span><span class="p">)</span>
<a id="__codelineno-0-294" name="__codelineno-0-294" href="#__codelineno-0-294"></a>
<a id="__codelineno-0-295" name="__codelineno-0-295" href="#__codelineno-0-295"></a>                    <span class="c1"># Evaluate the new population</span>
<a id="__codelineno-0-296" name="__codelineno-0-296" href="#__codelineno-0-296"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">problem</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">newpop</span><span class="p">)</span>
<a id="__codelineno-0-297" name="__codelineno-0-297" href="#__codelineno-0-297"></a>
<a id="__codelineno-0-298" name="__codelineno-0-298" href="#__codelineno-0-298"></a>                    <span class="c1"># Add the newly allocated and evaluated population into the populations list</span>
<a id="__codelineno-0-299" name="__codelineno-0-299" href="#__codelineno-0-299"></a>                    <span class="n">populations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">newpop</span><span class="p">)</span>
<a id="__codelineno-0-300" name="__codelineno-0-300" href="#__codelineno-0-300"></a>
<a id="__codelineno-0-301" name="__codelineno-0-301" href="#__codelineno-0-301"></a>                    <span class="c1"># In addition to the num_interactions threshold, we might also have a popsize_max threshold.</span>
<a id="__codelineno-0-302" name="__codelineno-0-302" href="#__codelineno-0-302"></a>                    <span class="c1"># We now check this threshold.</span>
<a id="__codelineno-0-303" name="__codelineno-0-303" href="#__codelineno-0-303"></a>                    <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_popsize_max</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">total_popsize</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_popsize_max</span><span class="p">):</span>
<a id="__codelineno-0-304" name="__codelineno-0-304" href="#__codelineno-0-304"></a>                        <span class="c1"># If the popsize_max threshold is reached, we leave the loop.</span>
<a id="__codelineno-0-305" name="__codelineno-0-305" href="#__codelineno-0-305"></a>                        <span class="k">break</span>
<a id="__codelineno-0-306" name="__codelineno-0-306" href="#__codelineno-0-306"></a>
<a id="__codelineno-0-307" name="__codelineno-0-307" href="#__codelineno-0-307"></a>                    <span class="c1"># We now compute the number of interactions we have made during this while loop.</span>
<a id="__codelineno-0-308" name="__codelineno-0-308" href="#__codelineno-0-308"></a>                    <span class="n">interactions_made</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">problem</span><span class="o">.</span><span class="n">status</span><span class="p">[</span><span class="s2">&quot;total_interaction_count&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">first_num_interactions</span>
<a id="__codelineno-0-309" name="__codelineno-0-309" href="#__codelineno-0-309"></a>
<a id="__codelineno-0-310" name="__codelineno-0-310" href="#__codelineno-0-310"></a>                    <span class="k">if</span> <span class="n">interactions_made</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_interactions</span><span class="p">:</span>
<a id="__codelineno-0-311" name="__codelineno-0-311" href="#__codelineno-0-311"></a>                        <span class="c1"># If the number of interactions exceeds our threshold, we leave the loop.</span>
<a id="__codelineno-0-312" name="__codelineno-0-312" href="#__codelineno-0-312"></a>                        <span class="k">break</span>
<a id="__codelineno-0-313" name="__codelineno-0-313" href="#__codelineno-0-313"></a>
<a id="__codelineno-0-314" name="__codelineno-0-314" href="#__codelineno-0-314"></a>                <span class="c1"># Finally, we concatenate all our populations into one.</span>
<a id="__codelineno-0-315" name="__codelineno-0-315" href="#__codelineno-0-315"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_population</span> <span class="o">=</span> <span class="n">SolutionBatch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">populations</span><span class="p">)</span>
<a id="__codelineno-0-316" name="__codelineno-0-316" href="#__codelineno-0-316"></a>
<a id="__codelineno-0-317" name="__codelineno-0-317" href="#__codelineno-0-317"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_first_iter</span><span class="p">:</span>
<a id="__codelineno-0-318" name="__codelineno-0-318" href="#__codelineno-0-318"></a>            <span class="c1"># If we are computing the first generation, we just sample from our distribution and evaluate</span>
<a id="__codelineno-0-319" name="__codelineno-0-319" href="#__codelineno-0-319"></a>            <span class="c1"># the solutions.</span>
<a id="__codelineno-0-320" name="__codelineno-0-320" href="#__codelineno-0-320"></a>            <span class="n">fill_and_eval_pop</span><span class="p">()</span>
<a id="__codelineno-0-321" name="__codelineno-0-321" href="#__codelineno-0-321"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_first_iter</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-322" name="__codelineno-0-322" href="#__codelineno-0-322"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-323" name="__codelineno-0-323" href="#__codelineno-0-323"></a>            <span class="c1"># If we are computing next generations, then we need to compute the gradients of the last</span>
<a id="__codelineno-0-324" name="__codelineno-0-324" href="#__codelineno-0-324"></a>            <span class="c1"># generation, sample a new population, and evaluate the new population&#39;s solutions.</span>
<a id="__codelineno-0-325" name="__codelineno-0-325" href="#__codelineno-0-325"></a>            <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_population</span><span class="o">.</span><span class="n">access_values</span><span class="p">(</span><span class="n">keep_evals</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-326" name="__codelineno-0-326" href="#__codelineno-0-326"></a>            <span class="n">fitnesses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_population</span><span class="o">.</span><span class="n">access_evals</span><span class="p">()[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_obj_index</span><span class="p">]</span>
<a id="__codelineno-0-327" name="__codelineno-0-327" href="#__codelineno-0-327"></a>            <span class="n">obj_sense</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">problem</span><span class="o">.</span><span class="n">senses</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_obj_index</span><span class="p">]</span>
<a id="__codelineno-0-328" name="__codelineno-0-328" href="#__codelineno-0-328"></a>            <span class="n">ranking_method</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ranking_method</span>
<a id="__codelineno-0-329" name="__codelineno-0-329" href="#__codelineno-0-329"></a>            <span class="n">gradients</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribution</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span>
<a id="__codelineno-0-330" name="__codelineno-0-330" href="#__codelineno-0-330"></a>                <span class="n">samples</span><span class="p">,</span> <span class="n">fitnesses</span><span class="p">,</span> <span class="n">objective_sense</span><span class="o">=</span><span class="n">obj_sense</span><span class="p">,</span> <span class="n">ranking_method</span><span class="o">=</span><span class="n">ranking_method</span>
<a id="__codelineno-0-331" name="__codelineno-0-331" href="#__codelineno-0-331"></a>            <span class="p">)</span>
<a id="__codelineno-0-332" name="__codelineno-0-332" href="#__codelineno-0-332"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_update_distribution</span><span class="p">(</span><span class="n">gradients</span><span class="p">)</span>
<a id="__codelineno-0-333" name="__codelineno-0-333" href="#__codelineno-0-333"></a>            <span class="n">fill_and_eval_pop</span><span class="p">()</span>
<a id="__codelineno-0-334" name="__codelineno-0-334" href="#__codelineno-0-334"></a>
<a id="__codelineno-0-335" name="__codelineno-0-335" href="#__codelineno-0-335"></a>    <span class="k">def</span> <span class="nf">_update_distribution</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
<a id="__codelineno-0-336" name="__codelineno-0-336" href="#__codelineno-0-336"></a>        <span class="c1"># This is where we follow the gradients with the help of the stored Distribution object.</span>
<a id="__codelineno-0-337" name="__codelineno-0-337" href="#__codelineno-0-337"></a>
<a id="__codelineno-0-338" name="__codelineno-0-338" href="#__codelineno-0-338"></a>        <span class="c1"># First, we check whether or not we will need to do a controlled update on the</span>
<a id="__codelineno-0-339" name="__codelineno-0-339" href="#__codelineno-0-339"></a>        <span class="c1"># standard deviation (do we have imposed lower and upper bounds for the standard deviation,</span>
<a id="__codelineno-0-340" name="__codelineno-0-340" href="#__codelineno-0-340"></a>        <span class="c1"># and do we have a maximum change limiter?)</span>
<a id="__codelineno-0-341" name="__codelineno-0-341" href="#__codelineno-0-341"></a>        <span class="n">controlled_stdev_update</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-342" name="__codelineno-0-342" href="#__codelineno-0-342"></a>            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stdev_min</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stdev_max</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stdev_max_change</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>
<a id="__codelineno-0-343" name="__codelineno-0-343" href="#__codelineno-0-343"></a>        <span class="p">)</span>
<a id="__codelineno-0-344" name="__codelineno-0-344" href="#__codelineno-0-344"></a>
<a id="__codelineno-0-345" name="__codelineno-0-345" href="#__codelineno-0-345"></a>        <span class="k">if</span> <span class="n">controlled_stdev_update</span><span class="p">:</span>
<a id="__codelineno-0-346" name="__codelineno-0-346" href="#__codelineno-0-346"></a>            <span class="c1"># If the standard deviation update needs to be controlled, we store the standard deviation just before</span>
<a id="__codelineno-0-347" name="__codelineno-0-347" href="#__codelineno-0-347"></a>            <span class="c1"># the update. We will use this later.</span>
<a id="__codelineno-0-348" name="__codelineno-0-348" href="#__codelineno-0-348"></a>            <span class="n">old_sigma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribution</span><span class="o">.</span><span class="n">sigma</span>
<a id="__codelineno-0-349" name="__codelineno-0-349" href="#__codelineno-0-349"></a>
<a id="__codelineno-0-350" name="__codelineno-0-350" href="#__codelineno-0-350"></a>        <span class="c1"># Here, we determine for which distribution parameter we have a learning rate and for which distribution</span>
<a id="__codelineno-0-351" name="__codelineno-0-351" href="#__codelineno-0-351"></a>        <span class="c1"># parameter we have an optimizer.</span>
<a id="__codelineno-0-352" name="__codelineno-0-352" href="#__codelineno-0-352"></a>        <span class="n">learning_rates</span> <span class="o">=</span> <span class="p">{}</span>
<a id="__codelineno-0-353" name="__codelineno-0-353" href="#__codelineno-0-353"></a>        <span class="n">optimizers</span> <span class="o">=</span> <span class="p">{}</span>
<a id="__codelineno-0-354" name="__codelineno-0-354" href="#__codelineno-0-354"></a>
<a id="__codelineno-0-355" name="__codelineno-0-355" href="#__codelineno-0-355"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-356" name="__codelineno-0-356" href="#__codelineno-0-356"></a>            <span class="c1"># If there is an optimizer, then we declare that &quot;mu&quot; has an optimizer</span>
<a id="__codelineno-0-357" name="__codelineno-0-357" href="#__codelineno-0-357"></a>            <span class="n">optimizers</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span>
<a id="__codelineno-0-358" name="__codelineno-0-358" href="#__codelineno-0-358"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-359" name="__codelineno-0-359" href="#__codelineno-0-359"></a>            <span class="c1"># If we do not have an optimizer, then we declare that &quot;mu&quot; has a raw learning rate coefficient</span>
<a id="__codelineno-0-360" name="__codelineno-0-360" href="#__codelineno-0-360"></a>            <span class="n">learning_rates</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_center_learning_rate</span>
<a id="__codelineno-0-361" name="__codelineno-0-361" href="#__codelineno-0-361"></a>
<a id="__codelineno-0-362" name="__codelineno-0-362" href="#__codelineno-0-362"></a>        <span class="c1"># Here, we declare that &quot;sigma&quot; has a learning rate</span>
<a id="__codelineno-0-363" name="__codelineno-0-363" href="#__codelineno-0-363"></a>        <span class="n">learning_rates</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stdev_learning_rate</span>
<a id="__codelineno-0-364" name="__codelineno-0-364" href="#__codelineno-0-364"></a>
<a id="__codelineno-0-365" name="__codelineno-0-365" href="#__codelineno-0-365"></a>        <span class="c1"># With the help of the Distribution object&#39;s `update_parameters(...)` method, we follow the gradients</span>
<a id="__codelineno-0-366" name="__codelineno-0-366" href="#__codelineno-0-366"></a>        <span class="n">updated_dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribution</span><span class="o">.</span><span class="n">update_parameters</span><span class="p">(</span>
<a id="__codelineno-0-367" name="__codelineno-0-367" href="#__codelineno-0-367"></a>            <span class="n">gradients</span><span class="p">,</span> <span class="n">learning_rates</span><span class="o">=</span><span class="n">learning_rates</span><span class="p">,</span> <span class="n">optimizers</span><span class="o">=</span><span class="n">optimizers</span>
<a id="__codelineno-0-368" name="__codelineno-0-368" href="#__codelineno-0-368"></a>        <span class="p">)</span>
<a id="__codelineno-0-369" name="__codelineno-0-369" href="#__codelineno-0-369"></a>
<a id="__codelineno-0-370" name="__codelineno-0-370" href="#__codelineno-0-370"></a>        <span class="k">if</span> <span class="n">controlled_stdev_update</span><span class="p">:</span>
<a id="__codelineno-0-371" name="__codelineno-0-371" href="#__codelineno-0-371"></a>            <span class="c1"># If our standard deviation update needs to be controlled, then, considering the pre-update</span>
<a id="__codelineno-0-372" name="__codelineno-0-372" href="#__codelineno-0-372"></a>            <span class="c1"># standard deviation, we ensure that the update constraints (lower and upper bounds and maximum change)</span>
<a id="__codelineno-0-373" name="__codelineno-0-373" href="#__codelineno-0-373"></a>            <span class="c1"># are not violated.</span>
<a id="__codelineno-0-374" name="__codelineno-0-374" href="#__codelineno-0-374"></a>            <span class="n">updated_dist</span> <span class="o">=</span> <span class="n">updated_dist</span><span class="o">.</span><span class="n">modified_copy</span><span class="p">(</span>
<a id="__codelineno-0-375" name="__codelineno-0-375" href="#__codelineno-0-375"></a>                <span class="n">sigma</span><span class="o">=</span><span class="n">modify_tensor</span><span class="p">(</span>
<a id="__codelineno-0-376" name="__codelineno-0-376" href="#__codelineno-0-376"></a>                    <span class="n">old_sigma</span><span class="p">,</span>
<a id="__codelineno-0-377" name="__codelineno-0-377" href="#__codelineno-0-377"></a>                    <span class="n">updated_dist</span><span class="o">.</span><span class="n">sigma</span><span class="p">,</span>
<a id="__codelineno-0-378" name="__codelineno-0-378" href="#__codelineno-0-378"></a>                    <span class="n">lb</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stdev_min</span><span class="p">,</span>
<a id="__codelineno-0-379" name="__codelineno-0-379" href="#__codelineno-0-379"></a>                    <span class="n">ub</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stdev_max</span><span class="p">,</span>
<a id="__codelineno-0-380" name="__codelineno-0-380" href="#__codelineno-0-380"></a>                    <span class="n">max_change</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stdev_max_change</span><span class="p">,</span>
<a id="__codelineno-0-381" name="__codelineno-0-381" href="#__codelineno-0-381"></a>                <span class="p">)</span>
<a id="__codelineno-0-382" name="__codelineno-0-382" href="#__codelineno-0-382"></a>            <span class="p">)</span>
<a id="__codelineno-0-383" name="__codelineno-0-383" href="#__codelineno-0-383"></a>
<a id="__codelineno-0-384" name="__codelineno-0-384" href="#__codelineno-0-384"></a>        <span class="c1"># Now we can declare that our main distribution is the updated one</span>
<a id="__codelineno-0-385" name="__codelineno-0-385" href="#__codelineno-0-385"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_distribution</span> <span class="o">=</span> <span class="n">updated_dist</span>
<a id="__codelineno-0-386" name="__codelineno-0-386" href="#__codelineno-0-386"></a>
<a id="__codelineno-0-387" name="__codelineno-0-387" href="#__codelineno-0-387"></a>    <span class="k">def</span> <span class="nf">_get_mu</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-388" name="__codelineno-0-388" href="#__codelineno-0-388"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribution</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">]</span>
<a id="__codelineno-0-389" name="__codelineno-0-389" href="#__codelineno-0-389"></a>
<a id="__codelineno-0-390" name="__codelineno-0-390" href="#__codelineno-0-390"></a>    <span class="k">def</span> <span class="nf">_get_sigma</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-391" name="__codelineno-0-391" href="#__codelineno-0-391"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribution</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">]</span>
<a id="__codelineno-0-392" name="__codelineno-0-392" href="#__codelineno-0-392"></a>
<a id="__codelineno-0-393" name="__codelineno-0-393" href="#__codelineno-0-393"></a>    <span class="k">def</span> <span class="nf">_get_mean_eval</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
<a id="__codelineno-0-394" name="__codelineno-0-394" href="#__codelineno-0-394"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_population</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-395" name="__codelineno-0-395" href="#__codelineno-0-395"></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mean_eval</span>
<a id="__codelineno-0-396" name="__codelineno-0-396" href="#__codelineno-0-396"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-397" name="__codelineno-0-397" href="#__codelineno-0-397"></a>            <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_population</span><span class="o">.</span><span class="n">evals</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_obj_index</span><span class="p">]))</span>
<a id="__codelineno-0-398" name="__codelineno-0-398" href="#__codelineno-0-398"></a>
<a id="__codelineno-0-399" name="__codelineno-0-399" href="#__codelineno-0-399"></a>    <span class="c1"># def _get_median_eval(self) -&gt; Optional[float]:</span>
<a id="__codelineno-0-400" name="__codelineno-0-400" href="#__codelineno-0-400"></a>    <span class="c1">#    if self._population is None:</span>
<a id="__codelineno-0-401" name="__codelineno-0-401" href="#__codelineno-0-401"></a>    <span class="c1">#        return None</span>
<a id="__codelineno-0-402" name="__codelineno-0-402" href="#__codelineno-0-402"></a>    <span class="c1">#    else:</span>
<a id="__codelineno-0-403" name="__codelineno-0-403" href="#__codelineno-0-403"></a>    <span class="c1">#        return float(torch.median(self._population.evals[:, self._obj_index]))</span>
<a id="__codelineno-0-404" name="__codelineno-0-404" href="#__codelineno-0-404"></a>
<a id="__codelineno-0-405" name="__codelineno-0-405" href="#__codelineno-0-405"></a>    <span class="k">def</span> <span class="nf">_get_popsize</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-406" name="__codelineno-0-406" href="#__codelineno-0-406"></a>        <span class="k">return</span> <span class="mi">0</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_population</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_population</span><span class="p">)</span>
<a id="__codelineno-0-407" name="__codelineno-0-407" href="#__codelineno-0-407"></a>
<a id="__codelineno-0-408" name="__codelineno-0-408" href="#__codelineno-0-408"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-409" name="__codelineno-0-409" href="#__codelineno-0-409"></a>    <span class="k">def</span> <span class="nf">population</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SolutionBatch</span><span class="p">]:</span>
<a id="__codelineno-0-410" name="__codelineno-0-410" href="#__codelineno-0-410"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-411" name="__codelineno-0-411" href="#__codelineno-0-411"></a><span class="sd">        The population, represented by a SolutionBatch.</span>
<a id="__codelineno-0-412" name="__codelineno-0-412" href="#__codelineno-0-412"></a>
<a id="__codelineno-0-413" name="__codelineno-0-413" href="#__codelineno-0-413"></a><span class="sd">        If the population is not initialized yet, the retrieved value will</span>
<a id="__codelineno-0-414" name="__codelineno-0-414" href="#__codelineno-0-414"></a><span class="sd">        be None.</span>
<a id="__codelineno-0-415" name="__codelineno-0-415" href="#__codelineno-0-415"></a><span class="sd">        Also note that, if this algorithm is in distributed mode, the</span>
<a id="__codelineno-0-416" name="__codelineno-0-416" href="#__codelineno-0-416"></a><span class="sd">        retrieved value will be None, since the distributed mode causes the</span>
<a id="__codelineno-0-417" name="__codelineno-0-417" href="#__codelineno-0-417"></a><span class="sd">        population to be generated in the remote actors, and not in the main</span>
<a id="__codelineno-0-418" name="__codelineno-0-418" href="#__codelineno-0-418"></a><span class="sd">        process.</span>
<a id="__codelineno-0-419" name="__codelineno-0-419" href="#__codelineno-0-419"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-420" name="__codelineno-0-420" href="#__codelineno-0-420"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_population</span>
<a id="__codelineno-0-421" name="__codelineno-0-421" href="#__codelineno-0-421"></a>
<a id="__codelineno-0-422" name="__codelineno-0-422" href="#__codelineno-0-422"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-423" name="__codelineno-0-423" href="#__codelineno-0-423"></a>    <span class="k">def</span> <span class="nf">obj_index</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-424" name="__codelineno-0-424" href="#__codelineno-0-424"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-425" name="__codelineno-0-425" href="#__codelineno-0-425"></a><span class="sd">        Index of the focused objective</span>
<a id="__codelineno-0-426" name="__codelineno-0-426" href="#__codelineno-0-426"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-427" name="__codelineno-0-427" href="#__codelineno-0-427"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_obj_index</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">








  <div class="doc doc-object doc-attribute">



<h3 id="evotorch.algorithms.distributed.gaussian.GaussianSearchAlgorithm.obj_index" class="doc doc-heading">
<code class="highlight language-python"><span class="n">obj_index</span><span class="p">:</span> <span class="nb">int</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

<a href="#evotorch.algorithms.distributed.gaussian.GaussianSearchAlgorithm.obj_index" class="headerlink" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p>Index of the focused objective</p>
    </div>

  </div>



  <div class="doc doc-object doc-attribute">



<h3 id="evotorch.algorithms.distributed.gaussian.GaussianSearchAlgorithm.population" class="doc doc-heading">
<code class="highlight language-python"><span class="n">population</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">evotorch</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">SolutionBatch</span><span class="p">]</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

<a href="#evotorch.algorithms.distributed.gaussian.GaussianSearchAlgorithm.population" class="headerlink" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p>The population, represented by a SolutionBatch.</p>
<p>If the population is not initialized yet, the retrieved value will
be None.
Also note that, if this algorithm is in distributed mode, the
retrieved value will be None, since the distributed mode causes the
population to be generated in the remote actors, and not in the main
process.</p>
    </div>

  </div>









  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h2 id="evotorch.algorithms.distributed.gaussian.PGPE" class="doc doc-heading">
        <code>
PGPE            (<a class="autorefs autorefs-internal" title="evotorch.algorithms.distributed.gaussian.GaussianSearchAlgorithm" href="#evotorch.algorithms.distributed.gaussian.GaussianSearchAlgorithm">GaussianSearchAlgorithm</a>)
        </code>



<a href="#evotorch.algorithms.distributed.gaussian.PGPE" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents ">

      <p>This implementation is the symmetric-sampling variant proposed
in the paper Sehnke et al. (2010).</p>
<p>Inspired by the PGPE implementations used in the studies
of Ha (2017, 2019), and by the evolution strategy variant of
Salimans et al. (2017), this PGPE implementation uses 0-centered
ranking by default.
The default optimizer for this PGPE implementation is ClipUp
(Toklu et al., 2020).</p>
<p>References:</p>
<div class="highlight"><pre><span></span><code>Frank Sehnke, Christian Osendorfer, Thomas Ruckstiess,
Alex Graves, Jan Peters, Jurgen Schmidhuber (2010).
Parameter-exploring Policy Gradients.
Neural Networks 23(4), 551-559.

David Ha (2017). Evolving Stable Strategies.
&lt;http://blog.otoro.net/2017/11/12/evolving-stable-strategies/&gt;

Salimans, T., Ho, J., Chen, X., Sidor, S. and Sutskever, I. (2017).
Evolution Strategies as a Scalable Alternative to
Reinforcement Learning.

David Ha (2019). Reinforcement Learning for Improving Agent Design.
Artificial life 25 (4), 352-365.

Toklu, N.E., Liskowski, P., Srivastava, R.K. (2020).
ClipUp: A Simple and Powerful Optimizer
for Distribution-based Policy Evolution.
Parallel Problem Solving from Nature (PPSN 2020).
</code></pre></div>

        <details class="quote">
          <summary>Source code in <code>evotorch/algorithms/distributed/gaussian.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">class</span> <span class="nc">PGPE</span><span class="p">(</span><span class="n">GaussianSearchAlgorithm</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="sd">    PGPE: Policy gradient with parameter-based exploration.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">    This implementation is the symmetric-sampling variant proposed</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">    in the paper Sehnke et al. (2010).</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="sd">    Inspired by the PGPE implementations used in the studies</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">    of Ha (2017, 2019), and by the evolution strategy variant of</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">    Salimans et al. (2017), this PGPE implementation uses 0-centered</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="sd">    ranking by default.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="sd">    The default optimizer for this PGPE implementation is ClipUp</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a><span class="sd">    (Toklu et al., 2020).</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a><span class="sd">    References:</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a><span class="sd">        Frank Sehnke, Christian Osendorfer, Thomas Ruckstiess,</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a><span class="sd">        Alex Graves, Jan Peters, Jurgen Schmidhuber (2010).</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a><span class="sd">        Parameter-exploring Policy Gradients.</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a><span class="sd">        Neural Networks 23(4), 551-559.</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a><span class="sd">        David Ha (2017). Evolving Stable Strategies.</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a><span class="sd">        &lt;http://blog.otoro.net/2017/11/12/evolving-stable-strategies/&gt;</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a><span class="sd">        Salimans, T., Ho, J., Chen, X., Sidor, S. and Sutskever, I. (2017).</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a><span class="sd">        Evolution Strategies as a Scalable Alternative to</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a><span class="sd">        Reinforcement Learning.</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a><span class="sd">        David Ha (2019). Reinforcement Learning for Improving Agent Design.</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a><span class="sd">        Artificial life 25 (4), 352-365.</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a><span class="sd">        Toklu, N.E., Liskowski, P., Srivastava, R.K. (2020).</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a><span class="sd">        ClipUp: A Simple and Powerful Optimizer</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a><span class="sd">        for Distribution-based Policy Evolution.</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a><span class="sd">        Parallel Problem Solving from Nature (PPSN 2020).</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>    <span class="n">DISTRIBUTION_TYPE</span> <span class="o">=</span> <span class="bp">NotImplemented</span>  <span class="c1"># To be filled by the PGPE instance</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a>    <span class="n">DISTRIBUTION_PARAMS</span> <span class="o">=</span> <span class="bp">NotImplemented</span>  <span class="c1"># To be filled by the PGPE instance</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a>        <span class="n">problem</span><span class="p">:</span> <span class="n">Problem</span><span class="p">,</span>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a>        <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a>        <span class="n">popsize</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a>        <span class="n">center_learning_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a>        <span class="n">stdev_learning_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a>        <span class="n">stdev_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a>        <span class="n">radius_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a>        <span class="n">num_interactions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a>        <span class="n">popsize_max</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a>        <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;clipup&quot;</span><span class="p">,</span>
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a>        <span class="n">optimizer_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a>        <span class="n">ranking_method</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;centered&quot;</span><span class="p">,</span>
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a>        <span class="n">center_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a>        <span class="n">stdev_min</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a>        <span class="n">stdev_max</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a>        <span class="n">stdev_max_change</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a>        <span class="n">symmetric</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a>        <span class="n">obj_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a>        <span class="n">distributed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#__codelineno-0-62"></a>        <span class="n">popsize_weighted_grad_avg</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#__codelineno-0-63"></a>    <span class="p">):</span>
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#__codelineno-0-64"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#__codelineno-0-65"></a><span class="sd">        `__init__(...)`: Initialize the PGPE algorithm.</span>
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#__codelineno-0-66"></a>
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#__codelineno-0-67"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#__codelineno-0-68"></a><span class="sd">            problem: The problem object which is being worked on.</span>
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#__codelineno-0-69"></a><span class="sd">                The problem must have its dtype defined</span>
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#__codelineno-0-70"></a><span class="sd">                (which means it works on Solution objects,</span>
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#__codelineno-0-71"></a><span class="sd">                not with custom Solution objects).</span>
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#__codelineno-0-72"></a><span class="sd">                Also, the problem must be single-objective.</span>
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#__codelineno-0-73"></a><span class="sd">            popsize: The population size.</span>
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#__codelineno-0-74"></a><span class="sd">                In the case of PGPE, `popsize` is expected as an even number</span>
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#__codelineno-0-75"></a><span class="sd">                in non-distributed mode. In distributed mode, PGPE will</span>
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#__codelineno-0-76"></a><span class="sd">                ensure that each sub-population size assigned to a remote</span>
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#__codelineno-0-77"></a><span class="sd">                actor is an even number.</span>
<a id="__codelineno-0-78" name="__codelineno-0-78" href="#__codelineno-0-78"></a><span class="sd">                This behavior is because PGPE does symmetric sampling</span>
<a id="__codelineno-0-79" name="__codelineno-0-79" href="#__codelineno-0-79"></a><span class="sd">                (i.e. solutions are sampled in pairs).</span>
<a id="__codelineno-0-80" name="__codelineno-0-80" href="#__codelineno-0-80"></a><span class="sd">            center_learning_rate: The learning rate for the center</span>
<a id="__codelineno-0-81" name="__codelineno-0-81" href="#__codelineno-0-81"></a><span class="sd">                of the search distribution.</span>
<a id="__codelineno-0-82" name="__codelineno-0-82" href="#__codelineno-0-82"></a><span class="sd">            stdev_learning_rate: The learning rate for the standard</span>
<a id="__codelineno-0-83" name="__codelineno-0-83" href="#__codelineno-0-83"></a><span class="sd">                deviation values of the search distribution.</span>
<a id="__codelineno-0-84" name="__codelineno-0-84" href="#__codelineno-0-84"></a><span class="sd">            stdev_init: The initial standard deviation of the search</span>
<a id="__codelineno-0-85" name="__codelineno-0-85" href="#__codelineno-0-85"></a><span class="sd">                distribution, expressed as a scalar or as an array.</span>
<a id="__codelineno-0-86" name="__codelineno-0-86" href="#__codelineno-0-86"></a><span class="sd">                Determines the initial coverage area of the search</span>
<a id="__codelineno-0-87" name="__codelineno-0-87" href="#__codelineno-0-87"></a><span class="sd">                distribution.</span>
<a id="__codelineno-0-88" name="__codelineno-0-88" href="#__codelineno-0-88"></a><span class="sd">                If one wishes to configure the coverage area via the</span>
<a id="__codelineno-0-89" name="__codelineno-0-89" href="#__codelineno-0-89"></a><span class="sd">                argument `radius_init` instead, then `stdev_init` is expected</span>
<a id="__codelineno-0-90" name="__codelineno-0-90" href="#__codelineno-0-90"></a><span class="sd">                as None.</span>
<a id="__codelineno-0-91" name="__codelineno-0-91" href="#__codelineno-0-91"></a><span class="sd">            radius_init: The initial radius of the search distribution,</span>
<a id="__codelineno-0-92" name="__codelineno-0-92" href="#__codelineno-0-92"></a><span class="sd">                expressed as a scalar.</span>
<a id="__codelineno-0-93" name="__codelineno-0-93" href="#__codelineno-0-93"></a><span class="sd">                Determines the initial coverage area of the search</span>
<a id="__codelineno-0-94" name="__codelineno-0-94" href="#__codelineno-0-94"></a><span class="sd">                distribution.</span>
<a id="__codelineno-0-95" name="__codelineno-0-95" href="#__codelineno-0-95"></a><span class="sd">                Here, &quot;radius&quot; is defined as the norm of the search</span>
<a id="__codelineno-0-96" name="__codelineno-0-96" href="#__codelineno-0-96"></a><span class="sd">                distribution.</span>
<a id="__codelineno-0-97" name="__codelineno-0-97" href="#__codelineno-0-97"></a><span class="sd">                If one wishes to configure the coverage area via the</span>
<a id="__codelineno-0-98" name="__codelineno-0-98" href="#__codelineno-0-98"></a><span class="sd">                argument `stdev_init` instead, then `radius_init` is expected</span>
<a id="__codelineno-0-99" name="__codelineno-0-99" href="#__codelineno-0-99"></a><span class="sd">                as None.</span>
<a id="__codelineno-0-100" name="__codelineno-0-100" href="#__codelineno-0-100"></a><span class="sd">            num_interactions: When given as an integer n,</span>
<a id="__codelineno-0-101" name="__codelineno-0-101" href="#__codelineno-0-101"></a><span class="sd">                it is ensured that a population has interacted with</span>
<a id="__codelineno-0-102" name="__codelineno-0-102" href="#__codelineno-0-102"></a><span class="sd">                the GymProblem&#39;s environment n times. If this target</span>
<a id="__codelineno-0-103" name="__codelineno-0-103" href="#__codelineno-0-103"></a><span class="sd">                has not been reached yet, then the population is declared</span>
<a id="__codelineno-0-104" name="__codelineno-0-104" href="#__codelineno-0-104"></a><span class="sd">                too small, and gets extended with more samples,</span>
<a id="__codelineno-0-105" name="__codelineno-0-105" href="#__codelineno-0-105"></a><span class="sd">                until n amount of interactions is reached.</span>
<a id="__codelineno-0-106" name="__codelineno-0-106" href="#__codelineno-0-106"></a><span class="sd">                When given as None, popsize is the only configuration</span>
<a id="__codelineno-0-107" name="__codelineno-0-107" href="#__codelineno-0-107"></a><span class="sd">                affecting the size of a population.</span>
<a id="__codelineno-0-108" name="__codelineno-0-108" href="#__codelineno-0-108"></a><span class="sd">            popsize_max: Having `num_interactions` set as an integer</span>
<a id="__codelineno-0-109" name="__codelineno-0-109" href="#__codelineno-0-109"></a><span class="sd">                might cause the effective population size jump to</span>
<a id="__codelineno-0-110" name="__codelineno-0-110" href="#__codelineno-0-110"></a><span class="sd">                unnecesarily large numbers. To prevent this,</span>
<a id="__codelineno-0-111" name="__codelineno-0-111" href="#__codelineno-0-111"></a><span class="sd">                one can set `popsize_max` to specify an upper</span>
<a id="__codelineno-0-112" name="__codelineno-0-112" href="#__codelineno-0-112"></a><span class="sd">                bound for the effective population size.</span>
<a id="__codelineno-0-113" name="__codelineno-0-113" href="#__codelineno-0-113"></a><span class="sd">            optimizer: The optimizer to be used while following the</span>
<a id="__codelineno-0-114" name="__codelineno-0-114" href="#__codelineno-0-114"></a><span class="sd">                estimated the gradients.</span>
<a id="__codelineno-0-115" name="__codelineno-0-115" href="#__codelineno-0-115"></a><span class="sd">                Can be given as None if a momentum-based optimizer</span>
<a id="__codelineno-0-116" name="__codelineno-0-116" href="#__codelineno-0-116"></a><span class="sd">                is not required.</span>
<a id="__codelineno-0-117" name="__codelineno-0-117" href="#__codelineno-0-117"></a><span class="sd">                Otherwise, can be given as a str containing the name</span>
<a id="__codelineno-0-118" name="__codelineno-0-118" href="#__codelineno-0-118"></a><span class="sd">                of the optimizer (e.g. &#39;adam&#39;, &#39;clipup&#39;);</span>
<a id="__codelineno-0-119" name="__codelineno-0-119" href="#__codelineno-0-119"></a><span class="sd">                or as an instance of evotorch.optimizers.TorchOptimizer</span>
<a id="__codelineno-0-120" name="__codelineno-0-120" href="#__codelineno-0-120"></a><span class="sd">                or evotorch.optimizers.ClipUp.</span>
<a id="__codelineno-0-121" name="__codelineno-0-121" href="#__codelineno-0-121"></a><span class="sd">                The default is &#39;clipup&#39;.</span>
<a id="__codelineno-0-122" name="__codelineno-0-122" href="#__codelineno-0-122"></a><span class="sd">                Note that, for ClipUp, the default maximum speed is set</span>
<a id="__codelineno-0-123" name="__codelineno-0-123" href="#__codelineno-0-123"></a><span class="sd">                as twice the given `center_learning_rate`.</span>
<a id="__codelineno-0-124" name="__codelineno-0-124" href="#__codelineno-0-124"></a><span class="sd">                This maximum speed can be configured by passing</span>
<a id="__codelineno-0-125" name="__codelineno-0-125" href="#__codelineno-0-125"></a><span class="sd">                `{&quot;max_speed&quot;: ...}` to `optimizer_config`.</span>
<a id="__codelineno-0-126" name="__codelineno-0-126" href="#__codelineno-0-126"></a><span class="sd">            optimizer_config: Configuration which will be passed</span>
<a id="__codelineno-0-127" name="__codelineno-0-127" href="#__codelineno-0-127"></a><span class="sd">                to the optimizer as keyword arguments.</span>
<a id="__codelineno-0-128" name="__codelineno-0-128" href="#__codelineno-0-128"></a><span class="sd">                See `evotorch.optimizers` for details about</span>
<a id="__codelineno-0-129" name="__codelineno-0-129" href="#__codelineno-0-129"></a><span class="sd">                which optimizer accepts which keyword arguments.</span>
<a id="__codelineno-0-130" name="__codelineno-0-130" href="#__codelineno-0-130"></a><span class="sd">            ranking_method: Which ranking method will be used for</span>
<a id="__codelineno-0-131" name="__codelineno-0-131" href="#__codelineno-0-131"></a><span class="sd">                fitness shaping. See the documentation of</span>
<a id="__codelineno-0-132" name="__codelineno-0-132" href="#__codelineno-0-132"></a><span class="sd">                `evotorch.ranking.rank(...)` for details.</span>
<a id="__codelineno-0-133" name="__codelineno-0-133" href="#__codelineno-0-133"></a><span class="sd">                As in the study of Salimans et al. (2017),</span>
<a id="__codelineno-0-134" name="__codelineno-0-134" href="#__codelineno-0-134"></a><span class="sd">                the default is &#39;centered&#39;.</span>
<a id="__codelineno-0-135" name="__codelineno-0-135" href="#__codelineno-0-135"></a><span class="sd">                Can be given as None if no such ranking is required.</span>
<a id="__codelineno-0-136" name="__codelineno-0-136" href="#__codelineno-0-136"></a><span class="sd">            center_init: The initial center solution.</span>
<a id="__codelineno-0-137" name="__codelineno-0-137" href="#__codelineno-0-137"></a><span class="sd">                Can be left as None.</span>
<a id="__codelineno-0-138" name="__codelineno-0-138" href="#__codelineno-0-138"></a><span class="sd">            stdev_min: Lower bound for the standard deviation value/array.</span>
<a id="__codelineno-0-139" name="__codelineno-0-139" href="#__codelineno-0-139"></a><span class="sd">                Can be given as a real number, or as an array of real numbers.</span>
<a id="__codelineno-0-140" name="__codelineno-0-140" href="#__codelineno-0-140"></a><span class="sd">            stdev_max: Upper bound for the standard deviation value/array.</span>
<a id="__codelineno-0-141" name="__codelineno-0-141" href="#__codelineno-0-141"></a><span class="sd">                Can be given as a real number, or as an array of real numbers.</span>
<a id="__codelineno-0-142" name="__codelineno-0-142" href="#__codelineno-0-142"></a><span class="sd">            stdev_max_change: The maximum update ratio allowed on the</span>
<a id="__codelineno-0-143" name="__codelineno-0-143" href="#__codelineno-0-143"></a><span class="sd">                standard deviation. Expected as None if no such limiter</span>
<a id="__codelineno-0-144" name="__codelineno-0-144" href="#__codelineno-0-144"></a><span class="sd">                is needed, or as a real number within 0.0 and 1.0 otherwise.</span>
<a id="__codelineno-0-145" name="__codelineno-0-145" href="#__codelineno-0-145"></a><span class="sd">                Like in the implementation of Ha (2017, 2018),</span>
<a id="__codelineno-0-146" name="__codelineno-0-146" href="#__codelineno-0-146"></a><span class="sd">                the default value for this setting is 0.2, meaning that</span>
<a id="__codelineno-0-147" name="__codelineno-0-147" href="#__codelineno-0-147"></a><span class="sd">                the update on the standard deviation values can not be</span>
<a id="__codelineno-0-148" name="__codelineno-0-148" href="#__codelineno-0-148"></a><span class="sd">                more than 20% of their original values.</span>
<a id="__codelineno-0-149" name="__codelineno-0-149" href="#__codelineno-0-149"></a><span class="sd">            symmetric: Whether or not the solutions will be sampled</span>
<a id="__codelineno-0-150" name="__codelineno-0-150" href="#__codelineno-0-150"></a><span class="sd">                in a symmetric/mirrored/antithetic manner.</span>
<a id="__codelineno-0-151" name="__codelineno-0-151" href="#__codelineno-0-151"></a><span class="sd">                The default is True.</span>
<a id="__codelineno-0-152" name="__codelineno-0-152" href="#__codelineno-0-152"></a><span class="sd">            obj_index: Index of the objective according to which the</span>
<a id="__codelineno-0-153" name="__codelineno-0-153" href="#__codelineno-0-153"></a><span class="sd">                gradient estimations will be done.</span>
<a id="__codelineno-0-154" name="__codelineno-0-154" href="#__codelineno-0-154"></a><span class="sd">                For single-objective problems, this can be left as None.</span>
<a id="__codelineno-0-155" name="__codelineno-0-155" href="#__codelineno-0-155"></a><span class="sd">            distributed: Whether or not the gradient computation will</span>
<a id="__codelineno-0-156" name="__codelineno-0-156" href="#__codelineno-0-156"></a><span class="sd">                be distributed. If `distributed` is given as False and</span>
<a id="__codelineno-0-157" name="__codelineno-0-157" href="#__codelineno-0-157"></a><span class="sd">                the problem is not parallelized, then everything will</span>
<a id="__codelineno-0-158" name="__codelineno-0-158" href="#__codelineno-0-158"></a><span class="sd">                be centralized (i.e. the entire computation will happen</span>
<a id="__codelineno-0-159" name="__codelineno-0-159" href="#__codelineno-0-159"></a><span class="sd">                in the main process).</span>
<a id="__codelineno-0-160" name="__codelineno-0-160" href="#__codelineno-0-160"></a><span class="sd">                If `distributed` is given as False, and the problem</span>
<a id="__codelineno-0-161" name="__codelineno-0-161" href="#__codelineno-0-161"></a><span class="sd">                is parallelized, then the population will be created</span>
<a id="__codelineno-0-162" name="__codelineno-0-162" href="#__codelineno-0-162"></a><span class="sd">                in the main process and then sent to remote workers</span>
<a id="__codelineno-0-163" name="__codelineno-0-163" href="#__codelineno-0-163"></a><span class="sd">                for parallelized evaluation, and then the remote fitnesses</span>
<a id="__codelineno-0-164" name="__codelineno-0-164" href="#__codelineno-0-164"></a><span class="sd">                will be collected by the main process again for computing</span>
<a id="__codelineno-0-165" name="__codelineno-0-165" href="#__codelineno-0-165"></a><span class="sd">                the search gradients.</span>
<a id="__codelineno-0-166" name="__codelineno-0-166" href="#__codelineno-0-166"></a><span class="sd">                If `distributed` is given as True, and the problem</span>
<a id="__codelineno-0-167" name="__codelineno-0-167" href="#__codelineno-0-167"></a><span class="sd">                is parallelized, then the search algorithm itself will</span>
<a id="__codelineno-0-168" name="__codelineno-0-168" href="#__codelineno-0-168"></a><span class="sd">                be distributed, in the sense that each remote actor will</span>
<a id="__codelineno-0-169" name="__codelineno-0-169" href="#__codelineno-0-169"></a><span class="sd">                generate its own population (such that the total population</span>
<a id="__codelineno-0-170" name="__codelineno-0-170" href="#__codelineno-0-170"></a><span class="sd">                size across all these actors becomes equal to `popsize`)</span>
<a id="__codelineno-0-171" name="__codelineno-0-171" href="#__codelineno-0-171"></a><span class="sd">                and will compute its own gradient, and then the main process</span>
<a id="__codelineno-0-172" name="__codelineno-0-172" href="#__codelineno-0-172"></a><span class="sd">                will collect these gradients, compute the averaged gradients</span>
<a id="__codelineno-0-173" name="__codelineno-0-173" href="#__codelineno-0-173"></a><span class="sd">                and update the main search distribution.</span>
<a id="__codelineno-0-174" name="__codelineno-0-174" href="#__codelineno-0-174"></a><span class="sd">                Non-distributed mode has the advantage of keeping the</span>
<a id="__codelineno-0-175" name="__codelineno-0-175" href="#__codelineno-0-175"></a><span class="sd">                population in the main process, which is good when one wishes</span>
<a id="__codelineno-0-176" name="__codelineno-0-176" href="#__codelineno-0-176"></a><span class="sd">                to do detailed monitoring during the evolutionary process,</span>
<a id="__codelineno-0-177" name="__codelineno-0-177" href="#__codelineno-0-177"></a><span class="sd">                but has the disadvantage of having to pass the solutions to</span>
<a id="__codelineno-0-178" name="__codelineno-0-178" href="#__codelineno-0-178"></a><span class="sd">                the remote actors and having to collect fitnesses, which</span>
<a id="__codelineno-0-179" name="__codelineno-0-179" href="#__codelineno-0-179"></a><span class="sd">                might result in increased interprocess communication traffic.</span>
<a id="__codelineno-0-180" name="__codelineno-0-180" href="#__codelineno-0-180"></a><span class="sd">                On the other hand, while it is not possible to monitor the</span>
<a id="__codelineno-0-181" name="__codelineno-0-181" href="#__codelineno-0-181"></a><span class="sd">                population in distributed mode, the distributed mode has the</span>
<a id="__codelineno-0-182" name="__codelineno-0-182" href="#__codelineno-0-182"></a><span class="sd">                advantage of significantly reducing the interprocess</span>
<a id="__codelineno-0-183" name="__codelineno-0-183" href="#__codelineno-0-183"></a><span class="sd">                communication traffic, since the only things communicated</span>
<a id="__codelineno-0-184" name="__codelineno-0-184" href="#__codelineno-0-184"></a><span class="sd">                with the remote actors are the search distributions (not the</span>
<a id="__codelineno-0-185" name="__codelineno-0-185" href="#__codelineno-0-185"></a><span class="sd">                solutions) and the gradients.</span>
<a id="__codelineno-0-186" name="__codelineno-0-186" href="#__codelineno-0-186"></a><span class="sd">            popsize_weighted_grad_avg: Only to be used in distributed mode.</span>
<a id="__codelineno-0-187" name="__codelineno-0-187" href="#__codelineno-0-187"></a><span class="sd">                (where being in distributed mode means `distributed` is given</span>
<a id="__codelineno-0-188" name="__codelineno-0-188" href="#__codelineno-0-188"></a><span class="sd">                as True). In distributed mode, each actor remotely samples</span>
<a id="__codelineno-0-189" name="__codelineno-0-189" href="#__codelineno-0-189"></a><span class="sd">                its own solution batches and computes its own gradients.</span>
<a id="__codelineno-0-190" name="__codelineno-0-190" href="#__codelineno-0-190"></a><span class="sd">                These gradients are then collected, and a final average</span>
<a id="__codelineno-0-191" name="__codelineno-0-191" href="#__codelineno-0-191"></a><span class="sd">                gradient is computed.</span>
<a id="__codelineno-0-192" name="__codelineno-0-192" href="#__codelineno-0-192"></a><span class="sd">                If `popsize_weighted_grad_avg` is True, then, while averaging</span>
<a id="__codelineno-0-193" name="__codelineno-0-193" href="#__codelineno-0-193"></a><span class="sd">                over the gradients, each gradient will have its own weight</span>
<a id="__codelineno-0-194" name="__codelineno-0-194" href="#__codelineno-0-194"></a><span class="sd">                that is computed according to how many solutions were sampled</span>
<a id="__codelineno-0-195" name="__codelineno-0-195" href="#__codelineno-0-195"></a><span class="sd">                by the actor that produced the gradient.</span>
<a id="__codelineno-0-196" name="__codelineno-0-196" href="#__codelineno-0-196"></a><span class="sd">                If `popsize_weighted_grad_avg` is False, then, there will not</span>
<a id="__codelineno-0-197" name="__codelineno-0-197" href="#__codelineno-0-197"></a><span class="sd">                be weighted averaging (or, each gradient will have equal</span>
<a id="__codelineno-0-198" name="__codelineno-0-198" href="#__codelineno-0-198"></a><span class="sd">                weight).</span>
<a id="__codelineno-0-199" name="__codelineno-0-199" href="#__codelineno-0-199"></a><span class="sd">                If `popsize_weighted_grad_avg` is None, then, the gradient</span>
<a id="__codelineno-0-200" name="__codelineno-0-200" href="#__codelineno-0-200"></a><span class="sd">                weights will be equal a value for `num_interactions` is given</span>
<a id="__codelineno-0-201" name="__codelineno-0-201" href="#__codelineno-0-201"></a><span class="sd">                (because `num_interactions` affects the number of solutions</span>
<a id="__codelineno-0-202" name="__codelineno-0-202" href="#__codelineno-0-202"></a><span class="sd">                according to the episode lengths, and popsize-weighting the</span>
<a id="__codelineno-0-203" name="__codelineno-0-203" href="#__codelineno-0-203"></a><span class="sd">                gradients could be misleading); and the gradient weights will</span>
<a id="__codelineno-0-204" name="__codelineno-0-204" href="#__codelineno-0-204"></a><span class="sd">                be weighted according to the sub-population (i.e. sub-batch)</span>
<a id="__codelineno-0-205" name="__codelineno-0-205" href="#__codelineno-0-205"></a><span class="sd">                sizes if `num_interactions` is left as None.</span>
<a id="__codelineno-0-206" name="__codelineno-0-206" href="#__codelineno-0-206"></a><span class="sd">                The default value for `popsize_weighted_grad_avg` is None.</span>
<a id="__codelineno-0-207" name="__codelineno-0-207" href="#__codelineno-0-207"></a><span class="sd">                When the distributed mode is disabled (i.e. when `distributed`</span>
<a id="__codelineno-0-208" name="__codelineno-0-208" href="#__codelineno-0-208"></a><span class="sd">                is False), then the argument `popsize_weighted_grad_avg` is</span>
<a id="__codelineno-0-209" name="__codelineno-0-209" href="#__codelineno-0-209"></a><span class="sd">                expected as None.</span>
<a id="__codelineno-0-210" name="__codelineno-0-210" href="#__codelineno-0-210"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-211" name="__codelineno-0-211" href="#__codelineno-0-211"></a>
<a id="__codelineno-0-212" name="__codelineno-0-212" href="#__codelineno-0-212"></a>        <span class="k">if</span> <span class="n">symmetric</span><span class="p">:</span>
<a id="__codelineno-0-213" name="__codelineno-0-213" href="#__codelineno-0-213"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">DISTRIBUTION_TYPE</span> <span class="o">=</span> <span class="n">SymmetricSeparableGaussian</span>
<a id="__codelineno-0-214" name="__codelineno-0-214" href="#__codelineno-0-214"></a>            <span class="n">divide_by</span> <span class="o">=</span> <span class="s2">&quot;num_directions&quot;</span>
<a id="__codelineno-0-215" name="__codelineno-0-215" href="#__codelineno-0-215"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-216" name="__codelineno-0-216" href="#__codelineno-0-216"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">DISTRIBUTION_TYPE</span> <span class="o">=</span> <span class="n">SeparableGaussian</span>
<a id="__codelineno-0-217" name="__codelineno-0-217" href="#__codelineno-0-217"></a>            <span class="n">divide_by</span> <span class="o">=</span> <span class="s2">&quot;num_solutions&quot;</span>
<a id="__codelineno-0-218" name="__codelineno-0-218" href="#__codelineno-0-218"></a>
<a id="__codelineno-0-219" name="__codelineno-0-219" href="#__codelineno-0-219"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">DISTRIBUTION_PARAMS</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;divide_mu_grad_by&quot;</span><span class="p">:</span> <span class="n">divide_by</span><span class="p">,</span> <span class="s2">&quot;divide_sigma_grad_by&quot;</span><span class="p">:</span> <span class="n">divide_by</span><span class="p">}</span>
<a id="__codelineno-0-220" name="__codelineno-0-220" href="#__codelineno-0-220"></a>
<a id="__codelineno-0-221" name="__codelineno-0-221" href="#__codelineno-0-221"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-222" name="__codelineno-0-222" href="#__codelineno-0-222"></a>            <span class="n">problem</span><span class="p">,</span>
<a id="__codelineno-0-223" name="__codelineno-0-223" href="#__codelineno-0-223"></a>            <span class="n">popsize</span><span class="o">=</span><span class="n">popsize</span><span class="p">,</span>
<a id="__codelineno-0-224" name="__codelineno-0-224" href="#__codelineno-0-224"></a>            <span class="n">center_learning_rate</span><span class="o">=</span><span class="n">center_learning_rate</span><span class="p">,</span>
<a id="__codelineno-0-225" name="__codelineno-0-225" href="#__codelineno-0-225"></a>            <span class="n">stdev_learning_rate</span><span class="o">=</span><span class="n">stdev_learning_rate</span><span class="p">,</span>
<a id="__codelineno-0-226" name="__codelineno-0-226" href="#__codelineno-0-226"></a>            <span class="n">stdev_init</span><span class="o">=</span><span class="n">stdev_init</span><span class="p">,</span>
<a id="__codelineno-0-227" name="__codelineno-0-227" href="#__codelineno-0-227"></a>            <span class="n">radius_init</span><span class="o">=</span><span class="n">radius_init</span><span class="p">,</span>
<a id="__codelineno-0-228" name="__codelineno-0-228" href="#__codelineno-0-228"></a>            <span class="n">popsize_max</span><span class="o">=</span><span class="n">popsize_max</span><span class="p">,</span>
<a id="__codelineno-0-229" name="__codelineno-0-229" href="#__codelineno-0-229"></a>            <span class="n">num_interactions</span><span class="o">=</span><span class="n">num_interactions</span><span class="p">,</span>
<a id="__codelineno-0-230" name="__codelineno-0-230" href="#__codelineno-0-230"></a>            <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
<a id="__codelineno-0-231" name="__codelineno-0-231" href="#__codelineno-0-231"></a>            <span class="n">optimizer_config</span><span class="o">=</span><span class="n">optimizer_config</span><span class="p">,</span>
<a id="__codelineno-0-232" name="__codelineno-0-232" href="#__codelineno-0-232"></a>            <span class="n">ranking_method</span><span class="o">=</span><span class="n">ranking_method</span><span class="p">,</span>
<a id="__codelineno-0-233" name="__codelineno-0-233" href="#__codelineno-0-233"></a>            <span class="n">center_init</span><span class="o">=</span><span class="n">center_init</span><span class="p">,</span>
<a id="__codelineno-0-234" name="__codelineno-0-234" href="#__codelineno-0-234"></a>            <span class="n">stdev_min</span><span class="o">=</span><span class="n">stdev_min</span><span class="p">,</span>
<a id="__codelineno-0-235" name="__codelineno-0-235" href="#__codelineno-0-235"></a>            <span class="n">stdev_max</span><span class="o">=</span><span class="n">stdev_max</span><span class="p">,</span>
<a id="__codelineno-0-236" name="__codelineno-0-236" href="#__codelineno-0-236"></a>            <span class="n">stdev_max_change</span><span class="o">=</span><span class="n">stdev_max_change</span><span class="p">,</span>
<a id="__codelineno-0-237" name="__codelineno-0-237" href="#__codelineno-0-237"></a>            <span class="n">obj_index</span><span class="o">=</span><span class="n">obj_index</span><span class="p">,</span>
<a id="__codelineno-0-238" name="__codelineno-0-238" href="#__codelineno-0-238"></a>            <span class="n">distributed</span><span class="o">=</span><span class="n">distributed</span><span class="p">,</span>
<a id="__codelineno-0-239" name="__codelineno-0-239" href="#__codelineno-0-239"></a>            <span class="n">popsize_weighted_grad_avg</span><span class="o">=</span><span class="n">popsize_weighted_grad_avg</span><span class="p">,</span>
<a id="__codelineno-0-240" name="__codelineno-0-240" href="#__codelineno-0-240"></a>            <span class="n">ensure_even_popsize</span><span class="o">=</span><span class="n">symmetric</span><span class="p">,</span>
<a id="__codelineno-0-241" name="__codelineno-0-241" href="#__codelineno-0-241"></a>        <span class="p">)</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">











  <div class="doc doc-object doc-method">



<h3 id="evotorch.algorithms.distributed.gaussian.PGPE.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">problem</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">popsize</span><span class="p">,</span> <span class="n">center_learning_rate</span><span class="p">,</span> <span class="n">stdev_learning_rate</span><span class="p">,</span> <span class="n">stdev_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">radius_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_interactions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">popsize_max</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;clipup&#39;</span><span class="p">,</span> <span class="n">optimizer_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ranking_method</span><span class="o">=</span><span class="s1">&#39;centered&#39;</span><span class="p">,</span> <span class="n">center_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stdev_min</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stdev_max</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stdev_max_change</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">symmetric</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">obj_index</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">distributed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">popsize_weighted_grad_avg</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

<a href="#evotorch.algorithms.distributed.gaussian.PGPE.__init__" class="headerlink" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p><code>__init__(...)</code>: Initialize the PGPE algorithm.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>problem</code></td>
        <td><code>Problem</code></td>
        <td><p>The problem object which is being worked on.
The problem must have its dtype defined
(which means it works on Solution objects,
not with custom Solution objects).
Also, the problem must be single-objective.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>popsize</code></td>
        <td><code>int</code></td>
        <td><p>The population size.
In the case of PGPE, <code>popsize</code> is expected as an even number
in non-distributed mode. In distributed mode, PGPE will
ensure that each sub-population size assigned to a remote
actor is an even number.
This behavior is because PGPE does symmetric sampling
(i.e. solutions are sampled in pairs).</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>center_learning_rate</code></td>
        <td><code>float</code></td>
        <td><p>The learning rate for the center
of the search distribution.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>stdev_learning_rate</code></td>
        <td><code>float</code></td>
        <td><p>The learning rate for the standard
deviation values of the search distribution.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>stdev_init</code></td>
        <td><code>Union[float, Iterable[float], torch.Tensor]</code></td>
        <td><p>The initial standard deviation of the search
distribution, expressed as a scalar or as an array.
Determines the initial coverage area of the search
distribution.
If one wishes to configure the coverage area via the
argument <code>radius_init</code> instead, then <code>stdev_init</code> is expected
as None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>radius_init</code></td>
        <td><code>Union[float, Iterable[float], torch.Tensor]</code></td>
        <td><p>The initial radius of the search distribution,
expressed as a scalar.
Determines the initial coverage area of the search
distribution.
Here, "radius" is defined as the norm of the search
distribution.
If one wishes to configure the coverage area via the
argument <code>stdev_init</code> instead, then <code>radius_init</code> is expected
as None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>num_interactions</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>When given as an integer n,
it is ensured that a population has interacted with
the GymProblem's environment n times. If this target
has not been reached yet, then the population is declared
too small, and gets extended with more samples,
until n amount of interactions is reached.
When given as None, popsize is the only configuration
affecting the size of a population.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>popsize_max</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>Having <code>num_interactions</code> set as an integer
might cause the effective population size jump to
unnecesarily large numbers. To prevent this,
one can set <code>popsize_max</code> to specify an upper
bound for the effective population size.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>optimizer</code></td>
        <td></td>
        <td><p>The optimizer to be used while following the
estimated the gradients.
Can be given as None if a momentum-based optimizer
is not required.
Otherwise, can be given as a str containing the name
of the optimizer (e.g. 'adam', 'clipup');
or as an instance of evotorch.optimizers.TorchOptimizer
or evotorch.optimizers.ClipUp.
The default is 'clipup'.
Note that, for ClipUp, the default maximum speed is set
as twice the given <code>center_learning_rate</code>.
This maximum speed can be configured by passing
<code>{"max_speed": ...}</code> to <code>optimizer_config</code>.</p></td>
        <td><code>&#39;clipup&#39;</code></td>
      </tr>
      <tr>
        <td><code>optimizer_config</code></td>
        <td><code>Optional[dict]</code></td>
        <td><p>Configuration which will be passed
to the optimizer as keyword arguments.
See <code>evotorch.optimizers</code> for details about
which optimizer accepts which keyword arguments.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>ranking_method</code></td>
        <td><code>Optional[str]</code></td>
        <td><p>Which ranking method will be used for
fitness shaping. See the documentation of
<code>evotorch.ranking.rank(...)</code> for details.
As in the study of Salimans et al. (2017),
the default is 'centered'.
Can be given as None if no such ranking is required.</p></td>
        <td><code>&#39;centered&#39;</code></td>
      </tr>
      <tr>
        <td><code>center_init</code></td>
        <td><code>Union[float, Iterable[float], torch.Tensor]</code></td>
        <td><p>The initial center solution.
Can be left as None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>stdev_min</code></td>
        <td><code>Union[float, Iterable[float], torch.Tensor]</code></td>
        <td><p>Lower bound for the standard deviation value/array.
Can be given as a real number, or as an array of real numbers.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>stdev_max</code></td>
        <td><code>Union[float, Iterable[float], torch.Tensor]</code></td>
        <td><p>Upper bound for the standard deviation value/array.
Can be given as a real number, or as an array of real numbers.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>stdev_max_change</code></td>
        <td><code>Union[float, Iterable[float], torch.Tensor]</code></td>
        <td><p>The maximum update ratio allowed on the
standard deviation. Expected as None if no such limiter
is needed, or as a real number within 0.0 and 1.0 otherwise.
Like in the implementation of Ha (2017, 2018),
the default value for this setting is 0.2, meaning that
the update on the standard deviation values can not be
more than 20% of their original values.</p></td>
        <td><code>0.2</code></td>
      </tr>
      <tr>
        <td><code>symmetric</code></td>
        <td><code>bool</code></td>
        <td><p>Whether or not the solutions will be sampled
in a symmetric/mirrored/antithetic manner.
The default is True.</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>obj_index</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>Index of the objective according to which the
gradient estimations will be done.
For single-objective problems, this can be left as None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>distributed</code></td>
        <td><code>bool</code></td>
        <td><p>Whether or not the gradient computation will
be distributed. If <code>distributed</code> is given as False and
the problem is not parallelized, then everything will
be centralized (i.e. the entire computation will happen
in the main process).
If <code>distributed</code> is given as False, and the problem
is parallelized, then the population will be created
in the main process and then sent to remote workers
for parallelized evaluation, and then the remote fitnesses
will be collected by the main process again for computing
the search gradients.
If <code>distributed</code> is given as True, and the problem
is parallelized, then the search algorithm itself will
be distributed, in the sense that each remote actor will
generate its own population (such that the total population
size across all these actors becomes equal to <code>popsize</code>)
and will compute its own gradient, and then the main process
will collect these gradients, compute the averaged gradients
and update the main search distribution.
Non-distributed mode has the advantage of keeping the
population in the main process, which is good when one wishes
to do detailed monitoring during the evolutionary process,
but has the disadvantage of having to pass the solutions to
the remote actors and having to collect fitnesses, which
might result in increased interprocess communication traffic.
On the other hand, while it is not possible to monitor the
population in distributed mode, the distributed mode has the
advantage of significantly reducing the interprocess
communication traffic, since the only things communicated
with the remote actors are the search distributions (not the
solutions) and the gradients.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>popsize_weighted_grad_avg</code></td>
        <td><code>Optional[bool]</code></td>
        <td><p>Only to be used in distributed mode.
(where being in distributed mode means <code>distributed</code> is given
as True). In distributed mode, each actor remotely samples
its own solution batches and computes its own gradients.
These gradients are then collected, and a final average
gradient is computed.
If <code>popsize_weighted_grad_avg</code> is True, then, while averaging
over the gradients, each gradient will have its own weight
that is computed according to how many solutions were sampled
by the actor that produced the gradient.
If <code>popsize_weighted_grad_avg</code> is False, then, there will not
be weighted averaging (or, each gradient will have equal
weight).
If <code>popsize_weighted_grad_avg</code> is None, then, the gradient
weights will be equal a value for <code>num_interactions</code> is given
(because <code>num_interactions</code> affects the number of solutions
according to the episode lengths, and popsize-weighting the
gradients could be misleading); and the gradient weights will
be weighted according to the sub-population (i.e. sub-batch)
sizes if <code>num_interactions</code> is left as None.
The default value for <code>popsize_weighted_grad_avg</code> is None.
When the distributed mode is disabled (i.e. when <code>distributed</code>
is False), then the argument <code>popsize_weighted_grad_avg</code> is
expected as None.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>evotorch/algorithms/distributed/gaussian.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">problem</span><span class="p">:</span> <span class="n">Problem</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">popsize</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">center_learning_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">stdev_learning_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n">stdev_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="n">radius_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="n">num_interactions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="n">popsize_max</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;clipup&quot;</span><span class="p">,</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    <span class="n">optimizer_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="n">ranking_method</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;centered&quot;</span><span class="p">,</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="n">center_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="n">stdev_min</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>    <span class="n">stdev_max</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>    <span class="n">stdev_max_change</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>    <span class="n">symmetric</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>    <span class="n">obj_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>    <span class="n">distributed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>    <span class="n">popsize_weighted_grad_avg</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a><span class="p">):</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a><span class="sd">    `__init__(...)`: Initialize the PGPE algorithm.</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a><span class="sd">        problem: The problem object which is being worked on.</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a><span class="sd">            The problem must have its dtype defined</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a><span class="sd">            (which means it works on Solution objects,</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a><span class="sd">            not with custom Solution objects).</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a><span class="sd">            Also, the problem must be single-objective.</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a><span class="sd">        popsize: The population size.</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a><span class="sd">            In the case of PGPE, `popsize` is expected as an even number</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a><span class="sd">            in non-distributed mode. In distributed mode, PGPE will</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a><span class="sd">            ensure that each sub-population size assigned to a remote</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a><span class="sd">            actor is an even number.</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a><span class="sd">            This behavior is because PGPE does symmetric sampling</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a><span class="sd">            (i.e. solutions are sampled in pairs).</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a><span class="sd">        center_learning_rate: The learning rate for the center</span>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a><span class="sd">            of the search distribution.</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a><span class="sd">        stdev_learning_rate: The learning rate for the standard</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a><span class="sd">            deviation values of the search distribution.</span>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a><span class="sd">        stdev_init: The initial standard deviation of the search</span>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a><span class="sd">            distribution, expressed as a scalar or as an array.</span>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a><span class="sd">            Determines the initial coverage area of the search</span>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a><span class="sd">            distribution.</span>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a><span class="sd">            If one wishes to configure the coverage area via the</span>
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a><span class="sd">            argument `radius_init` instead, then `stdev_init` is expected</span>
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a><span class="sd">            as None.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a><span class="sd">        radius_init: The initial radius of the search distribution,</span>
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a><span class="sd">            expressed as a scalar.</span>
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a><span class="sd">            Determines the initial coverage area of the search</span>
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a><span class="sd">            distribution.</span>
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a><span class="sd">            Here, &quot;radius&quot; is defined as the norm of the search</span>
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a><span class="sd">            distribution.</span>
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a><span class="sd">            If one wishes to configure the coverage area via the</span>
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a><span class="sd">            argument `stdev_init` instead, then `radius_init` is expected</span>
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a><span class="sd">            as None.</span>
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a><span class="sd">        num_interactions: When given as an integer n,</span>
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a><span class="sd">            it is ensured that a population has interacted with</span>
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#__codelineno-0-62"></a><span class="sd">            the GymProblem&#39;s environment n times. If this target</span>
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#__codelineno-0-63"></a><span class="sd">            has not been reached yet, then the population is declared</span>
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#__codelineno-0-64"></a><span class="sd">            too small, and gets extended with more samples,</span>
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#__codelineno-0-65"></a><span class="sd">            until n amount of interactions is reached.</span>
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#__codelineno-0-66"></a><span class="sd">            When given as None, popsize is the only configuration</span>
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#__codelineno-0-67"></a><span class="sd">            affecting the size of a population.</span>
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#__codelineno-0-68"></a><span class="sd">        popsize_max: Having `num_interactions` set as an integer</span>
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#__codelineno-0-69"></a><span class="sd">            might cause the effective population size jump to</span>
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#__codelineno-0-70"></a><span class="sd">            unnecesarily large numbers. To prevent this,</span>
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#__codelineno-0-71"></a><span class="sd">            one can set `popsize_max` to specify an upper</span>
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#__codelineno-0-72"></a><span class="sd">            bound for the effective population size.</span>
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#__codelineno-0-73"></a><span class="sd">        optimizer: The optimizer to be used while following the</span>
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#__codelineno-0-74"></a><span class="sd">            estimated the gradients.</span>
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#__codelineno-0-75"></a><span class="sd">            Can be given as None if a momentum-based optimizer</span>
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#__codelineno-0-76"></a><span class="sd">            is not required.</span>
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#__codelineno-0-77"></a><span class="sd">            Otherwise, can be given as a str containing the name</span>
<a id="__codelineno-0-78" name="__codelineno-0-78" href="#__codelineno-0-78"></a><span class="sd">            of the optimizer (e.g. &#39;adam&#39;, &#39;clipup&#39;);</span>
<a id="__codelineno-0-79" name="__codelineno-0-79" href="#__codelineno-0-79"></a><span class="sd">            or as an instance of evotorch.optimizers.TorchOptimizer</span>
<a id="__codelineno-0-80" name="__codelineno-0-80" href="#__codelineno-0-80"></a><span class="sd">            or evotorch.optimizers.ClipUp.</span>
<a id="__codelineno-0-81" name="__codelineno-0-81" href="#__codelineno-0-81"></a><span class="sd">            The default is &#39;clipup&#39;.</span>
<a id="__codelineno-0-82" name="__codelineno-0-82" href="#__codelineno-0-82"></a><span class="sd">            Note that, for ClipUp, the default maximum speed is set</span>
<a id="__codelineno-0-83" name="__codelineno-0-83" href="#__codelineno-0-83"></a><span class="sd">            as twice the given `center_learning_rate`.</span>
<a id="__codelineno-0-84" name="__codelineno-0-84" href="#__codelineno-0-84"></a><span class="sd">            This maximum speed can be configured by passing</span>
<a id="__codelineno-0-85" name="__codelineno-0-85" href="#__codelineno-0-85"></a><span class="sd">            `{&quot;max_speed&quot;: ...}` to `optimizer_config`.</span>
<a id="__codelineno-0-86" name="__codelineno-0-86" href="#__codelineno-0-86"></a><span class="sd">        optimizer_config: Configuration which will be passed</span>
<a id="__codelineno-0-87" name="__codelineno-0-87" href="#__codelineno-0-87"></a><span class="sd">            to the optimizer as keyword arguments.</span>
<a id="__codelineno-0-88" name="__codelineno-0-88" href="#__codelineno-0-88"></a><span class="sd">            See `evotorch.optimizers` for details about</span>
<a id="__codelineno-0-89" name="__codelineno-0-89" href="#__codelineno-0-89"></a><span class="sd">            which optimizer accepts which keyword arguments.</span>
<a id="__codelineno-0-90" name="__codelineno-0-90" href="#__codelineno-0-90"></a><span class="sd">        ranking_method: Which ranking method will be used for</span>
<a id="__codelineno-0-91" name="__codelineno-0-91" href="#__codelineno-0-91"></a><span class="sd">            fitness shaping. See the documentation of</span>
<a id="__codelineno-0-92" name="__codelineno-0-92" href="#__codelineno-0-92"></a><span class="sd">            `evotorch.ranking.rank(...)` for details.</span>
<a id="__codelineno-0-93" name="__codelineno-0-93" href="#__codelineno-0-93"></a><span class="sd">            As in the study of Salimans et al. (2017),</span>
<a id="__codelineno-0-94" name="__codelineno-0-94" href="#__codelineno-0-94"></a><span class="sd">            the default is &#39;centered&#39;.</span>
<a id="__codelineno-0-95" name="__codelineno-0-95" href="#__codelineno-0-95"></a><span class="sd">            Can be given as None if no such ranking is required.</span>
<a id="__codelineno-0-96" name="__codelineno-0-96" href="#__codelineno-0-96"></a><span class="sd">        center_init: The initial center solution.</span>
<a id="__codelineno-0-97" name="__codelineno-0-97" href="#__codelineno-0-97"></a><span class="sd">            Can be left as None.</span>
<a id="__codelineno-0-98" name="__codelineno-0-98" href="#__codelineno-0-98"></a><span class="sd">        stdev_min: Lower bound for the standard deviation value/array.</span>
<a id="__codelineno-0-99" name="__codelineno-0-99" href="#__codelineno-0-99"></a><span class="sd">            Can be given as a real number, or as an array of real numbers.</span>
<a id="__codelineno-0-100" name="__codelineno-0-100" href="#__codelineno-0-100"></a><span class="sd">        stdev_max: Upper bound for the standard deviation value/array.</span>
<a id="__codelineno-0-101" name="__codelineno-0-101" href="#__codelineno-0-101"></a><span class="sd">            Can be given as a real number, or as an array of real numbers.</span>
<a id="__codelineno-0-102" name="__codelineno-0-102" href="#__codelineno-0-102"></a><span class="sd">        stdev_max_change: The maximum update ratio allowed on the</span>
<a id="__codelineno-0-103" name="__codelineno-0-103" href="#__codelineno-0-103"></a><span class="sd">            standard deviation. Expected as None if no such limiter</span>
<a id="__codelineno-0-104" name="__codelineno-0-104" href="#__codelineno-0-104"></a><span class="sd">            is needed, or as a real number within 0.0 and 1.0 otherwise.</span>
<a id="__codelineno-0-105" name="__codelineno-0-105" href="#__codelineno-0-105"></a><span class="sd">            Like in the implementation of Ha (2017, 2018),</span>
<a id="__codelineno-0-106" name="__codelineno-0-106" href="#__codelineno-0-106"></a><span class="sd">            the default value for this setting is 0.2, meaning that</span>
<a id="__codelineno-0-107" name="__codelineno-0-107" href="#__codelineno-0-107"></a><span class="sd">            the update on the standard deviation values can not be</span>
<a id="__codelineno-0-108" name="__codelineno-0-108" href="#__codelineno-0-108"></a><span class="sd">            more than 20% of their original values.</span>
<a id="__codelineno-0-109" name="__codelineno-0-109" href="#__codelineno-0-109"></a><span class="sd">        symmetric: Whether or not the solutions will be sampled</span>
<a id="__codelineno-0-110" name="__codelineno-0-110" href="#__codelineno-0-110"></a><span class="sd">            in a symmetric/mirrored/antithetic manner.</span>
<a id="__codelineno-0-111" name="__codelineno-0-111" href="#__codelineno-0-111"></a><span class="sd">            The default is True.</span>
<a id="__codelineno-0-112" name="__codelineno-0-112" href="#__codelineno-0-112"></a><span class="sd">        obj_index: Index of the objective according to which the</span>
<a id="__codelineno-0-113" name="__codelineno-0-113" href="#__codelineno-0-113"></a><span class="sd">            gradient estimations will be done.</span>
<a id="__codelineno-0-114" name="__codelineno-0-114" href="#__codelineno-0-114"></a><span class="sd">            For single-objective problems, this can be left as None.</span>
<a id="__codelineno-0-115" name="__codelineno-0-115" href="#__codelineno-0-115"></a><span class="sd">        distributed: Whether or not the gradient computation will</span>
<a id="__codelineno-0-116" name="__codelineno-0-116" href="#__codelineno-0-116"></a><span class="sd">            be distributed. If `distributed` is given as False and</span>
<a id="__codelineno-0-117" name="__codelineno-0-117" href="#__codelineno-0-117"></a><span class="sd">            the problem is not parallelized, then everything will</span>
<a id="__codelineno-0-118" name="__codelineno-0-118" href="#__codelineno-0-118"></a><span class="sd">            be centralized (i.e. the entire computation will happen</span>
<a id="__codelineno-0-119" name="__codelineno-0-119" href="#__codelineno-0-119"></a><span class="sd">            in the main process).</span>
<a id="__codelineno-0-120" name="__codelineno-0-120" href="#__codelineno-0-120"></a><span class="sd">            If `distributed` is given as False, and the problem</span>
<a id="__codelineno-0-121" name="__codelineno-0-121" href="#__codelineno-0-121"></a><span class="sd">            is parallelized, then the population will be created</span>
<a id="__codelineno-0-122" name="__codelineno-0-122" href="#__codelineno-0-122"></a><span class="sd">            in the main process and then sent to remote workers</span>
<a id="__codelineno-0-123" name="__codelineno-0-123" href="#__codelineno-0-123"></a><span class="sd">            for parallelized evaluation, and then the remote fitnesses</span>
<a id="__codelineno-0-124" name="__codelineno-0-124" href="#__codelineno-0-124"></a><span class="sd">            will be collected by the main process again for computing</span>
<a id="__codelineno-0-125" name="__codelineno-0-125" href="#__codelineno-0-125"></a><span class="sd">            the search gradients.</span>
<a id="__codelineno-0-126" name="__codelineno-0-126" href="#__codelineno-0-126"></a><span class="sd">            If `distributed` is given as True, and the problem</span>
<a id="__codelineno-0-127" name="__codelineno-0-127" href="#__codelineno-0-127"></a><span class="sd">            is parallelized, then the search algorithm itself will</span>
<a id="__codelineno-0-128" name="__codelineno-0-128" href="#__codelineno-0-128"></a><span class="sd">            be distributed, in the sense that each remote actor will</span>
<a id="__codelineno-0-129" name="__codelineno-0-129" href="#__codelineno-0-129"></a><span class="sd">            generate its own population (such that the total population</span>
<a id="__codelineno-0-130" name="__codelineno-0-130" href="#__codelineno-0-130"></a><span class="sd">            size across all these actors becomes equal to `popsize`)</span>
<a id="__codelineno-0-131" name="__codelineno-0-131" href="#__codelineno-0-131"></a><span class="sd">            and will compute its own gradient, and then the main process</span>
<a id="__codelineno-0-132" name="__codelineno-0-132" href="#__codelineno-0-132"></a><span class="sd">            will collect these gradients, compute the averaged gradients</span>
<a id="__codelineno-0-133" name="__codelineno-0-133" href="#__codelineno-0-133"></a><span class="sd">            and update the main search distribution.</span>
<a id="__codelineno-0-134" name="__codelineno-0-134" href="#__codelineno-0-134"></a><span class="sd">            Non-distributed mode has the advantage of keeping the</span>
<a id="__codelineno-0-135" name="__codelineno-0-135" href="#__codelineno-0-135"></a><span class="sd">            population in the main process, which is good when one wishes</span>
<a id="__codelineno-0-136" name="__codelineno-0-136" href="#__codelineno-0-136"></a><span class="sd">            to do detailed monitoring during the evolutionary process,</span>
<a id="__codelineno-0-137" name="__codelineno-0-137" href="#__codelineno-0-137"></a><span class="sd">            but has the disadvantage of having to pass the solutions to</span>
<a id="__codelineno-0-138" name="__codelineno-0-138" href="#__codelineno-0-138"></a><span class="sd">            the remote actors and having to collect fitnesses, which</span>
<a id="__codelineno-0-139" name="__codelineno-0-139" href="#__codelineno-0-139"></a><span class="sd">            might result in increased interprocess communication traffic.</span>
<a id="__codelineno-0-140" name="__codelineno-0-140" href="#__codelineno-0-140"></a><span class="sd">            On the other hand, while it is not possible to monitor the</span>
<a id="__codelineno-0-141" name="__codelineno-0-141" href="#__codelineno-0-141"></a><span class="sd">            population in distributed mode, the distributed mode has the</span>
<a id="__codelineno-0-142" name="__codelineno-0-142" href="#__codelineno-0-142"></a><span class="sd">            advantage of significantly reducing the interprocess</span>
<a id="__codelineno-0-143" name="__codelineno-0-143" href="#__codelineno-0-143"></a><span class="sd">            communication traffic, since the only things communicated</span>
<a id="__codelineno-0-144" name="__codelineno-0-144" href="#__codelineno-0-144"></a><span class="sd">            with the remote actors are the search distributions (not the</span>
<a id="__codelineno-0-145" name="__codelineno-0-145" href="#__codelineno-0-145"></a><span class="sd">            solutions) and the gradients.</span>
<a id="__codelineno-0-146" name="__codelineno-0-146" href="#__codelineno-0-146"></a><span class="sd">        popsize_weighted_grad_avg: Only to be used in distributed mode.</span>
<a id="__codelineno-0-147" name="__codelineno-0-147" href="#__codelineno-0-147"></a><span class="sd">            (where being in distributed mode means `distributed` is given</span>
<a id="__codelineno-0-148" name="__codelineno-0-148" href="#__codelineno-0-148"></a><span class="sd">            as True). In distributed mode, each actor remotely samples</span>
<a id="__codelineno-0-149" name="__codelineno-0-149" href="#__codelineno-0-149"></a><span class="sd">            its own solution batches and computes its own gradients.</span>
<a id="__codelineno-0-150" name="__codelineno-0-150" href="#__codelineno-0-150"></a><span class="sd">            These gradients are then collected, and a final average</span>
<a id="__codelineno-0-151" name="__codelineno-0-151" href="#__codelineno-0-151"></a><span class="sd">            gradient is computed.</span>
<a id="__codelineno-0-152" name="__codelineno-0-152" href="#__codelineno-0-152"></a><span class="sd">            If `popsize_weighted_grad_avg` is True, then, while averaging</span>
<a id="__codelineno-0-153" name="__codelineno-0-153" href="#__codelineno-0-153"></a><span class="sd">            over the gradients, each gradient will have its own weight</span>
<a id="__codelineno-0-154" name="__codelineno-0-154" href="#__codelineno-0-154"></a><span class="sd">            that is computed according to how many solutions were sampled</span>
<a id="__codelineno-0-155" name="__codelineno-0-155" href="#__codelineno-0-155"></a><span class="sd">            by the actor that produced the gradient.</span>
<a id="__codelineno-0-156" name="__codelineno-0-156" href="#__codelineno-0-156"></a><span class="sd">            If `popsize_weighted_grad_avg` is False, then, there will not</span>
<a id="__codelineno-0-157" name="__codelineno-0-157" href="#__codelineno-0-157"></a><span class="sd">            be weighted averaging (or, each gradient will have equal</span>
<a id="__codelineno-0-158" name="__codelineno-0-158" href="#__codelineno-0-158"></a><span class="sd">            weight).</span>
<a id="__codelineno-0-159" name="__codelineno-0-159" href="#__codelineno-0-159"></a><span class="sd">            If `popsize_weighted_grad_avg` is None, then, the gradient</span>
<a id="__codelineno-0-160" name="__codelineno-0-160" href="#__codelineno-0-160"></a><span class="sd">            weights will be equal a value for `num_interactions` is given</span>
<a id="__codelineno-0-161" name="__codelineno-0-161" href="#__codelineno-0-161"></a><span class="sd">            (because `num_interactions` affects the number of solutions</span>
<a id="__codelineno-0-162" name="__codelineno-0-162" href="#__codelineno-0-162"></a><span class="sd">            according to the episode lengths, and popsize-weighting the</span>
<a id="__codelineno-0-163" name="__codelineno-0-163" href="#__codelineno-0-163"></a><span class="sd">            gradients could be misleading); and the gradient weights will</span>
<a id="__codelineno-0-164" name="__codelineno-0-164" href="#__codelineno-0-164"></a><span class="sd">            be weighted according to the sub-population (i.e. sub-batch)</span>
<a id="__codelineno-0-165" name="__codelineno-0-165" href="#__codelineno-0-165"></a><span class="sd">            sizes if `num_interactions` is left as None.</span>
<a id="__codelineno-0-166" name="__codelineno-0-166" href="#__codelineno-0-166"></a><span class="sd">            The default value for `popsize_weighted_grad_avg` is None.</span>
<a id="__codelineno-0-167" name="__codelineno-0-167" href="#__codelineno-0-167"></a><span class="sd">            When the distributed mode is disabled (i.e. when `distributed`</span>
<a id="__codelineno-0-168" name="__codelineno-0-168" href="#__codelineno-0-168"></a><span class="sd">            is False), then the argument `popsize_weighted_grad_avg` is</span>
<a id="__codelineno-0-169" name="__codelineno-0-169" href="#__codelineno-0-169"></a><span class="sd">            expected as None.</span>
<a id="__codelineno-0-170" name="__codelineno-0-170" href="#__codelineno-0-170"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-171" name="__codelineno-0-171" href="#__codelineno-0-171"></a>
<a id="__codelineno-0-172" name="__codelineno-0-172" href="#__codelineno-0-172"></a>    <span class="k">if</span> <span class="n">symmetric</span><span class="p">:</span>
<a id="__codelineno-0-173" name="__codelineno-0-173" href="#__codelineno-0-173"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">DISTRIBUTION_TYPE</span> <span class="o">=</span> <span class="n">SymmetricSeparableGaussian</span>
<a id="__codelineno-0-174" name="__codelineno-0-174" href="#__codelineno-0-174"></a>        <span class="n">divide_by</span> <span class="o">=</span> <span class="s2">&quot;num_directions&quot;</span>
<a id="__codelineno-0-175" name="__codelineno-0-175" href="#__codelineno-0-175"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-176" name="__codelineno-0-176" href="#__codelineno-0-176"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">DISTRIBUTION_TYPE</span> <span class="o">=</span> <span class="n">SeparableGaussian</span>
<a id="__codelineno-0-177" name="__codelineno-0-177" href="#__codelineno-0-177"></a>        <span class="n">divide_by</span> <span class="o">=</span> <span class="s2">&quot;num_solutions&quot;</span>
<a id="__codelineno-0-178" name="__codelineno-0-178" href="#__codelineno-0-178"></a>
<a id="__codelineno-0-179" name="__codelineno-0-179" href="#__codelineno-0-179"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">DISTRIBUTION_PARAMS</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;divide_mu_grad_by&quot;</span><span class="p">:</span> <span class="n">divide_by</span><span class="p">,</span> <span class="s2">&quot;divide_sigma_grad_by&quot;</span><span class="p">:</span> <span class="n">divide_by</span><span class="p">}</span>
<a id="__codelineno-0-180" name="__codelineno-0-180" href="#__codelineno-0-180"></a>
<a id="__codelineno-0-181" name="__codelineno-0-181" href="#__codelineno-0-181"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-182" name="__codelineno-0-182" href="#__codelineno-0-182"></a>        <span class="n">problem</span><span class="p">,</span>
<a id="__codelineno-0-183" name="__codelineno-0-183" href="#__codelineno-0-183"></a>        <span class="n">popsize</span><span class="o">=</span><span class="n">popsize</span><span class="p">,</span>
<a id="__codelineno-0-184" name="__codelineno-0-184" href="#__codelineno-0-184"></a>        <span class="n">center_learning_rate</span><span class="o">=</span><span class="n">center_learning_rate</span><span class="p">,</span>
<a id="__codelineno-0-185" name="__codelineno-0-185" href="#__codelineno-0-185"></a>        <span class="n">stdev_learning_rate</span><span class="o">=</span><span class="n">stdev_learning_rate</span><span class="p">,</span>
<a id="__codelineno-0-186" name="__codelineno-0-186" href="#__codelineno-0-186"></a>        <span class="n">stdev_init</span><span class="o">=</span><span class="n">stdev_init</span><span class="p">,</span>
<a id="__codelineno-0-187" name="__codelineno-0-187" href="#__codelineno-0-187"></a>        <span class="n">radius_init</span><span class="o">=</span><span class="n">radius_init</span><span class="p">,</span>
<a id="__codelineno-0-188" name="__codelineno-0-188" href="#__codelineno-0-188"></a>        <span class="n">popsize_max</span><span class="o">=</span><span class="n">popsize_max</span><span class="p">,</span>
<a id="__codelineno-0-189" name="__codelineno-0-189" href="#__codelineno-0-189"></a>        <span class="n">num_interactions</span><span class="o">=</span><span class="n">num_interactions</span><span class="p">,</span>
<a id="__codelineno-0-190" name="__codelineno-0-190" href="#__codelineno-0-190"></a>        <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
<a id="__codelineno-0-191" name="__codelineno-0-191" href="#__codelineno-0-191"></a>        <span class="n">optimizer_config</span><span class="o">=</span><span class="n">optimizer_config</span><span class="p">,</span>
<a id="__codelineno-0-192" name="__codelineno-0-192" href="#__codelineno-0-192"></a>        <span class="n">ranking_method</span><span class="o">=</span><span class="n">ranking_method</span><span class="p">,</span>
<a id="__codelineno-0-193" name="__codelineno-0-193" href="#__codelineno-0-193"></a>        <span class="n">center_init</span><span class="o">=</span><span class="n">center_init</span><span class="p">,</span>
<a id="__codelineno-0-194" name="__codelineno-0-194" href="#__codelineno-0-194"></a>        <span class="n">stdev_min</span><span class="o">=</span><span class="n">stdev_min</span><span class="p">,</span>
<a id="__codelineno-0-195" name="__codelineno-0-195" href="#__codelineno-0-195"></a>        <span class="n">stdev_max</span><span class="o">=</span><span class="n">stdev_max</span><span class="p">,</span>
<a id="__codelineno-0-196" name="__codelineno-0-196" href="#__codelineno-0-196"></a>        <span class="n">stdev_max_change</span><span class="o">=</span><span class="n">stdev_max_change</span><span class="p">,</span>
<a id="__codelineno-0-197" name="__codelineno-0-197" href="#__codelineno-0-197"></a>        <span class="n">obj_index</span><span class="o">=</span><span class="n">obj_index</span><span class="p">,</span>
<a id="__codelineno-0-198" name="__codelineno-0-198" href="#__codelineno-0-198"></a>        <span class="n">distributed</span><span class="o">=</span><span class="n">distributed</span><span class="p">,</span>
<a id="__codelineno-0-199" name="__codelineno-0-199" href="#__codelineno-0-199"></a>        <span class="n">popsize_weighted_grad_avg</span><span class="o">=</span><span class="n">popsize_weighted_grad_avg</span><span class="p">,</span>
<a id="__codelineno-0-200" name="__codelineno-0-200" href="#__codelineno-0-200"></a>        <span class="n">ensure_even_popsize</span><span class="o">=</span><span class="n">symmetric</span><span class="p">,</span>
<a id="__codelineno-0-201" name="__codelineno-0-201" href="#__codelineno-0-201"></a>    <span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h2 id="evotorch.algorithms.distributed.gaussian.SNES" class="doc doc-heading">
        <code>
SNES            (<a class="autorefs autorefs-internal" title="evotorch.algorithms.distributed.gaussian.GaussianSearchAlgorithm" href="#evotorch.algorithms.distributed.gaussian.GaussianSearchAlgorithm">GaussianSearchAlgorithm</a>)
        </code>



<a href="#evotorch.algorithms.distributed.gaussian.SNES" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents ">

      <p>Inspired by the implementation at: <a href="http://schaul.site44.com/code/snes.py">http://schaul.site44.com/code/snes.py</a></p>
<p>Reference:</p>
<div class="highlight"><pre><span></span><code>Schaul, T., Glasmachers, T., Schmidhuber, J. (2011).
High Dimensions and Heavy Tails for Natural Evolution Strategies.
Proceedings of the 13th annual conference on Genetic and evolutionary
computation (GECCO 2011).
</code></pre></div>

        <details class="quote">
          <summary>Source code in <code>evotorch/algorithms/distributed/gaussian.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">class</span> <span class="nc">SNES</span><span class="p">(</span><span class="n">GaussianSearchAlgorithm</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="sd">    SNES: Separable Natural Evolution Strategies</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">    Inspired by the implementation at: http://schaul.site44.com/code/snes.py</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">    Reference:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">        Schaul, T., Glasmachers, T., Schmidhuber, J. (2011).</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">        High Dimensions and Heavy Tails for Natural Evolution Strategies.</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="sd">        Proceedings of the 13th annual conference on Genetic and evolutionary</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="sd">        computation (GECCO 2011).</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="n">DISTRIBUTION_TYPE</span> <span class="o">=</span> <span class="n">ExpSeparableGaussian</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="n">DISTRIBUTION_PARAMS</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>        <span class="n">problem</span><span class="p">:</span> <span class="n">Problem</span><span class="p">,</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>        <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>        <span class="n">stdev_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>        <span class="n">radius_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>        <span class="n">popsize</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>        <span class="n">center_learning_rate</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>        <span class="n">stdev_learning_rate</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>        <span class="n">scale_learning_rate</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>        <span class="n">num_interactions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>        <span class="n">popsize_max</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>        <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>        <span class="n">optimizer_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>        <span class="n">ranking_method</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;nes&quot;</span><span class="p">,</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>        <span class="n">center_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>        <span class="n">stdev_min</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>        <span class="n">stdev_max</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a>        <span class="n">stdev_max_change</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>        <span class="n">obj_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>        <span class="n">distributed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a>        <span class="n">popsize_weighted_grad_avg</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>    <span class="p">):</span>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a><span class="sd">        `__init__(...)`: Initialize the SNES algorithm.</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a><span class="sd">            problem: The problem object which is being worked on.</span>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a><span class="sd">            stdev_init: The initial standard deviation of the search</span>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a><span class="sd">                distribution, expressed as a scalar or as an array.</span>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a><span class="sd">                Determines the initial coverage area of the search</span>
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a><span class="sd">                distribution.</span>
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a><span class="sd">                If one wishes to configure the coverage area via the</span>
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a><span class="sd">                argument `radius_init` instead, then `stdev_init` is expected</span>
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a><span class="sd">                as None.</span>
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a><span class="sd">            radius_init: The initial radius of the search distribution,</span>
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a><span class="sd">                expressed as a scalar.</span>
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a><span class="sd">                Determines the initial coverage area of the search</span>
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a><span class="sd">                distribution.</span>
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a><span class="sd">                Here, &quot;radius&quot; is defined as the norm of the search</span>
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a><span class="sd">                distribution.</span>
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a><span class="sd">                If one wishes to configure the coverage area via the</span>
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a><span class="sd">                argument `stdev_init` instead, then `radius_init` is expected</span>
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a><span class="sd">                as None.</span>
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#__codelineno-0-62"></a><span class="sd">            popsize: Population size. Can be specified as an int,</span>
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#__codelineno-0-63"></a><span class="sd">                or can be left as None to let the solver decide.</span>
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#__codelineno-0-64"></a><span class="sd">                In the case of SNES, `popsize` can be left as None,</span>
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#__codelineno-0-65"></a><span class="sd">                in which case the default `popsize` will be computed</span>
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#__codelineno-0-66"></a><span class="sd">                as `4 + floor(3 * log(n))` where `n` is the length</span>
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#__codelineno-0-67"></a><span class="sd">                of a solution.</span>
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#__codelineno-0-68"></a><span class="sd">            center_learning_rate: Learning rate for updating the mean</span>
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#__codelineno-0-69"></a><span class="sd">                of the search distribution. Default value is 1.0</span>
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#__codelineno-0-70"></a><span class="sd">            stdev_learning_rate: Learning rate for updating the covariance</span>
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#__codelineno-0-71"></a><span class="sd">                matrix of the search distribution.</span>
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#__codelineno-0-72"></a><span class="sd">                The default value is `0.2 * (3 + log(n)) / sqrt(n)`</span>
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#__codelineno-0-73"></a><span class="sd">                where `n` is the length of a solution.</span>
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#__codelineno-0-74"></a><span class="sd">            scale_learning_rate: For SNES, there is a default standard</span>
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#__codelineno-0-75"></a><span class="sd">                deviation learning rate value which is computed as</span>
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#__codelineno-0-76"></a><span class="sd">                `0.2 * (3 + log(n)) / sqrt(n)` (where `n` is the solution</span>
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#__codelineno-0-77"></a><span class="sd">                length).</span>
<a id="__codelineno-0-78" name="__codelineno-0-78" href="#__codelineno-0-78"></a><span class="sd">                If scale_learning_rate is True (which is the default),</span>
<a id="__codelineno-0-79" name="__codelineno-0-79" href="#__codelineno-0-79"></a><span class="sd">                then the effective learning rate for the standard deviation</span>
<a id="__codelineno-0-80" name="__codelineno-0-80" href="#__codelineno-0-80"></a><span class="sd">                becomes the provided `stdev_learning_rate` multiplied by this</span>
<a id="__codelineno-0-81" name="__codelineno-0-81" href="#__codelineno-0-81"></a><span class="sd">                default value. If `scale_learning_rate` is False, then the</span>
<a id="__codelineno-0-82" name="__codelineno-0-82" href="#__codelineno-0-82"></a><span class="sd">                effective standard deviation learning rate becomes</span>
<a id="__codelineno-0-83" name="__codelineno-0-83" href="#__codelineno-0-83"></a><span class="sd">                equal to the provided `stdev_learning_rate` value.</span>
<a id="__codelineno-0-84" name="__codelineno-0-84" href="#__codelineno-0-84"></a><span class="sd">            num_interactions: When given as an integer n,</span>
<a id="__codelineno-0-85" name="__codelineno-0-85" href="#__codelineno-0-85"></a><span class="sd">                it is ensured that a population has interacted with</span>
<a id="__codelineno-0-86" name="__codelineno-0-86" href="#__codelineno-0-86"></a><span class="sd">                the GymProblem&#39;s environment n times. If this target</span>
<a id="__codelineno-0-87" name="__codelineno-0-87" href="#__codelineno-0-87"></a><span class="sd">                has not been reached yet, then the population is declared</span>
<a id="__codelineno-0-88" name="__codelineno-0-88" href="#__codelineno-0-88"></a><span class="sd">                too small, and gets extended with more samples,</span>
<a id="__codelineno-0-89" name="__codelineno-0-89" href="#__codelineno-0-89"></a><span class="sd">                until n amount of interactions is reached.</span>
<a id="__codelineno-0-90" name="__codelineno-0-90" href="#__codelineno-0-90"></a><span class="sd">                When given as None, popsize is the only configuration</span>
<a id="__codelineno-0-91" name="__codelineno-0-91" href="#__codelineno-0-91"></a><span class="sd">                affecting the size of a population.</span>
<a id="__codelineno-0-92" name="__codelineno-0-92" href="#__codelineno-0-92"></a><span class="sd">            popsize_max: Having `num_interactions` set as an integer</span>
<a id="__codelineno-0-93" name="__codelineno-0-93" href="#__codelineno-0-93"></a><span class="sd">                might cause the effective population size jump to</span>
<a id="__codelineno-0-94" name="__codelineno-0-94" href="#__codelineno-0-94"></a><span class="sd">                unnecesarily large numbers. To prevent this,</span>
<a id="__codelineno-0-95" name="__codelineno-0-95" href="#__codelineno-0-95"></a><span class="sd">                one can set `popsize_max` to specify an upper</span>
<a id="__codelineno-0-96" name="__codelineno-0-96" href="#__codelineno-0-96"></a><span class="sd">                bound for the effective population size.</span>
<a id="__codelineno-0-97" name="__codelineno-0-97" href="#__codelineno-0-97"></a><span class="sd">            num_interactions: When given as an integer n,</span>
<a id="__codelineno-0-98" name="__codelineno-0-98" href="#__codelineno-0-98"></a><span class="sd">                it is ensured that a population has interacted with</span>
<a id="__codelineno-0-99" name="__codelineno-0-99" href="#__codelineno-0-99"></a><span class="sd">                the GymProblem&#39;s environment n times. If this target</span>
<a id="__codelineno-0-100" name="__codelineno-0-100" href="#__codelineno-0-100"></a><span class="sd">                has not been reached yet, then the population is declared</span>
<a id="__codelineno-0-101" name="__codelineno-0-101" href="#__codelineno-0-101"></a><span class="sd">                too small, and gets extended with more samples,</span>
<a id="__codelineno-0-102" name="__codelineno-0-102" href="#__codelineno-0-102"></a><span class="sd">                until n amount of interactions is reached.</span>
<a id="__codelineno-0-103" name="__codelineno-0-103" href="#__codelineno-0-103"></a><span class="sd">                When given as None, popsize is the only configuration</span>
<a id="__codelineno-0-104" name="__codelineno-0-104" href="#__codelineno-0-104"></a><span class="sd">                affecting the size of a population.</span>
<a id="__codelineno-0-105" name="__codelineno-0-105" href="#__codelineno-0-105"></a><span class="sd">            popsize_max: Having `num_interactions` set as an integer</span>
<a id="__codelineno-0-106" name="__codelineno-0-106" href="#__codelineno-0-106"></a><span class="sd">                might cause the effective population size jump to</span>
<a id="__codelineno-0-107" name="__codelineno-0-107" href="#__codelineno-0-107"></a><span class="sd">                unnecesarily large numbers. To prevent this,</span>
<a id="__codelineno-0-108" name="__codelineno-0-108" href="#__codelineno-0-108"></a><span class="sd">                one can set `popsize_max` to specify an upper</span>
<a id="__codelineno-0-109" name="__codelineno-0-109" href="#__codelineno-0-109"></a><span class="sd">                bound for the effective population size.</span>
<a id="__codelineno-0-110" name="__codelineno-0-110" href="#__codelineno-0-110"></a><span class="sd">            optimizer: The optimizer to be used while following the</span>
<a id="__codelineno-0-111" name="__codelineno-0-111" href="#__codelineno-0-111"></a><span class="sd">                estimated the gradients.</span>
<a id="__codelineno-0-112" name="__codelineno-0-112" href="#__codelineno-0-112"></a><span class="sd">                Can be given as None if a momentum-based optimizer</span>
<a id="__codelineno-0-113" name="__codelineno-0-113" href="#__codelineno-0-113"></a><span class="sd">                is not required.</span>
<a id="__codelineno-0-114" name="__codelineno-0-114" href="#__codelineno-0-114"></a><span class="sd">                Otherwise, can be given as a str containing the name</span>
<a id="__codelineno-0-115" name="__codelineno-0-115" href="#__codelineno-0-115"></a><span class="sd">                of the optimizer (e.g. &#39;adam&#39;, &#39;clipup&#39;);</span>
<a id="__codelineno-0-116" name="__codelineno-0-116" href="#__codelineno-0-116"></a><span class="sd">                or as an instance of evotorch.optimizers.TorchOptimizer</span>
<a id="__codelineno-0-117" name="__codelineno-0-117" href="#__codelineno-0-117"></a><span class="sd">                or evotorch.optimizers.ClipUp.</span>
<a id="__codelineno-0-118" name="__codelineno-0-118" href="#__codelineno-0-118"></a><span class="sd">                The default is None.</span>
<a id="__codelineno-0-119" name="__codelineno-0-119" href="#__codelineno-0-119"></a><span class="sd">                Note that, for ClipUp, the default maximum speed is set</span>
<a id="__codelineno-0-120" name="__codelineno-0-120" href="#__codelineno-0-120"></a><span class="sd">                as twice the given `center_learning_rate`.</span>
<a id="__codelineno-0-121" name="__codelineno-0-121" href="#__codelineno-0-121"></a><span class="sd">                This maximum speed can be configured by passing</span>
<a id="__codelineno-0-122" name="__codelineno-0-122" href="#__codelineno-0-122"></a><span class="sd">                `{&quot;max_speed&quot;: ...}` to `optimizer_config`.</span>
<a id="__codelineno-0-123" name="__codelineno-0-123" href="#__codelineno-0-123"></a><span class="sd">            optimizer_config: Configuration which will be passed</span>
<a id="__codelineno-0-124" name="__codelineno-0-124" href="#__codelineno-0-124"></a><span class="sd">                to the optimizer as keyword arguments.</span>
<a id="__codelineno-0-125" name="__codelineno-0-125" href="#__codelineno-0-125"></a><span class="sd">                See `evotorch.optimizers` for details about</span>
<a id="__codelineno-0-126" name="__codelineno-0-126" href="#__codelineno-0-126"></a><span class="sd">                which optimizer accepts which keyword arguments.</span>
<a id="__codelineno-0-127" name="__codelineno-0-127" href="#__codelineno-0-127"></a><span class="sd">            ranking_method: Which ranking method will be used for</span>
<a id="__codelineno-0-128" name="__codelineno-0-128" href="#__codelineno-0-128"></a><span class="sd">                fitness shaping. See the documentation of</span>
<a id="__codelineno-0-129" name="__codelineno-0-129" href="#__codelineno-0-129"></a><span class="sd">                `evotorch.ranking.rank(...)` for details.</span>
<a id="__codelineno-0-130" name="__codelineno-0-130" href="#__codelineno-0-130"></a><span class="sd">                The default is &#39;nes&#39;.</span>
<a id="__codelineno-0-131" name="__codelineno-0-131" href="#__codelineno-0-131"></a><span class="sd">                Can be given as None if no such ranking is required.</span>
<a id="__codelineno-0-132" name="__codelineno-0-132" href="#__codelineno-0-132"></a><span class="sd">            center_init: The initial center solution.</span>
<a id="__codelineno-0-133" name="__codelineno-0-133" href="#__codelineno-0-133"></a><span class="sd">                Can be left as None.</span>
<a id="__codelineno-0-134" name="__codelineno-0-134" href="#__codelineno-0-134"></a><span class="sd">            stdev_min: Minimum values for the standard deviation.</span>
<a id="__codelineno-0-135" name="__codelineno-0-135" href="#__codelineno-0-135"></a><span class="sd">                Expected as a 1-dimensional array to serve as a limiter</span>
<a id="__codelineno-0-136" name="__codelineno-0-136" href="#__codelineno-0-136"></a><span class="sd">                to the diagonals of the covariance matrix&#39;s square root.</span>
<a id="__codelineno-0-137" name="__codelineno-0-137" href="#__codelineno-0-137"></a><span class="sd">            stdev_max: Maximum values for the standard deviation.</span>
<a id="__codelineno-0-138" name="__codelineno-0-138" href="#__codelineno-0-138"></a><span class="sd">                Expected as a 1-dimensional array to serve as a limiter</span>
<a id="__codelineno-0-139" name="__codelineno-0-139" href="#__codelineno-0-139"></a><span class="sd">                to the diagonals of the covariance matrix&#39;s square root.</span>
<a id="__codelineno-0-140" name="__codelineno-0-140" href="#__codelineno-0-140"></a><span class="sd">            stdev_max_change: Maximum change allowed for when updating</span>
<a id="__codelineno-0-141" name="__codelineno-0-141" href="#__codelineno-0-141"></a><span class="sd">                the square roort of the covariance matrix.</span>
<a id="__codelineno-0-142" name="__codelineno-0-142" href="#__codelineno-0-142"></a><span class="sd">            obj_index: Index of the objective according to which the</span>
<a id="__codelineno-0-143" name="__codelineno-0-143" href="#__codelineno-0-143"></a><span class="sd">                gradient estimations will be done.</span>
<a id="__codelineno-0-144" name="__codelineno-0-144" href="#__codelineno-0-144"></a><span class="sd">                For single-objective problems, this can be left as None.</span>
<a id="__codelineno-0-145" name="__codelineno-0-145" href="#__codelineno-0-145"></a><span class="sd">            distributed: Whether or not the gradient computation will</span>
<a id="__codelineno-0-146" name="__codelineno-0-146" href="#__codelineno-0-146"></a><span class="sd">                be distributed. If `distributed` is given as False and</span>
<a id="__codelineno-0-147" name="__codelineno-0-147" href="#__codelineno-0-147"></a><span class="sd">                the problem is not parallelized, then everything will</span>
<a id="__codelineno-0-148" name="__codelineno-0-148" href="#__codelineno-0-148"></a><span class="sd">                be centralized (i.e. the entire computation will happen</span>
<a id="__codelineno-0-149" name="__codelineno-0-149" href="#__codelineno-0-149"></a><span class="sd">                in the main process).</span>
<a id="__codelineno-0-150" name="__codelineno-0-150" href="#__codelineno-0-150"></a><span class="sd">                If `distributed` is given as False, and the problem</span>
<a id="__codelineno-0-151" name="__codelineno-0-151" href="#__codelineno-0-151"></a><span class="sd">                is parallelized, then the population will be created</span>
<a id="__codelineno-0-152" name="__codelineno-0-152" href="#__codelineno-0-152"></a><span class="sd">                in the main process and then sent to remote workers</span>
<a id="__codelineno-0-153" name="__codelineno-0-153" href="#__codelineno-0-153"></a><span class="sd">                for parallelized evaluation, and then the remote fitnesses</span>
<a id="__codelineno-0-154" name="__codelineno-0-154" href="#__codelineno-0-154"></a><span class="sd">                will be collected by the main process again for computing</span>
<a id="__codelineno-0-155" name="__codelineno-0-155" href="#__codelineno-0-155"></a><span class="sd">                the search gradients.</span>
<a id="__codelineno-0-156" name="__codelineno-0-156" href="#__codelineno-0-156"></a><span class="sd">                If `distributed` is given as True, and the problem</span>
<a id="__codelineno-0-157" name="__codelineno-0-157" href="#__codelineno-0-157"></a><span class="sd">                is parallelized, then the search algorithm itself will</span>
<a id="__codelineno-0-158" name="__codelineno-0-158" href="#__codelineno-0-158"></a><span class="sd">                be distributed, in the sense that each remote actor will</span>
<a id="__codelineno-0-159" name="__codelineno-0-159" href="#__codelineno-0-159"></a><span class="sd">                generate its own population (such that the total population</span>
<a id="__codelineno-0-160" name="__codelineno-0-160" href="#__codelineno-0-160"></a><span class="sd">                size across all these actors becomes equal to `popsize`)</span>
<a id="__codelineno-0-161" name="__codelineno-0-161" href="#__codelineno-0-161"></a><span class="sd">                and will compute its own gradient, and then the main process</span>
<a id="__codelineno-0-162" name="__codelineno-0-162" href="#__codelineno-0-162"></a><span class="sd">                will collect these gradients, compute the averaged gradients</span>
<a id="__codelineno-0-163" name="__codelineno-0-163" href="#__codelineno-0-163"></a><span class="sd">                and update the main search distribution.</span>
<a id="__codelineno-0-164" name="__codelineno-0-164" href="#__codelineno-0-164"></a><span class="sd">                Non-distributed mode has the advantage of keeping the</span>
<a id="__codelineno-0-165" name="__codelineno-0-165" href="#__codelineno-0-165"></a><span class="sd">                population in the main process, which is good when one wishes</span>
<a id="__codelineno-0-166" name="__codelineno-0-166" href="#__codelineno-0-166"></a><span class="sd">                to do detailed monitoring during the evolutionary process,</span>
<a id="__codelineno-0-167" name="__codelineno-0-167" href="#__codelineno-0-167"></a><span class="sd">                but has the disadvantage of having to pass the solutions to</span>
<a id="__codelineno-0-168" name="__codelineno-0-168" href="#__codelineno-0-168"></a><span class="sd">                the remote actors and having to collect fitnesses, which</span>
<a id="__codelineno-0-169" name="__codelineno-0-169" href="#__codelineno-0-169"></a><span class="sd">                might result in increased interprocess communication traffic.</span>
<a id="__codelineno-0-170" name="__codelineno-0-170" href="#__codelineno-0-170"></a><span class="sd">                On the other hand, while it is not possible to monitor the</span>
<a id="__codelineno-0-171" name="__codelineno-0-171" href="#__codelineno-0-171"></a><span class="sd">                population in distributed mode, the distributed mode has the</span>
<a id="__codelineno-0-172" name="__codelineno-0-172" href="#__codelineno-0-172"></a><span class="sd">                advantage of significantly reducing the interprocess</span>
<a id="__codelineno-0-173" name="__codelineno-0-173" href="#__codelineno-0-173"></a><span class="sd">                communication traffic, since the only things communicated</span>
<a id="__codelineno-0-174" name="__codelineno-0-174" href="#__codelineno-0-174"></a><span class="sd">                with the remote actors are the search distributions (not the</span>
<a id="__codelineno-0-175" name="__codelineno-0-175" href="#__codelineno-0-175"></a><span class="sd">                solutions) and the gradients.</span>
<a id="__codelineno-0-176" name="__codelineno-0-176" href="#__codelineno-0-176"></a><span class="sd">            popsize_weighted_grad_avg: Only to be used in distributed mode.</span>
<a id="__codelineno-0-177" name="__codelineno-0-177" href="#__codelineno-0-177"></a><span class="sd">                (where being in distributed mode means `distributed` is given</span>
<a id="__codelineno-0-178" name="__codelineno-0-178" href="#__codelineno-0-178"></a><span class="sd">                as True). In distributed mode, each actor remotely samples</span>
<a id="__codelineno-0-179" name="__codelineno-0-179" href="#__codelineno-0-179"></a><span class="sd">                its own solution batches and computes its own gradients.</span>
<a id="__codelineno-0-180" name="__codelineno-0-180" href="#__codelineno-0-180"></a><span class="sd">                These gradients are then collected, and a final average</span>
<a id="__codelineno-0-181" name="__codelineno-0-181" href="#__codelineno-0-181"></a><span class="sd">                gradient is computed.</span>
<a id="__codelineno-0-182" name="__codelineno-0-182" href="#__codelineno-0-182"></a><span class="sd">                If `popsize_weighted_grad_avg` is True, then, while averaging</span>
<a id="__codelineno-0-183" name="__codelineno-0-183" href="#__codelineno-0-183"></a><span class="sd">                over the gradients, each gradient will have its own weight</span>
<a id="__codelineno-0-184" name="__codelineno-0-184" href="#__codelineno-0-184"></a><span class="sd">                that is computed according to how many solutions were sampled</span>
<a id="__codelineno-0-185" name="__codelineno-0-185" href="#__codelineno-0-185"></a><span class="sd">                by the actor that produced the gradient.</span>
<a id="__codelineno-0-186" name="__codelineno-0-186" href="#__codelineno-0-186"></a><span class="sd">                If `popsize_weighted_grad_avg` is False, then, there will not</span>
<a id="__codelineno-0-187" name="__codelineno-0-187" href="#__codelineno-0-187"></a><span class="sd">                be weighted averaging (or, each gradient will have equal</span>
<a id="__codelineno-0-188" name="__codelineno-0-188" href="#__codelineno-0-188"></a><span class="sd">                weight).</span>
<a id="__codelineno-0-189" name="__codelineno-0-189" href="#__codelineno-0-189"></a><span class="sd">                If `popsize_weighted_grad_avg` is None, then, the gradient</span>
<a id="__codelineno-0-190" name="__codelineno-0-190" href="#__codelineno-0-190"></a><span class="sd">                weights will be equal a value for `num_interactions` is given</span>
<a id="__codelineno-0-191" name="__codelineno-0-191" href="#__codelineno-0-191"></a><span class="sd">                (because `num_interactions` affects the number of solutions</span>
<a id="__codelineno-0-192" name="__codelineno-0-192" href="#__codelineno-0-192"></a><span class="sd">                according to the episode lengths, and popsize-weighting the</span>
<a id="__codelineno-0-193" name="__codelineno-0-193" href="#__codelineno-0-193"></a><span class="sd">                gradients could be misleading); and the gradient weights will</span>
<a id="__codelineno-0-194" name="__codelineno-0-194" href="#__codelineno-0-194"></a><span class="sd">                be weighted according to the sub-population (i.e. sub-batch)</span>
<a id="__codelineno-0-195" name="__codelineno-0-195" href="#__codelineno-0-195"></a><span class="sd">                sizes if `num_interactions` is left as None.</span>
<a id="__codelineno-0-196" name="__codelineno-0-196" href="#__codelineno-0-196"></a><span class="sd">                The default value for `popsize_weighted_grad_avg` is None.</span>
<a id="__codelineno-0-197" name="__codelineno-0-197" href="#__codelineno-0-197"></a><span class="sd">                When the distributed mode is disabled (i.e. when `distributed`</span>
<a id="__codelineno-0-198" name="__codelineno-0-198" href="#__codelineno-0-198"></a><span class="sd">                is False), then the argument `popsize_weighted_grad_avg` is</span>
<a id="__codelineno-0-199" name="__codelineno-0-199" href="#__codelineno-0-199"></a><span class="sd">                expected as None.</span>
<a id="__codelineno-0-200" name="__codelineno-0-200" href="#__codelineno-0-200"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-201" name="__codelineno-0-201" href="#__codelineno-0-201"></a>
<a id="__codelineno-0-202" name="__codelineno-0-202" href="#__codelineno-0-202"></a>        <span class="k">if</span> <span class="n">popsize</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-203" name="__codelineno-0-203" href="#__codelineno-0-203"></a>            <span class="n">popsize</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">4</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="mi">3</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">problem</span><span class="o">.</span><span class="n">solution_length</span><span class="p">)))</span>
<a id="__codelineno-0-204" name="__codelineno-0-204" href="#__codelineno-0-204"></a>
<a id="__codelineno-0-205" name="__codelineno-0-205" href="#__codelineno-0-205"></a>        <span class="k">if</span> <span class="n">center_learning_rate</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-206" name="__codelineno-0-206" href="#__codelineno-0-206"></a>            <span class="n">center_learning_rate</span> <span class="o">=</span> <span class="mf">1.0</span>
<a id="__codelineno-0-207" name="__codelineno-0-207" href="#__codelineno-0-207"></a>
<a id="__codelineno-0-208" name="__codelineno-0-208" href="#__codelineno-0-208"></a>        <span class="k">def</span> <span class="nf">default_stdev_lr</span><span class="p">():</span>
<a id="__codelineno-0-209" name="__codelineno-0-209" href="#__codelineno-0-209"></a>            <span class="n">n</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">solution_length</span>
<a id="__codelineno-0-210" name="__codelineno-0-210" href="#__codelineno-0-210"></a>            <span class="k">return</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">3</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n</span><span class="p">))</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<a id="__codelineno-0-211" name="__codelineno-0-211" href="#__codelineno-0-211"></a>
<a id="__codelineno-0-212" name="__codelineno-0-212" href="#__codelineno-0-212"></a>        <span class="k">if</span> <span class="n">stdev_learning_rate</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-213" name="__codelineno-0-213" href="#__codelineno-0-213"></a>            <span class="n">stdev_learning_rate</span> <span class="o">=</span> <span class="n">default_stdev_lr</span><span class="p">()</span>
<a id="__codelineno-0-214" name="__codelineno-0-214" href="#__codelineno-0-214"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-215" name="__codelineno-0-215" href="#__codelineno-0-215"></a>            <span class="n">stdev_learning_rate</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">stdev_learning_rate</span><span class="p">)</span>
<a id="__codelineno-0-216" name="__codelineno-0-216" href="#__codelineno-0-216"></a>            <span class="k">if</span> <span class="n">scale_learning_rate</span><span class="p">:</span>
<a id="__codelineno-0-217" name="__codelineno-0-217" href="#__codelineno-0-217"></a>                <span class="n">stdev_learning_rate</span> <span class="o">*=</span> <span class="n">default_stdev_lr</span><span class="p">()</span>
<a id="__codelineno-0-218" name="__codelineno-0-218" href="#__codelineno-0-218"></a>
<a id="__codelineno-0-219" name="__codelineno-0-219" href="#__codelineno-0-219"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-220" name="__codelineno-0-220" href="#__codelineno-0-220"></a>            <span class="n">problem</span><span class="p">,</span>
<a id="__codelineno-0-221" name="__codelineno-0-221" href="#__codelineno-0-221"></a>            <span class="n">popsize</span><span class="o">=</span><span class="n">popsize</span><span class="p">,</span>
<a id="__codelineno-0-222" name="__codelineno-0-222" href="#__codelineno-0-222"></a>            <span class="n">center_learning_rate</span><span class="o">=</span><span class="n">center_learning_rate</span><span class="p">,</span>
<a id="__codelineno-0-223" name="__codelineno-0-223" href="#__codelineno-0-223"></a>            <span class="n">stdev_learning_rate</span><span class="o">=</span><span class="n">stdev_learning_rate</span><span class="p">,</span>
<a id="__codelineno-0-224" name="__codelineno-0-224" href="#__codelineno-0-224"></a>            <span class="n">stdev_init</span><span class="o">=</span><span class="n">stdev_init</span><span class="p">,</span>
<a id="__codelineno-0-225" name="__codelineno-0-225" href="#__codelineno-0-225"></a>            <span class="n">radius_init</span><span class="o">=</span><span class="n">radius_init</span><span class="p">,</span>
<a id="__codelineno-0-226" name="__codelineno-0-226" href="#__codelineno-0-226"></a>            <span class="n">popsize_max</span><span class="o">=</span><span class="n">popsize_max</span><span class="p">,</span>
<a id="__codelineno-0-227" name="__codelineno-0-227" href="#__codelineno-0-227"></a>            <span class="n">num_interactions</span><span class="o">=</span><span class="n">num_interactions</span><span class="p">,</span>
<a id="__codelineno-0-228" name="__codelineno-0-228" href="#__codelineno-0-228"></a>            <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
<a id="__codelineno-0-229" name="__codelineno-0-229" href="#__codelineno-0-229"></a>            <span class="n">optimizer_config</span><span class="o">=</span><span class="n">optimizer_config</span><span class="p">,</span>
<a id="__codelineno-0-230" name="__codelineno-0-230" href="#__codelineno-0-230"></a>            <span class="n">ranking_method</span><span class="o">=</span><span class="n">ranking_method</span><span class="p">,</span>
<a id="__codelineno-0-231" name="__codelineno-0-231" href="#__codelineno-0-231"></a>            <span class="n">center_init</span><span class="o">=</span><span class="n">center_init</span><span class="p">,</span>
<a id="__codelineno-0-232" name="__codelineno-0-232" href="#__codelineno-0-232"></a>            <span class="n">stdev_min</span><span class="o">=</span><span class="n">stdev_min</span><span class="p">,</span>
<a id="__codelineno-0-233" name="__codelineno-0-233" href="#__codelineno-0-233"></a>            <span class="n">stdev_max</span><span class="o">=</span><span class="n">stdev_max</span><span class="p">,</span>
<a id="__codelineno-0-234" name="__codelineno-0-234" href="#__codelineno-0-234"></a>            <span class="n">stdev_max_change</span><span class="o">=</span><span class="n">stdev_max_change</span><span class="p">,</span>
<a id="__codelineno-0-235" name="__codelineno-0-235" href="#__codelineno-0-235"></a>            <span class="n">obj_index</span><span class="o">=</span><span class="n">obj_index</span><span class="p">,</span>
<a id="__codelineno-0-236" name="__codelineno-0-236" href="#__codelineno-0-236"></a>            <span class="n">distributed</span><span class="o">=</span><span class="n">distributed</span><span class="p">,</span>
<a id="__codelineno-0-237" name="__codelineno-0-237" href="#__codelineno-0-237"></a>            <span class="n">popsize_weighted_grad_avg</span><span class="o">=</span><span class="n">popsize_weighted_grad_avg</span><span class="p">,</span>
<a id="__codelineno-0-238" name="__codelineno-0-238" href="#__codelineno-0-238"></a>        <span class="p">)</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">








  <div class="doc doc-object doc-class">



<h3 id="evotorch.algorithms.distributed.gaussian.SNES.DISTRIBUTION_TYPE" class="doc doc-heading">
        <code>
DISTRIBUTION_TYPE            (<a class="autorefs autorefs-internal" title="evotorch.distributions.SeparableGaussian" href="../../../distributions/#evotorch.distributions.SeparableGaussian">SeparableGaussian</a>)
        </code>



<a href="#evotorch.algorithms.distributed.gaussian.SNES.DISTRIBUTION_TYPE" class="headerlink" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p>exponentialseparable Multivariate Gaussian, as used by SNES</p>

        <details class="quote">
          <summary>Source code in <code>evotorch/algorithms/distributed/gaussian.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">class</span> <span class="nc">ExpSeparableGaussian</span><span class="p">(</span><span class="n">SeparableGaussian</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;exponentialseparable Multivariate Gaussian, as used by SNES&quot;&quot;&quot;</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">MANDATORY_PARAMETERS</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;mu&quot;</span><span class="p">,</span> <span class="s2">&quot;sigma&quot;</span><span class="p">}</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">OPTIONAL_PARAMETERS</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="k">def</span> <span class="nf">_compute_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">ranking_used</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>        <span class="k">if</span> <span class="n">ranking_used</span> <span class="o">!=</span> <span class="s2">&quot;nes&quot;</span><span class="p">:</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>            <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">weights</span><span class="p">))</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>        <span class="n">scaled_noises</span> <span class="o">=</span> <span class="n">samples</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>        <span class="n">raw_noises</span> <span class="o">=</span> <span class="n">scaled_noises</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>        <span class="n">mu_grad</span> <span class="o">=</span> <span class="n">total</span><span class="p">(</span><span class="n">dot</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">scaled_noises</span><span class="p">))</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>        <span class="n">sigma_grad</span> <span class="o">=</span> <span class="n">total</span><span class="p">(</span><span class="n">dot</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="p">(</span><span class="n">raw_noises</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;mu&quot;</span><span class="p">:</span> <span class="n">mu_grad</span><span class="p">,</span> <span class="s2">&quot;sigma&quot;</span><span class="p">:</span> <span class="n">sigma_grad</span><span class="p">}</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>    <span class="k">def</span> <span class="nf">update_parameters</span><span class="p">(</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>        <span class="n">gradients</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>        <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>        <span class="n">learning_rates</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>        <span class="n">optimizers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ExpSeparableGaussian&quot;</span><span class="p">:</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>        <span class="n">mu_grad</span> <span class="o">=</span> <span class="n">gradients</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">]</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>        <span class="n">sigma_grad</span> <span class="o">=</span> <span class="n">gradients</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">]</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>        <span class="n">new_mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_follow_gradient</span><span class="p">(</span><span class="s2">&quot;mu&quot;</span><span class="p">,</span> <span class="n">mu_grad</span><span class="p">,</span> <span class="n">learning_rates</span><span class="o">=</span><span class="n">learning_rates</span><span class="p">,</span> <span class="n">optimizers</span><span class="o">=</span><span class="n">optimizers</span><span class="p">)</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>        <span class="n">new_sigma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>            <span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_follow_gradient</span><span class="p">(</span><span class="s2">&quot;sigma&quot;</span><span class="p">,</span> <span class="n">sigma_grad</span><span class="p">,</span> <span class="n">learning_rates</span><span class="o">=</span><span class="n">learning_rates</span><span class="p">,</span> <span class="n">optimizers</span><span class="o">=</span><span class="n">optimizers</span><span class="p">)</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>        <span class="p">)</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">modified_copy</span><span class="p">(</span><span class="n">mu</span><span class="o">=</span><span class="n">new_mu</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">new_sigma</span><span class="p">)</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">











  <div class="doc doc-object doc-method">



<h4 id="evotorch.algorithms.distributed.gaussian.SNES.DISTRIBUTION_TYPE.update_parameters" class="doc doc-heading">
<code class="highlight language-python"><span class="n">update_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">learning_rates</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">optimizers</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>


<a href="#evotorch.algorithms.distributed.gaussian.SNES.DISTRIBUTION_TYPE.update_parameters" class="headerlink" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>Do an update on the distribution by following the given gradients.</p>
<p>It is expected that the inheriting class has its own implementation
for this method.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>gradients</code></td>
        <td><code>dict</code></td>
        <td><p>Gradients, as a dictionary, which will be used for
computing the necessary updates.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>learning_rates</code></td>
        <td><code>Optional[dict]</code></td>
        <td><p>A dictionary which contains learning rates
for parameters that will be updated using a learning rate
coefficient.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>optimizers</code></td>
        <td><code>Optional[dict]</code></td>
        <td><p>A dictionary which contains optimizer objects
for parameters that will be updated using an adaptive
optimizer.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>ExpSeparableGaussian</code></td>
      <td><p>The updated copy of the distribution.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>evotorch/algorithms/distributed/gaussian.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">update_parameters</span><span class="p">(</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">gradients</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">learning_rates</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">optimizers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ExpSeparableGaussian&quot;</span><span class="p">:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n">mu_grad</span> <span class="o">=</span> <span class="n">gradients</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">]</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="n">sigma_grad</span> <span class="o">=</span> <span class="n">gradients</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">]</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="n">new_mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_follow_gradient</span><span class="p">(</span><span class="s2">&quot;mu&quot;</span><span class="p">,</span> <span class="n">mu_grad</span><span class="p">,</span> <span class="n">learning_rates</span><span class="o">=</span><span class="n">learning_rates</span><span class="p">,</span> <span class="n">optimizers</span><span class="o">=</span><span class="n">optimizers</span><span class="p">)</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="n">new_sigma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>        <span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_follow_gradient</span><span class="p">(</span><span class="s2">&quot;sigma&quot;</span><span class="p">,</span> <span class="n">sigma_grad</span><span class="p">,</span> <span class="n">learning_rates</span><span class="o">=</span><span class="n">learning_rates</span><span class="p">,</span> <span class="n">optimizers</span><span class="o">=</span><span class="n">optimizers</span><span class="p">)</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="p">)</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">modified_copy</span><span class="p">(</span><span class="n">mu</span><span class="o">=</span><span class="n">new_mu</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">new_sigma</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>





  <div class="doc doc-object doc-method">



<h3 id="evotorch.algorithms.distributed.gaussian.SNES.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">problem</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">stdev_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">radius_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">popsize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">center_learning_rate</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stdev_learning_rate</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scale_learning_rate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_interactions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">popsize_max</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">optimizer_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ranking_method</span><span class="o">=</span><span class="s1">&#39;nes&#39;</span><span class="p">,</span> <span class="n">center_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stdev_min</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stdev_max</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stdev_max_change</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">obj_index</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">distributed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">popsize_weighted_grad_avg</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

<a href="#evotorch.algorithms.distributed.gaussian.SNES.__init__" class="headerlink" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p><code>__init__(...)</code>: Initialize the SNES algorithm.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>problem</code></td>
        <td><code>Problem</code></td>
        <td><p>The problem object which is being worked on.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>stdev_init</code></td>
        <td><code>Union[float, Iterable[float], torch.Tensor]</code></td>
        <td><p>The initial standard deviation of the search
distribution, expressed as a scalar or as an array.
Determines the initial coverage area of the search
distribution.
If one wishes to configure the coverage area via the
argument <code>radius_init</code> instead, then <code>stdev_init</code> is expected
as None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>radius_init</code></td>
        <td><code>Union[float, Iterable[float], torch.Tensor]</code></td>
        <td><p>The initial radius of the search distribution,
expressed as a scalar.
Determines the initial coverage area of the search
distribution.
Here, "radius" is defined as the norm of the search
distribution.
If one wishes to configure the coverage area via the
argument <code>stdev_init</code> instead, then <code>radius_init</code> is expected
as None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>popsize</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>Population size. Can be specified as an int,
or can be left as None to let the solver decide.
In the case of SNES, <code>popsize</code> can be left as None,
in which case the default <code>popsize</code> will be computed
as <code>4 + floor(3 * log(n))</code> where <code>n</code> is the length
of a solution.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>center_learning_rate</code></td>
        <td><code>Optional[float]</code></td>
        <td><p>Learning rate for updating the mean
of the search distribution. Default value is 1.0</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>stdev_learning_rate</code></td>
        <td><code>Optional[float]</code></td>
        <td><p>Learning rate for updating the covariance
matrix of the search distribution.
The default value is <code>0.2 * (3 + log(n)) / sqrt(n)</code>
where <code>n</code> is the length of a solution.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>scale_learning_rate</code></td>
        <td><code>bool</code></td>
        <td><p>For SNES, there is a default standard
deviation learning rate value which is computed as
<code>0.2 * (3 + log(n)) / sqrt(n)</code> (where <code>n</code> is the solution
length).
If scale_learning_rate is True (which is the default),
then the effective learning rate for the standard deviation
becomes the provided <code>stdev_learning_rate</code> multiplied by this
default value. If <code>scale_learning_rate</code> is False, then the
effective standard deviation learning rate becomes
equal to the provided <code>stdev_learning_rate</code> value.</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>num_interactions</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>When given as an integer n,
it is ensured that a population has interacted with
the GymProblem's environment n times. If this target
has not been reached yet, then the population is declared
too small, and gets extended with more samples,
until n amount of interactions is reached.
When given as None, popsize is the only configuration
affecting the size of a population.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>popsize_max</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>Having <code>num_interactions</code> set as an integer
might cause the effective population size jump to
unnecesarily large numbers. To prevent this,
one can set <code>popsize_max</code> to specify an upper
bound for the effective population size.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>num_interactions</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>When given as an integer n,
it is ensured that a population has interacted with
the GymProblem's environment n times. If this target
has not been reached yet, then the population is declared
too small, and gets extended with more samples,
until n amount of interactions is reached.
When given as None, popsize is the only configuration
affecting the size of a population.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>popsize_max</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>Having <code>num_interactions</code> set as an integer
might cause the effective population size jump to
unnecesarily large numbers. To prevent this,
one can set <code>popsize_max</code> to specify an upper
bound for the effective population size.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>optimizer</code></td>
        <td></td>
        <td><p>The optimizer to be used while following the
estimated the gradients.
Can be given as None if a momentum-based optimizer
is not required.
Otherwise, can be given as a str containing the name
of the optimizer (e.g. 'adam', 'clipup');
or as an instance of evotorch.optimizers.TorchOptimizer
or evotorch.optimizers.ClipUp.
The default is None.
Note that, for ClipUp, the default maximum speed is set
as twice the given <code>center_learning_rate</code>.
This maximum speed can be configured by passing
<code>{"max_speed": ...}</code> to <code>optimizer_config</code>.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>optimizer_config</code></td>
        <td><code>Optional[dict]</code></td>
        <td><p>Configuration which will be passed
to the optimizer as keyword arguments.
See <code>evotorch.optimizers</code> for details about
which optimizer accepts which keyword arguments.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>ranking_method</code></td>
        <td><code>Optional[str]</code></td>
        <td><p>Which ranking method will be used for
fitness shaping. See the documentation of
<code>evotorch.ranking.rank(...)</code> for details.
The default is 'nes'.
Can be given as None if no such ranking is required.</p></td>
        <td><code>&#39;nes&#39;</code></td>
      </tr>
      <tr>
        <td><code>center_init</code></td>
        <td><code>Union[float, Iterable[float], torch.Tensor]</code></td>
        <td><p>The initial center solution.
Can be left as None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>stdev_min</code></td>
        <td><code>Union[float, Iterable[float], torch.Tensor]</code></td>
        <td><p>Minimum values for the standard deviation.
Expected as a 1-dimensional array to serve as a limiter
to the diagonals of the covariance matrix's square root.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>stdev_max</code></td>
        <td><code>Union[float, Iterable[float], torch.Tensor]</code></td>
        <td><p>Maximum values for the standard deviation.
Expected as a 1-dimensional array to serve as a limiter
to the diagonals of the covariance matrix's square root.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>stdev_max_change</code></td>
        <td><code>Union[float, Iterable[float], torch.Tensor]</code></td>
        <td><p>Maximum change allowed for when updating
the square roort of the covariance matrix.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>obj_index</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>Index of the objective according to which the
gradient estimations will be done.
For single-objective problems, this can be left as None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>distributed</code></td>
        <td><code>bool</code></td>
        <td><p>Whether or not the gradient computation will
be distributed. If <code>distributed</code> is given as False and
the problem is not parallelized, then everything will
be centralized (i.e. the entire computation will happen
in the main process).
If <code>distributed</code> is given as False, and the problem
is parallelized, then the population will be created
in the main process and then sent to remote workers
for parallelized evaluation, and then the remote fitnesses
will be collected by the main process again for computing
the search gradients.
If <code>distributed</code> is given as True, and the problem
is parallelized, then the search algorithm itself will
be distributed, in the sense that each remote actor will
generate its own population (such that the total population
size across all these actors becomes equal to <code>popsize</code>)
and will compute its own gradient, and then the main process
will collect these gradients, compute the averaged gradients
and update the main search distribution.
Non-distributed mode has the advantage of keeping the
population in the main process, which is good when one wishes
to do detailed monitoring during the evolutionary process,
but has the disadvantage of having to pass the solutions to
the remote actors and having to collect fitnesses, which
might result in increased interprocess communication traffic.
On the other hand, while it is not possible to monitor the
population in distributed mode, the distributed mode has the
advantage of significantly reducing the interprocess
communication traffic, since the only things communicated
with the remote actors are the search distributions (not the
solutions) and the gradients.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>popsize_weighted_grad_avg</code></td>
        <td><code>Optional[bool]</code></td>
        <td><p>Only to be used in distributed mode.
(where being in distributed mode means <code>distributed</code> is given
as True). In distributed mode, each actor remotely samples
its own solution batches and computes its own gradients.
These gradients are then collected, and a final average
gradient is computed.
If <code>popsize_weighted_grad_avg</code> is True, then, while averaging
over the gradients, each gradient will have its own weight
that is computed according to how many solutions were sampled
by the actor that produced the gradient.
If <code>popsize_weighted_grad_avg</code> is False, then, there will not
be weighted averaging (or, each gradient will have equal
weight).
If <code>popsize_weighted_grad_avg</code> is None, then, the gradient
weights will be equal a value for <code>num_interactions</code> is given
(because <code>num_interactions</code> affects the number of solutions
according to the episode lengths, and popsize-weighting the
gradients could be misleading); and the gradient weights will
be weighted according to the sub-population (i.e. sub-batch)
sizes if <code>num_interactions</code> is left as None.
The default value for <code>popsize_weighted_grad_avg</code> is None.
When the distributed mode is disabled (i.e. when <code>distributed</code>
is False), then the argument <code>popsize_weighted_grad_avg</code> is
expected as None.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>evotorch/algorithms/distributed/gaussian.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">problem</span><span class="p">:</span> <span class="n">Problem</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">stdev_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">radius_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">popsize</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n">center_learning_rate</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="n">stdev_learning_rate</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="n">scale_learning_rate</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="n">num_interactions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="n">popsize_max</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="n">optimizer_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="n">ranking_method</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;nes&quot;</span><span class="p">,</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="n">center_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>    <span class="n">stdev_min</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>    <span class="n">stdev_max</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>    <span class="n">stdev_max_change</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>    <span class="n">obj_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>    <span class="n">distributed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>    <span class="n">popsize_weighted_grad_avg</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a><span class="p">):</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a><span class="sd">    `__init__(...)`: Initialize the SNES algorithm.</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a><span class="sd">        problem: The problem object which is being worked on.</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a><span class="sd">        stdev_init: The initial standard deviation of the search</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a><span class="sd">            distribution, expressed as a scalar or as an array.</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a><span class="sd">            Determines the initial coverage area of the search</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a><span class="sd">            distribution.</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a><span class="sd">            If one wishes to configure the coverage area via the</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a><span class="sd">            argument `radius_init` instead, then `stdev_init` is expected</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a><span class="sd">            as None.</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a><span class="sd">        radius_init: The initial radius of the search distribution,</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a><span class="sd">            expressed as a scalar.</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a><span class="sd">            Determines the initial coverage area of the search</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a><span class="sd">            distribution.</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a><span class="sd">            Here, &quot;radius&quot; is defined as the norm of the search</span>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a><span class="sd">            distribution.</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a><span class="sd">            If one wishes to configure the coverage area via the</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a><span class="sd">            argument `stdev_init` instead, then `radius_init` is expected</span>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a><span class="sd">            as None.</span>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a><span class="sd">        popsize: Population size. Can be specified as an int,</span>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a><span class="sd">            or can be left as None to let the solver decide.</span>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a><span class="sd">            In the case of SNES, `popsize` can be left as None,</span>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a><span class="sd">            in which case the default `popsize` will be computed</span>
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a><span class="sd">            as `4 + floor(3 * log(n))` where `n` is the length</span>
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a><span class="sd">            of a solution.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a><span class="sd">        center_learning_rate: Learning rate for updating the mean</span>
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a><span class="sd">            of the search distribution. Default value is 1.0</span>
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a><span class="sd">        stdev_learning_rate: Learning rate for updating the covariance</span>
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a><span class="sd">            matrix of the search distribution.</span>
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a><span class="sd">            The default value is `0.2 * (3 + log(n)) / sqrt(n)`</span>
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a><span class="sd">            where `n` is the length of a solution.</span>
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a><span class="sd">        scale_learning_rate: For SNES, there is a default standard</span>
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a><span class="sd">            deviation learning rate value which is computed as</span>
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a><span class="sd">            `0.2 * (3 + log(n)) / sqrt(n)` (where `n` is the solution</span>
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a><span class="sd">            length).</span>
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a><span class="sd">            If scale_learning_rate is True (which is the default),</span>
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#__codelineno-0-62"></a><span class="sd">            then the effective learning rate for the standard deviation</span>
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#__codelineno-0-63"></a><span class="sd">            becomes the provided `stdev_learning_rate` multiplied by this</span>
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#__codelineno-0-64"></a><span class="sd">            default value. If `scale_learning_rate` is False, then the</span>
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#__codelineno-0-65"></a><span class="sd">            effective standard deviation learning rate becomes</span>
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#__codelineno-0-66"></a><span class="sd">            equal to the provided `stdev_learning_rate` value.</span>
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#__codelineno-0-67"></a><span class="sd">        num_interactions: When given as an integer n,</span>
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#__codelineno-0-68"></a><span class="sd">            it is ensured that a population has interacted with</span>
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#__codelineno-0-69"></a><span class="sd">            the GymProblem&#39;s environment n times. If this target</span>
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#__codelineno-0-70"></a><span class="sd">            has not been reached yet, then the population is declared</span>
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#__codelineno-0-71"></a><span class="sd">            too small, and gets extended with more samples,</span>
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#__codelineno-0-72"></a><span class="sd">            until n amount of interactions is reached.</span>
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#__codelineno-0-73"></a><span class="sd">            When given as None, popsize is the only configuration</span>
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#__codelineno-0-74"></a><span class="sd">            affecting the size of a population.</span>
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#__codelineno-0-75"></a><span class="sd">        popsize_max: Having `num_interactions` set as an integer</span>
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#__codelineno-0-76"></a><span class="sd">            might cause the effective population size jump to</span>
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#__codelineno-0-77"></a><span class="sd">            unnecesarily large numbers. To prevent this,</span>
<a id="__codelineno-0-78" name="__codelineno-0-78" href="#__codelineno-0-78"></a><span class="sd">            one can set `popsize_max` to specify an upper</span>
<a id="__codelineno-0-79" name="__codelineno-0-79" href="#__codelineno-0-79"></a><span class="sd">            bound for the effective population size.</span>
<a id="__codelineno-0-80" name="__codelineno-0-80" href="#__codelineno-0-80"></a><span class="sd">        num_interactions: When given as an integer n,</span>
<a id="__codelineno-0-81" name="__codelineno-0-81" href="#__codelineno-0-81"></a><span class="sd">            it is ensured that a population has interacted with</span>
<a id="__codelineno-0-82" name="__codelineno-0-82" href="#__codelineno-0-82"></a><span class="sd">            the GymProblem&#39;s environment n times. If this target</span>
<a id="__codelineno-0-83" name="__codelineno-0-83" href="#__codelineno-0-83"></a><span class="sd">            has not been reached yet, then the population is declared</span>
<a id="__codelineno-0-84" name="__codelineno-0-84" href="#__codelineno-0-84"></a><span class="sd">            too small, and gets extended with more samples,</span>
<a id="__codelineno-0-85" name="__codelineno-0-85" href="#__codelineno-0-85"></a><span class="sd">            until n amount of interactions is reached.</span>
<a id="__codelineno-0-86" name="__codelineno-0-86" href="#__codelineno-0-86"></a><span class="sd">            When given as None, popsize is the only configuration</span>
<a id="__codelineno-0-87" name="__codelineno-0-87" href="#__codelineno-0-87"></a><span class="sd">            affecting the size of a population.</span>
<a id="__codelineno-0-88" name="__codelineno-0-88" href="#__codelineno-0-88"></a><span class="sd">        popsize_max: Having `num_interactions` set as an integer</span>
<a id="__codelineno-0-89" name="__codelineno-0-89" href="#__codelineno-0-89"></a><span class="sd">            might cause the effective population size jump to</span>
<a id="__codelineno-0-90" name="__codelineno-0-90" href="#__codelineno-0-90"></a><span class="sd">            unnecesarily large numbers. To prevent this,</span>
<a id="__codelineno-0-91" name="__codelineno-0-91" href="#__codelineno-0-91"></a><span class="sd">            one can set `popsize_max` to specify an upper</span>
<a id="__codelineno-0-92" name="__codelineno-0-92" href="#__codelineno-0-92"></a><span class="sd">            bound for the effective population size.</span>
<a id="__codelineno-0-93" name="__codelineno-0-93" href="#__codelineno-0-93"></a><span class="sd">        optimizer: The optimizer to be used while following the</span>
<a id="__codelineno-0-94" name="__codelineno-0-94" href="#__codelineno-0-94"></a><span class="sd">            estimated the gradients.</span>
<a id="__codelineno-0-95" name="__codelineno-0-95" href="#__codelineno-0-95"></a><span class="sd">            Can be given as None if a momentum-based optimizer</span>
<a id="__codelineno-0-96" name="__codelineno-0-96" href="#__codelineno-0-96"></a><span class="sd">            is not required.</span>
<a id="__codelineno-0-97" name="__codelineno-0-97" href="#__codelineno-0-97"></a><span class="sd">            Otherwise, can be given as a str containing the name</span>
<a id="__codelineno-0-98" name="__codelineno-0-98" href="#__codelineno-0-98"></a><span class="sd">            of the optimizer (e.g. &#39;adam&#39;, &#39;clipup&#39;);</span>
<a id="__codelineno-0-99" name="__codelineno-0-99" href="#__codelineno-0-99"></a><span class="sd">            or as an instance of evotorch.optimizers.TorchOptimizer</span>
<a id="__codelineno-0-100" name="__codelineno-0-100" href="#__codelineno-0-100"></a><span class="sd">            or evotorch.optimizers.ClipUp.</span>
<a id="__codelineno-0-101" name="__codelineno-0-101" href="#__codelineno-0-101"></a><span class="sd">            The default is None.</span>
<a id="__codelineno-0-102" name="__codelineno-0-102" href="#__codelineno-0-102"></a><span class="sd">            Note that, for ClipUp, the default maximum speed is set</span>
<a id="__codelineno-0-103" name="__codelineno-0-103" href="#__codelineno-0-103"></a><span class="sd">            as twice the given `center_learning_rate`.</span>
<a id="__codelineno-0-104" name="__codelineno-0-104" href="#__codelineno-0-104"></a><span class="sd">            This maximum speed can be configured by passing</span>
<a id="__codelineno-0-105" name="__codelineno-0-105" href="#__codelineno-0-105"></a><span class="sd">            `{&quot;max_speed&quot;: ...}` to `optimizer_config`.</span>
<a id="__codelineno-0-106" name="__codelineno-0-106" href="#__codelineno-0-106"></a><span class="sd">        optimizer_config: Configuration which will be passed</span>
<a id="__codelineno-0-107" name="__codelineno-0-107" href="#__codelineno-0-107"></a><span class="sd">            to the optimizer as keyword arguments.</span>
<a id="__codelineno-0-108" name="__codelineno-0-108" href="#__codelineno-0-108"></a><span class="sd">            See `evotorch.optimizers` for details about</span>
<a id="__codelineno-0-109" name="__codelineno-0-109" href="#__codelineno-0-109"></a><span class="sd">            which optimizer accepts which keyword arguments.</span>
<a id="__codelineno-0-110" name="__codelineno-0-110" href="#__codelineno-0-110"></a><span class="sd">        ranking_method: Which ranking method will be used for</span>
<a id="__codelineno-0-111" name="__codelineno-0-111" href="#__codelineno-0-111"></a><span class="sd">            fitness shaping. See the documentation of</span>
<a id="__codelineno-0-112" name="__codelineno-0-112" href="#__codelineno-0-112"></a><span class="sd">            `evotorch.ranking.rank(...)` for details.</span>
<a id="__codelineno-0-113" name="__codelineno-0-113" href="#__codelineno-0-113"></a><span class="sd">            The default is &#39;nes&#39;.</span>
<a id="__codelineno-0-114" name="__codelineno-0-114" href="#__codelineno-0-114"></a><span class="sd">            Can be given as None if no such ranking is required.</span>
<a id="__codelineno-0-115" name="__codelineno-0-115" href="#__codelineno-0-115"></a><span class="sd">        center_init: The initial center solution.</span>
<a id="__codelineno-0-116" name="__codelineno-0-116" href="#__codelineno-0-116"></a><span class="sd">            Can be left as None.</span>
<a id="__codelineno-0-117" name="__codelineno-0-117" href="#__codelineno-0-117"></a><span class="sd">        stdev_min: Minimum values for the standard deviation.</span>
<a id="__codelineno-0-118" name="__codelineno-0-118" href="#__codelineno-0-118"></a><span class="sd">            Expected as a 1-dimensional array to serve as a limiter</span>
<a id="__codelineno-0-119" name="__codelineno-0-119" href="#__codelineno-0-119"></a><span class="sd">            to the diagonals of the covariance matrix&#39;s square root.</span>
<a id="__codelineno-0-120" name="__codelineno-0-120" href="#__codelineno-0-120"></a><span class="sd">        stdev_max: Maximum values for the standard deviation.</span>
<a id="__codelineno-0-121" name="__codelineno-0-121" href="#__codelineno-0-121"></a><span class="sd">            Expected as a 1-dimensional array to serve as a limiter</span>
<a id="__codelineno-0-122" name="__codelineno-0-122" href="#__codelineno-0-122"></a><span class="sd">            to the diagonals of the covariance matrix&#39;s square root.</span>
<a id="__codelineno-0-123" name="__codelineno-0-123" href="#__codelineno-0-123"></a><span class="sd">        stdev_max_change: Maximum change allowed for when updating</span>
<a id="__codelineno-0-124" name="__codelineno-0-124" href="#__codelineno-0-124"></a><span class="sd">            the square roort of the covariance matrix.</span>
<a id="__codelineno-0-125" name="__codelineno-0-125" href="#__codelineno-0-125"></a><span class="sd">        obj_index: Index of the objective according to which the</span>
<a id="__codelineno-0-126" name="__codelineno-0-126" href="#__codelineno-0-126"></a><span class="sd">            gradient estimations will be done.</span>
<a id="__codelineno-0-127" name="__codelineno-0-127" href="#__codelineno-0-127"></a><span class="sd">            For single-objective problems, this can be left as None.</span>
<a id="__codelineno-0-128" name="__codelineno-0-128" href="#__codelineno-0-128"></a><span class="sd">        distributed: Whether or not the gradient computation will</span>
<a id="__codelineno-0-129" name="__codelineno-0-129" href="#__codelineno-0-129"></a><span class="sd">            be distributed. If `distributed` is given as False and</span>
<a id="__codelineno-0-130" name="__codelineno-0-130" href="#__codelineno-0-130"></a><span class="sd">            the problem is not parallelized, then everything will</span>
<a id="__codelineno-0-131" name="__codelineno-0-131" href="#__codelineno-0-131"></a><span class="sd">            be centralized (i.e. the entire computation will happen</span>
<a id="__codelineno-0-132" name="__codelineno-0-132" href="#__codelineno-0-132"></a><span class="sd">            in the main process).</span>
<a id="__codelineno-0-133" name="__codelineno-0-133" href="#__codelineno-0-133"></a><span class="sd">            If `distributed` is given as False, and the problem</span>
<a id="__codelineno-0-134" name="__codelineno-0-134" href="#__codelineno-0-134"></a><span class="sd">            is parallelized, then the population will be created</span>
<a id="__codelineno-0-135" name="__codelineno-0-135" href="#__codelineno-0-135"></a><span class="sd">            in the main process and then sent to remote workers</span>
<a id="__codelineno-0-136" name="__codelineno-0-136" href="#__codelineno-0-136"></a><span class="sd">            for parallelized evaluation, and then the remote fitnesses</span>
<a id="__codelineno-0-137" name="__codelineno-0-137" href="#__codelineno-0-137"></a><span class="sd">            will be collected by the main process again for computing</span>
<a id="__codelineno-0-138" name="__codelineno-0-138" href="#__codelineno-0-138"></a><span class="sd">            the search gradients.</span>
<a id="__codelineno-0-139" name="__codelineno-0-139" href="#__codelineno-0-139"></a><span class="sd">            If `distributed` is given as True, and the problem</span>
<a id="__codelineno-0-140" name="__codelineno-0-140" href="#__codelineno-0-140"></a><span class="sd">            is parallelized, then the search algorithm itself will</span>
<a id="__codelineno-0-141" name="__codelineno-0-141" href="#__codelineno-0-141"></a><span class="sd">            be distributed, in the sense that each remote actor will</span>
<a id="__codelineno-0-142" name="__codelineno-0-142" href="#__codelineno-0-142"></a><span class="sd">            generate its own population (such that the total population</span>
<a id="__codelineno-0-143" name="__codelineno-0-143" href="#__codelineno-0-143"></a><span class="sd">            size across all these actors becomes equal to `popsize`)</span>
<a id="__codelineno-0-144" name="__codelineno-0-144" href="#__codelineno-0-144"></a><span class="sd">            and will compute its own gradient, and then the main process</span>
<a id="__codelineno-0-145" name="__codelineno-0-145" href="#__codelineno-0-145"></a><span class="sd">            will collect these gradients, compute the averaged gradients</span>
<a id="__codelineno-0-146" name="__codelineno-0-146" href="#__codelineno-0-146"></a><span class="sd">            and update the main search distribution.</span>
<a id="__codelineno-0-147" name="__codelineno-0-147" href="#__codelineno-0-147"></a><span class="sd">            Non-distributed mode has the advantage of keeping the</span>
<a id="__codelineno-0-148" name="__codelineno-0-148" href="#__codelineno-0-148"></a><span class="sd">            population in the main process, which is good when one wishes</span>
<a id="__codelineno-0-149" name="__codelineno-0-149" href="#__codelineno-0-149"></a><span class="sd">            to do detailed monitoring during the evolutionary process,</span>
<a id="__codelineno-0-150" name="__codelineno-0-150" href="#__codelineno-0-150"></a><span class="sd">            but has the disadvantage of having to pass the solutions to</span>
<a id="__codelineno-0-151" name="__codelineno-0-151" href="#__codelineno-0-151"></a><span class="sd">            the remote actors and having to collect fitnesses, which</span>
<a id="__codelineno-0-152" name="__codelineno-0-152" href="#__codelineno-0-152"></a><span class="sd">            might result in increased interprocess communication traffic.</span>
<a id="__codelineno-0-153" name="__codelineno-0-153" href="#__codelineno-0-153"></a><span class="sd">            On the other hand, while it is not possible to monitor the</span>
<a id="__codelineno-0-154" name="__codelineno-0-154" href="#__codelineno-0-154"></a><span class="sd">            population in distributed mode, the distributed mode has the</span>
<a id="__codelineno-0-155" name="__codelineno-0-155" href="#__codelineno-0-155"></a><span class="sd">            advantage of significantly reducing the interprocess</span>
<a id="__codelineno-0-156" name="__codelineno-0-156" href="#__codelineno-0-156"></a><span class="sd">            communication traffic, since the only things communicated</span>
<a id="__codelineno-0-157" name="__codelineno-0-157" href="#__codelineno-0-157"></a><span class="sd">            with the remote actors are the search distributions (not the</span>
<a id="__codelineno-0-158" name="__codelineno-0-158" href="#__codelineno-0-158"></a><span class="sd">            solutions) and the gradients.</span>
<a id="__codelineno-0-159" name="__codelineno-0-159" href="#__codelineno-0-159"></a><span class="sd">        popsize_weighted_grad_avg: Only to be used in distributed mode.</span>
<a id="__codelineno-0-160" name="__codelineno-0-160" href="#__codelineno-0-160"></a><span class="sd">            (where being in distributed mode means `distributed` is given</span>
<a id="__codelineno-0-161" name="__codelineno-0-161" href="#__codelineno-0-161"></a><span class="sd">            as True). In distributed mode, each actor remotely samples</span>
<a id="__codelineno-0-162" name="__codelineno-0-162" href="#__codelineno-0-162"></a><span class="sd">            its own solution batches and computes its own gradients.</span>
<a id="__codelineno-0-163" name="__codelineno-0-163" href="#__codelineno-0-163"></a><span class="sd">            These gradients are then collected, and a final average</span>
<a id="__codelineno-0-164" name="__codelineno-0-164" href="#__codelineno-0-164"></a><span class="sd">            gradient is computed.</span>
<a id="__codelineno-0-165" name="__codelineno-0-165" href="#__codelineno-0-165"></a><span class="sd">            If `popsize_weighted_grad_avg` is True, then, while averaging</span>
<a id="__codelineno-0-166" name="__codelineno-0-166" href="#__codelineno-0-166"></a><span class="sd">            over the gradients, each gradient will have its own weight</span>
<a id="__codelineno-0-167" name="__codelineno-0-167" href="#__codelineno-0-167"></a><span class="sd">            that is computed according to how many solutions were sampled</span>
<a id="__codelineno-0-168" name="__codelineno-0-168" href="#__codelineno-0-168"></a><span class="sd">            by the actor that produced the gradient.</span>
<a id="__codelineno-0-169" name="__codelineno-0-169" href="#__codelineno-0-169"></a><span class="sd">            If `popsize_weighted_grad_avg` is False, then, there will not</span>
<a id="__codelineno-0-170" name="__codelineno-0-170" href="#__codelineno-0-170"></a><span class="sd">            be weighted averaging (or, each gradient will have equal</span>
<a id="__codelineno-0-171" name="__codelineno-0-171" href="#__codelineno-0-171"></a><span class="sd">            weight).</span>
<a id="__codelineno-0-172" name="__codelineno-0-172" href="#__codelineno-0-172"></a><span class="sd">            If `popsize_weighted_grad_avg` is None, then, the gradient</span>
<a id="__codelineno-0-173" name="__codelineno-0-173" href="#__codelineno-0-173"></a><span class="sd">            weights will be equal a value for `num_interactions` is given</span>
<a id="__codelineno-0-174" name="__codelineno-0-174" href="#__codelineno-0-174"></a><span class="sd">            (because `num_interactions` affects the number of solutions</span>
<a id="__codelineno-0-175" name="__codelineno-0-175" href="#__codelineno-0-175"></a><span class="sd">            according to the episode lengths, and popsize-weighting the</span>
<a id="__codelineno-0-176" name="__codelineno-0-176" href="#__codelineno-0-176"></a><span class="sd">            gradients could be misleading); and the gradient weights will</span>
<a id="__codelineno-0-177" name="__codelineno-0-177" href="#__codelineno-0-177"></a><span class="sd">            be weighted according to the sub-population (i.e. sub-batch)</span>
<a id="__codelineno-0-178" name="__codelineno-0-178" href="#__codelineno-0-178"></a><span class="sd">            sizes if `num_interactions` is left as None.</span>
<a id="__codelineno-0-179" name="__codelineno-0-179" href="#__codelineno-0-179"></a><span class="sd">            The default value for `popsize_weighted_grad_avg` is None.</span>
<a id="__codelineno-0-180" name="__codelineno-0-180" href="#__codelineno-0-180"></a><span class="sd">            When the distributed mode is disabled (i.e. when `distributed`</span>
<a id="__codelineno-0-181" name="__codelineno-0-181" href="#__codelineno-0-181"></a><span class="sd">            is False), then the argument `popsize_weighted_grad_avg` is</span>
<a id="__codelineno-0-182" name="__codelineno-0-182" href="#__codelineno-0-182"></a><span class="sd">            expected as None.</span>
<a id="__codelineno-0-183" name="__codelineno-0-183" href="#__codelineno-0-183"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-184" name="__codelineno-0-184" href="#__codelineno-0-184"></a>
<a id="__codelineno-0-185" name="__codelineno-0-185" href="#__codelineno-0-185"></a>    <span class="k">if</span> <span class="n">popsize</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-186" name="__codelineno-0-186" href="#__codelineno-0-186"></a>        <span class="n">popsize</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">4</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="mi">3</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">problem</span><span class="o">.</span><span class="n">solution_length</span><span class="p">)))</span>
<a id="__codelineno-0-187" name="__codelineno-0-187" href="#__codelineno-0-187"></a>
<a id="__codelineno-0-188" name="__codelineno-0-188" href="#__codelineno-0-188"></a>    <span class="k">if</span> <span class="n">center_learning_rate</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-189" name="__codelineno-0-189" href="#__codelineno-0-189"></a>        <span class="n">center_learning_rate</span> <span class="o">=</span> <span class="mf">1.0</span>
<a id="__codelineno-0-190" name="__codelineno-0-190" href="#__codelineno-0-190"></a>
<a id="__codelineno-0-191" name="__codelineno-0-191" href="#__codelineno-0-191"></a>    <span class="k">def</span> <span class="nf">default_stdev_lr</span><span class="p">():</span>
<a id="__codelineno-0-192" name="__codelineno-0-192" href="#__codelineno-0-192"></a>        <span class="n">n</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">solution_length</span>
<a id="__codelineno-0-193" name="__codelineno-0-193" href="#__codelineno-0-193"></a>        <span class="k">return</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">3</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n</span><span class="p">))</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<a id="__codelineno-0-194" name="__codelineno-0-194" href="#__codelineno-0-194"></a>
<a id="__codelineno-0-195" name="__codelineno-0-195" href="#__codelineno-0-195"></a>    <span class="k">if</span> <span class="n">stdev_learning_rate</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-196" name="__codelineno-0-196" href="#__codelineno-0-196"></a>        <span class="n">stdev_learning_rate</span> <span class="o">=</span> <span class="n">default_stdev_lr</span><span class="p">()</span>
<a id="__codelineno-0-197" name="__codelineno-0-197" href="#__codelineno-0-197"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-198" name="__codelineno-0-198" href="#__codelineno-0-198"></a>        <span class="n">stdev_learning_rate</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">stdev_learning_rate</span><span class="p">)</span>
<a id="__codelineno-0-199" name="__codelineno-0-199" href="#__codelineno-0-199"></a>        <span class="k">if</span> <span class="n">scale_learning_rate</span><span class="p">:</span>
<a id="__codelineno-0-200" name="__codelineno-0-200" href="#__codelineno-0-200"></a>            <span class="n">stdev_learning_rate</span> <span class="o">*=</span> <span class="n">default_stdev_lr</span><span class="p">()</span>
<a id="__codelineno-0-201" name="__codelineno-0-201" href="#__codelineno-0-201"></a>
<a id="__codelineno-0-202" name="__codelineno-0-202" href="#__codelineno-0-202"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-203" name="__codelineno-0-203" href="#__codelineno-0-203"></a>        <span class="n">problem</span><span class="p">,</span>
<a id="__codelineno-0-204" name="__codelineno-0-204" href="#__codelineno-0-204"></a>        <span class="n">popsize</span><span class="o">=</span><span class="n">popsize</span><span class="p">,</span>
<a id="__codelineno-0-205" name="__codelineno-0-205" href="#__codelineno-0-205"></a>        <span class="n">center_learning_rate</span><span class="o">=</span><span class="n">center_learning_rate</span><span class="p">,</span>
<a id="__codelineno-0-206" name="__codelineno-0-206" href="#__codelineno-0-206"></a>        <span class="n">stdev_learning_rate</span><span class="o">=</span><span class="n">stdev_learning_rate</span><span class="p">,</span>
<a id="__codelineno-0-207" name="__codelineno-0-207" href="#__codelineno-0-207"></a>        <span class="n">stdev_init</span><span class="o">=</span><span class="n">stdev_init</span><span class="p">,</span>
<a id="__codelineno-0-208" name="__codelineno-0-208" href="#__codelineno-0-208"></a>        <span class="n">radius_init</span><span class="o">=</span><span class="n">radius_init</span><span class="p">,</span>
<a id="__codelineno-0-209" name="__codelineno-0-209" href="#__codelineno-0-209"></a>        <span class="n">popsize_max</span><span class="o">=</span><span class="n">popsize_max</span><span class="p">,</span>
<a id="__codelineno-0-210" name="__codelineno-0-210" href="#__codelineno-0-210"></a>        <span class="n">num_interactions</span><span class="o">=</span><span class="n">num_interactions</span><span class="p">,</span>
<a id="__codelineno-0-211" name="__codelineno-0-211" href="#__codelineno-0-211"></a>        <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
<a id="__codelineno-0-212" name="__codelineno-0-212" href="#__codelineno-0-212"></a>        <span class="n">optimizer_config</span><span class="o">=</span><span class="n">optimizer_config</span><span class="p">,</span>
<a id="__codelineno-0-213" name="__codelineno-0-213" href="#__codelineno-0-213"></a>        <span class="n">ranking_method</span><span class="o">=</span><span class="n">ranking_method</span><span class="p">,</span>
<a id="__codelineno-0-214" name="__codelineno-0-214" href="#__codelineno-0-214"></a>        <span class="n">center_init</span><span class="o">=</span><span class="n">center_init</span><span class="p">,</span>
<a id="__codelineno-0-215" name="__codelineno-0-215" href="#__codelineno-0-215"></a>        <span class="n">stdev_min</span><span class="o">=</span><span class="n">stdev_min</span><span class="p">,</span>
<a id="__codelineno-0-216" name="__codelineno-0-216" href="#__codelineno-0-216"></a>        <span class="n">stdev_max</span><span class="o">=</span><span class="n">stdev_max</span><span class="p">,</span>
<a id="__codelineno-0-217" name="__codelineno-0-217" href="#__codelineno-0-217"></a>        <span class="n">stdev_max_change</span><span class="o">=</span><span class="n">stdev_max_change</span><span class="p">,</span>
<a id="__codelineno-0-218" name="__codelineno-0-218" href="#__codelineno-0-218"></a>        <span class="n">obj_index</span><span class="o">=</span><span class="n">obj_index</span><span class="p">,</span>
<a id="__codelineno-0-219" name="__codelineno-0-219" href="#__codelineno-0-219"></a>        <span class="n">distributed</span><span class="o">=</span><span class="n">distributed</span><span class="p">,</span>
<a id="__codelineno-0-220" name="__codelineno-0-220" href="#__codelineno-0-220"></a>        <span class="n">popsize_weighted_grad_avg</span><span class="o">=</span><span class="n">popsize_weighted_grad_avg</span><span class="p">,</span>
<a id="__codelineno-0-221" name="__codelineno-0-221" href="#__codelineno-0-221"></a>    <span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h2 id="evotorch.algorithms.distributed.gaussian.XNES" class="doc doc-heading">
        <code>
XNES            (<a class="autorefs autorefs-internal" title="evotorch.algorithms.distributed.gaussian.GaussianSearchAlgorithm" href="#evotorch.algorithms.distributed.gaussian.GaussianSearchAlgorithm">GaussianSearchAlgorithm</a>)
        </code>



<a href="#evotorch.algorithms.distributed.gaussian.XNES" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents ">

      <p>Inspired by the implementation at:
<a href="http://schaul.site44.com/code/xnes.py">http://schaul.site44.com/code/xnes.py</a>
<a href="https://github.com/pybrain/pybrain/blob/master/pybrain/optimization/distributionbased/xnes.py">https://github.com/pybrain/pybrain/blob/master/pybrain/optimization/distributionbased/xnes.py</a></p>
<div class="admonition reference">
<p class="admonition-title">Reference</p>
<p>Glasmachers, Tobias, et al.
Exponential natural evolution strategies.
Proceedings of the 12<sup>th</sup> annual conference on Genetic and evolutionary
computation (GECCO 2010).</p>
</div>

        <details class="quote">
          <summary>Source code in <code>evotorch/algorithms/distributed/gaussian.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">class</span> <span class="nc">XNES</span><span class="p">(</span><span class="n">GaussianSearchAlgorithm</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="sd">    XNES: Exponential Natural Evolution Strategies</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">    Inspired by the implementation at:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">    http://schaul.site44.com/code/xnes.py</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">    https://github.com/pybrain/pybrain/blob/master/pybrain/optimization/distributionbased/xnes.py</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">    Reference:</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">        Glasmachers, Tobias, et al.</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="sd">        Exponential natural evolution strategies.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="sd">        Proceedings of the 12th annual conference on Genetic and evolutionary</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a><span class="sd">        computation (GECCO 2010).</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="n">DISTRIBUTION_TYPE</span> <span class="o">=</span> <span class="n">ExpGaussian</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>    <span class="n">DISTRIBUTION_PARAMS</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>        <span class="n">problem</span><span class="p">:</span> <span class="n">Problem</span><span class="p">,</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>        <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>        <span class="n">stdev_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>        <span class="n">radius_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>        <span class="n">popsize</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>        <span class="n">center_learning_rate</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>        <span class="n">stdev_learning_rate</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>        <span class="n">scale_learning_rate</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>        <span class="n">num_interactions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>        <span class="n">popsize_max</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>        <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>        <span class="n">optimizer_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>        <span class="n">ranking_method</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;nes&quot;</span><span class="p">,</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>        <span class="n">center_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>        <span class="n">obj_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a>        <span class="n">distributed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>        <span class="n">popsize_weighted_grad_avg</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>    <span class="p">):</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a><span class="sd">        `__init__(...)`: Initialize the XNES algorithm.</span>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a><span class="sd">            problem: The problem object which is being worked on.</span>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a><span class="sd">            stdev_init: The initial standard deviation of the search</span>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a><span class="sd">                distribution, expressed as a scalar or as an array.</span>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a><span class="sd">                Determines the initial coverage area of the search</span>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a><span class="sd">                distribution.</span>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a><span class="sd">                If one wishes to configure the coverage area via the</span>
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a><span class="sd">                argument `radius_init` instead, then `stdev_init` is expected</span>
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a><span class="sd">                as None.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a><span class="sd">            radius_init: The initial radius of the search distribution,</span>
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a><span class="sd">                expressed as a scalar.</span>
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a><span class="sd">                Determines the initial coverage area of the search</span>
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a><span class="sd">                distribution.</span>
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a><span class="sd">                Here, &quot;radius&quot; is defined as the norm of the search</span>
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a><span class="sd">                distribution.</span>
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a><span class="sd">                If one wishes to configure the coverage area via the</span>
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a><span class="sd">                argument `stdev_init` instead, then `radius_init` is expected</span>
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a><span class="sd">                as None.</span>
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a><span class="sd">            popsize: Population size. Can be specified as an int,</span>
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a><span class="sd">                or can be left as None to let the solver decide.</span>
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#__codelineno-0-62"></a><span class="sd">                In the case of SNES, `popsize` can be left as None,</span>
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#__codelineno-0-63"></a><span class="sd">                in which case the default `popsize` will be computed</span>
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#__codelineno-0-64"></a><span class="sd">                as `4 + floor(3 * log(n))` where `n` is the length</span>
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#__codelineno-0-65"></a><span class="sd">                of a solution.</span>
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#__codelineno-0-66"></a><span class="sd">            center_learning_rate: Learning rate for updating the mean</span>
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#__codelineno-0-67"></a><span class="sd">                of the search distribution. Default value is 1.0</span>
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#__codelineno-0-68"></a><span class="sd">            stdev_learning_rate: Learning rate for updating the covariance</span>
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#__codelineno-0-69"></a><span class="sd">                matrix of the search distribution.</span>
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#__codelineno-0-70"></a><span class="sd">                The default value is `0.6 * (3 + log(n)) / (n * sqrt(n))`</span>
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#__codelineno-0-71"></a><span class="sd">                where `n` is the length of a solution.</span>
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#__codelineno-0-72"></a><span class="sd">            scale_learning_rate: For SNES, there is a default standard</span>
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#__codelineno-0-73"></a><span class="sd">                deviation learning rate value which is computed as</span>
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#__codelineno-0-74"></a><span class="sd">                `0.6 * (3 + log(n)) / (n * sqrt(n))` (where `n` is the solution</span>
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#__codelineno-0-75"></a><span class="sd">                length).</span>
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#__codelineno-0-76"></a><span class="sd">                If scale_learning_rate is True (which is the default),</span>
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#__codelineno-0-77"></a><span class="sd">                then the effective learning rate for the standard deviation</span>
<a id="__codelineno-0-78" name="__codelineno-0-78" href="#__codelineno-0-78"></a><span class="sd">                becomes the provided `stdev_learning_rate` multiplied by this</span>
<a id="__codelineno-0-79" name="__codelineno-0-79" href="#__codelineno-0-79"></a><span class="sd">                default value. If `scale_learning_rate` is False, then the</span>
<a id="__codelineno-0-80" name="__codelineno-0-80" href="#__codelineno-0-80"></a><span class="sd">                effective standard deviation learning rate becomes</span>
<a id="__codelineno-0-81" name="__codelineno-0-81" href="#__codelineno-0-81"></a><span class="sd">                equal to the provided `stdev_learning_rate` value.</span>
<a id="__codelineno-0-82" name="__codelineno-0-82" href="#__codelineno-0-82"></a><span class="sd">            num_interactions: When given as an integer n,</span>
<a id="__codelineno-0-83" name="__codelineno-0-83" href="#__codelineno-0-83"></a><span class="sd">                it is ensured that a population has interacted with</span>
<a id="__codelineno-0-84" name="__codelineno-0-84" href="#__codelineno-0-84"></a><span class="sd">                the GymProblem&#39;s environment n times. If this target</span>
<a id="__codelineno-0-85" name="__codelineno-0-85" href="#__codelineno-0-85"></a><span class="sd">                has not been reached yet, then the population is declared</span>
<a id="__codelineno-0-86" name="__codelineno-0-86" href="#__codelineno-0-86"></a><span class="sd">                too small, and gets extended with more samples,</span>
<a id="__codelineno-0-87" name="__codelineno-0-87" href="#__codelineno-0-87"></a><span class="sd">                until n amount of interactions is reached.</span>
<a id="__codelineno-0-88" name="__codelineno-0-88" href="#__codelineno-0-88"></a><span class="sd">                When given as None, popsize is the only configuration</span>
<a id="__codelineno-0-89" name="__codelineno-0-89" href="#__codelineno-0-89"></a><span class="sd">                affecting the size of a population.</span>
<a id="__codelineno-0-90" name="__codelineno-0-90" href="#__codelineno-0-90"></a><span class="sd">            popsize_max: Having `num_interactions` set as an integer</span>
<a id="__codelineno-0-91" name="__codelineno-0-91" href="#__codelineno-0-91"></a><span class="sd">                might cause the effective population size jump to</span>
<a id="__codelineno-0-92" name="__codelineno-0-92" href="#__codelineno-0-92"></a><span class="sd">                unnecesarily large numbers. To prevent this,</span>
<a id="__codelineno-0-93" name="__codelineno-0-93" href="#__codelineno-0-93"></a><span class="sd">                one can set `popsize_max` to specify an upper</span>
<a id="__codelineno-0-94" name="__codelineno-0-94" href="#__codelineno-0-94"></a><span class="sd">                bound for the effective population size.</span>
<a id="__codelineno-0-95" name="__codelineno-0-95" href="#__codelineno-0-95"></a><span class="sd">            num_interactions: When given as an integer n,</span>
<a id="__codelineno-0-96" name="__codelineno-0-96" href="#__codelineno-0-96"></a><span class="sd">                it is ensured that a population has interacted with</span>
<a id="__codelineno-0-97" name="__codelineno-0-97" href="#__codelineno-0-97"></a><span class="sd">                the GymProblem&#39;s environment n times. If this target</span>
<a id="__codelineno-0-98" name="__codelineno-0-98" href="#__codelineno-0-98"></a><span class="sd">                has not been reached yet, then the population is declared</span>
<a id="__codelineno-0-99" name="__codelineno-0-99" href="#__codelineno-0-99"></a><span class="sd">                too small, and gets extended with more samples,</span>
<a id="__codelineno-0-100" name="__codelineno-0-100" href="#__codelineno-0-100"></a><span class="sd">                until n amount of interactions is reached.</span>
<a id="__codelineno-0-101" name="__codelineno-0-101" href="#__codelineno-0-101"></a><span class="sd">                When given as None, popsize is the only configuration</span>
<a id="__codelineno-0-102" name="__codelineno-0-102" href="#__codelineno-0-102"></a><span class="sd">                affecting the size of a population.</span>
<a id="__codelineno-0-103" name="__codelineno-0-103" href="#__codelineno-0-103"></a><span class="sd">            optimizer: The optimizer to be used while following the</span>
<a id="__codelineno-0-104" name="__codelineno-0-104" href="#__codelineno-0-104"></a><span class="sd">                estimated the gradients.</span>
<a id="__codelineno-0-105" name="__codelineno-0-105" href="#__codelineno-0-105"></a><span class="sd">                Can be given as None if a momentum-based optimizer</span>
<a id="__codelineno-0-106" name="__codelineno-0-106" href="#__codelineno-0-106"></a><span class="sd">                is not required.</span>
<a id="__codelineno-0-107" name="__codelineno-0-107" href="#__codelineno-0-107"></a><span class="sd">                Otherwise, can be given as a str containing the name</span>
<a id="__codelineno-0-108" name="__codelineno-0-108" href="#__codelineno-0-108"></a><span class="sd">                of the optimizer (e.g. &#39;adam&#39;, &#39;clipup&#39;);</span>
<a id="__codelineno-0-109" name="__codelineno-0-109" href="#__codelineno-0-109"></a><span class="sd">                or as an instance of evotorch.optimizers.TorchOptimizer</span>
<a id="__codelineno-0-110" name="__codelineno-0-110" href="#__codelineno-0-110"></a><span class="sd">                or evotorch.optimizers.ClipUp.</span>
<a id="__codelineno-0-111" name="__codelineno-0-111" href="#__codelineno-0-111"></a><span class="sd">                The default is None.</span>
<a id="__codelineno-0-112" name="__codelineno-0-112" href="#__codelineno-0-112"></a><span class="sd">                Note that, for ClipUp, the default maximum speed is set</span>
<a id="__codelineno-0-113" name="__codelineno-0-113" href="#__codelineno-0-113"></a><span class="sd">                as twice the given `center_learning_rate`.</span>
<a id="__codelineno-0-114" name="__codelineno-0-114" href="#__codelineno-0-114"></a><span class="sd">                This maximum speed can be configured by passing</span>
<a id="__codelineno-0-115" name="__codelineno-0-115" href="#__codelineno-0-115"></a><span class="sd">                `{&quot;max_speed&quot;: ...}` to `optimizer_config`.</span>
<a id="__codelineno-0-116" name="__codelineno-0-116" href="#__codelineno-0-116"></a><span class="sd">            optimizer_config: Configuration which will be passed</span>
<a id="__codelineno-0-117" name="__codelineno-0-117" href="#__codelineno-0-117"></a><span class="sd">                to the optimizer as keyword arguments.</span>
<a id="__codelineno-0-118" name="__codelineno-0-118" href="#__codelineno-0-118"></a><span class="sd">                See `evotorch.optimizers` for details about</span>
<a id="__codelineno-0-119" name="__codelineno-0-119" href="#__codelineno-0-119"></a><span class="sd">                which optimizer accepts which keyword arguments.</span>
<a id="__codelineno-0-120" name="__codelineno-0-120" href="#__codelineno-0-120"></a><span class="sd">            ranking_method: Which ranking method will be used for</span>
<a id="__codelineno-0-121" name="__codelineno-0-121" href="#__codelineno-0-121"></a><span class="sd">                fitness shaping. See the documentation of</span>
<a id="__codelineno-0-122" name="__codelineno-0-122" href="#__codelineno-0-122"></a><span class="sd">                `evotorch.ranking.rank(...)` for details.</span>
<a id="__codelineno-0-123" name="__codelineno-0-123" href="#__codelineno-0-123"></a><span class="sd">                The default is &#39;nes&#39;.</span>
<a id="__codelineno-0-124" name="__codelineno-0-124" href="#__codelineno-0-124"></a><span class="sd">                Can be given as None if no such ranking is required.</span>
<a id="__codelineno-0-125" name="__codelineno-0-125" href="#__codelineno-0-125"></a><span class="sd">            center_init: The initial center solution.</span>
<a id="__codelineno-0-126" name="__codelineno-0-126" href="#__codelineno-0-126"></a><span class="sd">                Can be left as None.</span>
<a id="__codelineno-0-127" name="__codelineno-0-127" href="#__codelineno-0-127"></a><span class="sd">            obj_index: Index of the objective according to which the</span>
<a id="__codelineno-0-128" name="__codelineno-0-128" href="#__codelineno-0-128"></a><span class="sd">                gradient estimations will be done.</span>
<a id="__codelineno-0-129" name="__codelineno-0-129" href="#__codelineno-0-129"></a><span class="sd">                For single-objective problems, this can be left as None.</span>
<a id="__codelineno-0-130" name="__codelineno-0-130" href="#__codelineno-0-130"></a><span class="sd">            distributed: Whether or not the gradient computation will</span>
<a id="__codelineno-0-131" name="__codelineno-0-131" href="#__codelineno-0-131"></a><span class="sd">                be distributed. If `distributed` is given as False and</span>
<a id="__codelineno-0-132" name="__codelineno-0-132" href="#__codelineno-0-132"></a><span class="sd">                the problem is not parallelized, then everything will</span>
<a id="__codelineno-0-133" name="__codelineno-0-133" href="#__codelineno-0-133"></a><span class="sd">                be centralized (i.e. the entire computation will happen</span>
<a id="__codelineno-0-134" name="__codelineno-0-134" href="#__codelineno-0-134"></a><span class="sd">                in the main process).</span>
<a id="__codelineno-0-135" name="__codelineno-0-135" href="#__codelineno-0-135"></a><span class="sd">                If `distributed` is given as False, and the problem</span>
<a id="__codelineno-0-136" name="__codelineno-0-136" href="#__codelineno-0-136"></a><span class="sd">                is parallelized, then the population will be created</span>
<a id="__codelineno-0-137" name="__codelineno-0-137" href="#__codelineno-0-137"></a><span class="sd">                in the main process and then sent to remote workers</span>
<a id="__codelineno-0-138" name="__codelineno-0-138" href="#__codelineno-0-138"></a><span class="sd">                for parallelized evaluation, and then the remote fitnesses</span>
<a id="__codelineno-0-139" name="__codelineno-0-139" href="#__codelineno-0-139"></a><span class="sd">                will be collected by the main process again for computing</span>
<a id="__codelineno-0-140" name="__codelineno-0-140" href="#__codelineno-0-140"></a><span class="sd">                the search gradients.</span>
<a id="__codelineno-0-141" name="__codelineno-0-141" href="#__codelineno-0-141"></a><span class="sd">                If `distributed` is given as True, and the problem</span>
<a id="__codelineno-0-142" name="__codelineno-0-142" href="#__codelineno-0-142"></a><span class="sd">                is parallelized, then the search algorithm itself will</span>
<a id="__codelineno-0-143" name="__codelineno-0-143" href="#__codelineno-0-143"></a><span class="sd">                be distributed, in the sense that each remote actor will</span>
<a id="__codelineno-0-144" name="__codelineno-0-144" href="#__codelineno-0-144"></a><span class="sd">                generate its own population (such that the total population</span>
<a id="__codelineno-0-145" name="__codelineno-0-145" href="#__codelineno-0-145"></a><span class="sd">                size across all these actors becomes equal to `popsize`)</span>
<a id="__codelineno-0-146" name="__codelineno-0-146" href="#__codelineno-0-146"></a><span class="sd">                and will compute its own gradient, and then the main process</span>
<a id="__codelineno-0-147" name="__codelineno-0-147" href="#__codelineno-0-147"></a><span class="sd">                will collect these gradients, compute the averaged gradients</span>
<a id="__codelineno-0-148" name="__codelineno-0-148" href="#__codelineno-0-148"></a><span class="sd">                and update the main search distribution.</span>
<a id="__codelineno-0-149" name="__codelineno-0-149" href="#__codelineno-0-149"></a><span class="sd">                Non-distributed mode has the advantage of keeping the</span>
<a id="__codelineno-0-150" name="__codelineno-0-150" href="#__codelineno-0-150"></a><span class="sd">                population in the main process, which is good when one wishes</span>
<a id="__codelineno-0-151" name="__codelineno-0-151" href="#__codelineno-0-151"></a><span class="sd">                to do detailed monitoring during the evolutionary process,</span>
<a id="__codelineno-0-152" name="__codelineno-0-152" href="#__codelineno-0-152"></a><span class="sd">                but has the disadvantage of having to pass the solutions to</span>
<a id="__codelineno-0-153" name="__codelineno-0-153" href="#__codelineno-0-153"></a><span class="sd">                the remote actors and having to collect fitnesses, which</span>
<a id="__codelineno-0-154" name="__codelineno-0-154" href="#__codelineno-0-154"></a><span class="sd">                might result in increased interprocess communication traffic.</span>
<a id="__codelineno-0-155" name="__codelineno-0-155" href="#__codelineno-0-155"></a><span class="sd">                On the other hand, while it is not possible to monitor the</span>
<a id="__codelineno-0-156" name="__codelineno-0-156" href="#__codelineno-0-156"></a><span class="sd">                population in distributed mode, the distributed mode has the</span>
<a id="__codelineno-0-157" name="__codelineno-0-157" href="#__codelineno-0-157"></a><span class="sd">                advantage of significantly reducing the interprocess</span>
<a id="__codelineno-0-158" name="__codelineno-0-158" href="#__codelineno-0-158"></a><span class="sd">                communication traffic, since the only things communicated</span>
<a id="__codelineno-0-159" name="__codelineno-0-159" href="#__codelineno-0-159"></a><span class="sd">                with the remote actors are the search distributions (not the</span>
<a id="__codelineno-0-160" name="__codelineno-0-160" href="#__codelineno-0-160"></a><span class="sd">                solutions) and the gradients.</span>
<a id="__codelineno-0-161" name="__codelineno-0-161" href="#__codelineno-0-161"></a><span class="sd">            popsize_weighted_grad_avg: Only to be used in distributed mode.</span>
<a id="__codelineno-0-162" name="__codelineno-0-162" href="#__codelineno-0-162"></a><span class="sd">                (where being in distributed mode means `distributed` is given</span>
<a id="__codelineno-0-163" name="__codelineno-0-163" href="#__codelineno-0-163"></a><span class="sd">                as True). In distributed mode, each actor remotely samples</span>
<a id="__codelineno-0-164" name="__codelineno-0-164" href="#__codelineno-0-164"></a><span class="sd">                its own solution batches and computes its own gradients.</span>
<a id="__codelineno-0-165" name="__codelineno-0-165" href="#__codelineno-0-165"></a><span class="sd">                These gradients are then collected, and a final average</span>
<a id="__codelineno-0-166" name="__codelineno-0-166" href="#__codelineno-0-166"></a><span class="sd">                gradient is computed.</span>
<a id="__codelineno-0-167" name="__codelineno-0-167" href="#__codelineno-0-167"></a><span class="sd">                If `popsize_weighted_grad_avg` is True, then, while averaging</span>
<a id="__codelineno-0-168" name="__codelineno-0-168" href="#__codelineno-0-168"></a><span class="sd">                over the gradients, each gradient will have its own weight</span>
<a id="__codelineno-0-169" name="__codelineno-0-169" href="#__codelineno-0-169"></a><span class="sd">                that is computed according to how many solutions were sampled</span>
<a id="__codelineno-0-170" name="__codelineno-0-170" href="#__codelineno-0-170"></a><span class="sd">                by the actor that produced the gradient.</span>
<a id="__codelineno-0-171" name="__codelineno-0-171" href="#__codelineno-0-171"></a><span class="sd">                If `popsize_weighted_grad_avg` is False, then, there will not</span>
<a id="__codelineno-0-172" name="__codelineno-0-172" href="#__codelineno-0-172"></a><span class="sd">                be weighted averaging (or, each gradient will have equal</span>
<a id="__codelineno-0-173" name="__codelineno-0-173" href="#__codelineno-0-173"></a><span class="sd">                weight).</span>
<a id="__codelineno-0-174" name="__codelineno-0-174" href="#__codelineno-0-174"></a><span class="sd">                If `popsize_weighted_grad_avg` is None, then, the gradient</span>
<a id="__codelineno-0-175" name="__codelineno-0-175" href="#__codelineno-0-175"></a><span class="sd">                weights will be equal a value for `num_interactions` is given</span>
<a id="__codelineno-0-176" name="__codelineno-0-176" href="#__codelineno-0-176"></a><span class="sd">                (because `num_interactions` affects the number of solutions</span>
<a id="__codelineno-0-177" name="__codelineno-0-177" href="#__codelineno-0-177"></a><span class="sd">                according to the episode lengths, and popsize-weighting the</span>
<a id="__codelineno-0-178" name="__codelineno-0-178" href="#__codelineno-0-178"></a><span class="sd">                gradients could be misleading); and the gradient weights will</span>
<a id="__codelineno-0-179" name="__codelineno-0-179" href="#__codelineno-0-179"></a><span class="sd">                be weighted according to the sub-population (i.e. sub-batch)</span>
<a id="__codelineno-0-180" name="__codelineno-0-180" href="#__codelineno-0-180"></a><span class="sd">                sizes if `num_interactions` is left as None.</span>
<a id="__codelineno-0-181" name="__codelineno-0-181" href="#__codelineno-0-181"></a><span class="sd">                The default value for `popsize_weighted_grad_avg` is None.</span>
<a id="__codelineno-0-182" name="__codelineno-0-182" href="#__codelineno-0-182"></a><span class="sd">                When the distributed mode is disabled (i.e. when `distributed`</span>
<a id="__codelineno-0-183" name="__codelineno-0-183" href="#__codelineno-0-183"></a><span class="sd">                is False), then the argument `popsize_weighted_grad_avg` is</span>
<a id="__codelineno-0-184" name="__codelineno-0-184" href="#__codelineno-0-184"></a><span class="sd">                expected as None.</span>
<a id="__codelineno-0-185" name="__codelineno-0-185" href="#__codelineno-0-185"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-186" name="__codelineno-0-186" href="#__codelineno-0-186"></a>
<a id="__codelineno-0-187" name="__codelineno-0-187" href="#__codelineno-0-187"></a>        <span class="k">if</span> <span class="n">popsize</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-188" name="__codelineno-0-188" href="#__codelineno-0-188"></a>            <span class="n">popsize</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">4</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="mi">3</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">problem</span><span class="o">.</span><span class="n">solution_length</span><span class="p">)))</span>
<a id="__codelineno-0-189" name="__codelineno-0-189" href="#__codelineno-0-189"></a>
<a id="__codelineno-0-190" name="__codelineno-0-190" href="#__codelineno-0-190"></a>        <span class="k">if</span> <span class="n">center_learning_rate</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-191" name="__codelineno-0-191" href="#__codelineno-0-191"></a>            <span class="n">center_learning_rate</span> <span class="o">=</span> <span class="mf">1.0</span>
<a id="__codelineno-0-192" name="__codelineno-0-192" href="#__codelineno-0-192"></a>
<a id="__codelineno-0-193" name="__codelineno-0-193" href="#__codelineno-0-193"></a>        <span class="k">def</span> <span class="nf">default_stdev_lr</span><span class="p">():</span>
<a id="__codelineno-0-194" name="__codelineno-0-194" href="#__codelineno-0-194"></a>            <span class="n">n</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">solution_length</span>
<a id="__codelineno-0-195" name="__codelineno-0-195" href="#__codelineno-0-195"></a>            <span class="k">return</span> <span class="mf">0.6</span> <span class="o">*</span> <span class="p">(</span><span class="mi">3</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
<a id="__codelineno-0-196" name="__codelineno-0-196" href="#__codelineno-0-196"></a>
<a id="__codelineno-0-197" name="__codelineno-0-197" href="#__codelineno-0-197"></a>        <span class="k">if</span> <span class="n">stdev_learning_rate</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-198" name="__codelineno-0-198" href="#__codelineno-0-198"></a>            <span class="n">stdev_learning_rate</span> <span class="o">=</span> <span class="n">default_stdev_lr</span><span class="p">()</span>
<a id="__codelineno-0-199" name="__codelineno-0-199" href="#__codelineno-0-199"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-200" name="__codelineno-0-200" href="#__codelineno-0-200"></a>            <span class="n">stdev_learning_rate</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">stdev_learning_rate</span><span class="p">)</span>
<a id="__codelineno-0-201" name="__codelineno-0-201" href="#__codelineno-0-201"></a>            <span class="k">if</span> <span class="n">scale_learning_rate</span><span class="p">:</span>
<a id="__codelineno-0-202" name="__codelineno-0-202" href="#__codelineno-0-202"></a>                <span class="n">stdev_learning_rate</span> <span class="o">*=</span> <span class="n">default_stdev_lr</span><span class="p">()</span>
<a id="__codelineno-0-203" name="__codelineno-0-203" href="#__codelineno-0-203"></a>
<a id="__codelineno-0-204" name="__codelineno-0-204" href="#__codelineno-0-204"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-205" name="__codelineno-0-205" href="#__codelineno-0-205"></a>            <span class="n">problem</span><span class="p">,</span>
<a id="__codelineno-0-206" name="__codelineno-0-206" href="#__codelineno-0-206"></a>            <span class="n">popsize</span><span class="o">=</span><span class="n">popsize</span><span class="p">,</span>
<a id="__codelineno-0-207" name="__codelineno-0-207" href="#__codelineno-0-207"></a>            <span class="n">center_learning_rate</span><span class="o">=</span><span class="n">center_learning_rate</span><span class="p">,</span>
<a id="__codelineno-0-208" name="__codelineno-0-208" href="#__codelineno-0-208"></a>            <span class="n">stdev_learning_rate</span><span class="o">=</span><span class="n">stdev_learning_rate</span><span class="p">,</span>
<a id="__codelineno-0-209" name="__codelineno-0-209" href="#__codelineno-0-209"></a>            <span class="n">stdev_init</span><span class="o">=</span><span class="n">stdev_init</span><span class="p">,</span>
<a id="__codelineno-0-210" name="__codelineno-0-210" href="#__codelineno-0-210"></a>            <span class="n">radius_init</span><span class="o">=</span><span class="n">radius_init</span><span class="p">,</span>
<a id="__codelineno-0-211" name="__codelineno-0-211" href="#__codelineno-0-211"></a>            <span class="n">popsize_max</span><span class="o">=</span><span class="n">popsize_max</span><span class="p">,</span>
<a id="__codelineno-0-212" name="__codelineno-0-212" href="#__codelineno-0-212"></a>            <span class="n">num_interactions</span><span class="o">=</span><span class="n">num_interactions</span><span class="p">,</span>
<a id="__codelineno-0-213" name="__codelineno-0-213" href="#__codelineno-0-213"></a>            <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
<a id="__codelineno-0-214" name="__codelineno-0-214" href="#__codelineno-0-214"></a>            <span class="n">optimizer_config</span><span class="o">=</span><span class="n">optimizer_config</span><span class="p">,</span>
<a id="__codelineno-0-215" name="__codelineno-0-215" href="#__codelineno-0-215"></a>            <span class="n">ranking_method</span><span class="o">=</span><span class="n">ranking_method</span><span class="p">,</span>
<a id="__codelineno-0-216" name="__codelineno-0-216" href="#__codelineno-0-216"></a>            <span class="n">center_init</span><span class="o">=</span><span class="n">center_init</span><span class="p">,</span>
<a id="__codelineno-0-217" name="__codelineno-0-217" href="#__codelineno-0-217"></a>            <span class="n">stdev_min</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-218" name="__codelineno-0-218" href="#__codelineno-0-218"></a>            <span class="n">stdev_max</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-219" name="__codelineno-0-219" href="#__codelineno-0-219"></a>            <span class="n">stdev_max_change</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-220" name="__codelineno-0-220" href="#__codelineno-0-220"></a>            <span class="n">obj_index</span><span class="o">=</span><span class="n">obj_index</span><span class="p">,</span>
<a id="__codelineno-0-221" name="__codelineno-0-221" href="#__codelineno-0-221"></a>            <span class="n">distributed</span><span class="o">=</span><span class="n">distributed</span><span class="p">,</span>
<a id="__codelineno-0-222" name="__codelineno-0-222" href="#__codelineno-0-222"></a>            <span class="n">popsize_weighted_grad_avg</span><span class="o">=</span><span class="n">popsize_weighted_grad_avg</span><span class="p">,</span>
<a id="__codelineno-0-223" name="__codelineno-0-223" href="#__codelineno-0-223"></a>        <span class="p">)</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">








  <div class="doc doc-object doc-class">



<h3 id="evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE" class="doc doc-heading">
        <code>
DISTRIBUTION_TYPE            (<a class="autorefs autorefs-internal" title="evotorch.distributions.Distribution" href="../../../distributions/#evotorch.distributions.Distribution">Distribution</a>)
        </code>



<a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE" class="headerlink" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p>exponential Multivariate Gaussian, as used by XNES</p>

        <details class="quote">
          <summary>Source code in <code>evotorch/algorithms/distributed/gaussian.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">class</span> <span class="nc">ExpGaussian</span><span class="p">(</span><span class="n">Distribution</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;exponential Multivariate Gaussian, as used by XNES&quot;&quot;&quot;</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="c1"># Corresponding to mu and A in symbols used in xNES paper</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">MANDATORY_PARAMETERS</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;mu&quot;</span><span class="p">,</span> <span class="s2">&quot;sigma&quot;</span><span class="p">}</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="c1"># Inverse of sigma, numerically more stable to track this independently to sigma</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n">OPTIONAL_PARAMETERS</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;sigma_inv&quot;</span><span class="p">}</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>        <span class="n">parameters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>        <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>        <span class="n">solution_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>        <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>        <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>    <span class="p">):</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>        <span class="p">[</span><span class="n">mu_length</span><span class="p">]</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>        <span class="c1"># Make sigma 2D</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>            <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">])</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>        <span class="c1"># Automatically generate sigma_inv if not provided</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>        <span class="k">if</span> <span class="s2">&quot;sigma_inv&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>            <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;sigma_inv&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">])</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>        <span class="p">[</span><span class="n">sigma_length</span><span class="p">,</span> <span class="n">_</span><span class="p">]</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>        <span class="k">if</span> <span class="n">solution_length</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>            <span class="n">solution_length</span> <span class="o">=</span> <span class="n">mu_length</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>            <span class="k">if</span> <span class="n">solution_length</span> <span class="o">!=</span> <span class="n">mu_length</span><span class="p">:</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>                    <span class="sa">f</span><span class="s2">&quot;The argument `solution_length` does not match the length of `mu` provided in `parameters`.&quot;</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a>                    <span class="sa">f</span><span class="s2">&quot; solution_length=</span><span class="si">{</span><span class="n">solution_length</span><span class="si">}</span><span class="s2">,&quot;</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>                    <span class="sa">f</span><span class="s1">&#39; parameters[&quot;mu&quot;]=</span><span class="si">{</span><span class="n">mu_length</span><span class="si">}</span><span class="s1">.&#39;</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>                <span class="p">)</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>        <span class="k">if</span> <span class="n">mu_length</span> <span class="o">!=</span> <span class="n">sigma_length</span><span class="p">:</span>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a>                <span class="sa">f</span><span class="s2">&quot;The tensors `mu` and `sigma` provided within `parameters` have mismatching lengths.&quot;</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a>                <span class="sa">f</span><span class="s1">&#39; parameters[&quot;mu&quot;]=</span><span class="si">{</span><span class="n">mu_length</span><span class="si">}</span><span class="s1">,&#39;</span>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a>                <span class="sa">f</span><span class="s1">&#39; parameters[&quot;sigma&quot;]=</span><span class="si">{</span><span class="n">sigma_length</span><span class="si">}</span><span class="s1">.&#39;</span>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a>            <span class="p">)</span>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a>            <span class="n">solution_length</span><span class="o">=</span><span class="n">solution_length</span><span class="p">,</span>
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a>            <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span>
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a>            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a>            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a>        <span class="p">)</span>
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a>        <span class="c1"># Make identity matrix as this is used throughout in gradient computation</span>
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">eye</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_I</span><span class="p">(</span><span class="n">solution_length</span><span class="p">)</span>
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a>
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a>    <span class="k">def</span> <span class="nf">mu</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Getter for mu</span>
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a><span class="sd">            mu (torch.Tensor): The center of the search distribution</span>
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#__codelineno-0-62"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">]</span>
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#__codelineno-0-63"></a>
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#__codelineno-0-64"></a>    <span class="nd">@mu</span><span class="o">.</span><span class="n">setter</span>
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#__codelineno-0-65"></a>    <span class="k">def</span> <span class="nf">mu</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_mu</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">):</span>
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#__codelineno-0-66"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Setter for mu</span>
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#__codelineno-0-67"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#__codelineno-0-68"></a><span class="sd">            new_mu (torch.Tensor): The new value of mu</span>
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#__codelineno-0-69"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#__codelineno-0-70"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">new_mu</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#__codelineno-0-71"></a>
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#__codelineno-0-72"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#__codelineno-0-73"></a>    <span class="k">def</span> <span class="nf">cov</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#__codelineno-0-74"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;The covariance matrix A^T A&quot;&quot;&quot;</span>
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#__codelineno-0-75"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span>
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#__codelineno-0-76"></a>
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#__codelineno-0-77"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-78" name="__codelineno-0-78" href="#__codelineno-0-78"></a>    <span class="k">def</span> <span class="nf">sigma</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-79" name="__codelineno-0-79" href="#__codelineno-0-79"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Getter for sigma</span>
<a id="__codelineno-0-80" name="__codelineno-0-80" href="#__codelineno-0-80"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-81" name="__codelineno-0-81" href="#__codelineno-0-81"></a><span class="sd">            sigma (torch.Tensor): The square root of the covariance matrix</span>
<a id="__codelineno-0-82" name="__codelineno-0-82" href="#__codelineno-0-82"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-83" name="__codelineno-0-83" href="#__codelineno-0-83"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">]</span>
<a id="__codelineno-0-84" name="__codelineno-0-84" href="#__codelineno-0-84"></a>
<a id="__codelineno-0-85" name="__codelineno-0-85" href="#__codelineno-0-85"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-86" name="__codelineno-0-86" href="#__codelineno-0-86"></a>    <span class="k">def</span> <span class="nf">sigma_inv</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-87" name="__codelineno-0-87" href="#__codelineno-0-87"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Getter for sigma_inv</span>
<a id="__codelineno-0-88" name="__codelineno-0-88" href="#__codelineno-0-88"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-89" name="__codelineno-0-89" href="#__codelineno-0-89"></a><span class="sd">            sigma_inv (torch.Tensor): The inverse square root of the covariance matrix</span>
<a id="__codelineno-0-90" name="__codelineno-0-90" href="#__codelineno-0-90"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-91" name="__codelineno-0-91" href="#__codelineno-0-91"></a>        <span class="k">if</span> <span class="s2">&quot;sigma_inv&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">:</span>
<a id="__codelineno-0-92" name="__codelineno-0-92" href="#__codelineno-0-92"></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;sigma_inv&quot;</span><span class="p">]</span>
<a id="__codelineno-0-93" name="__codelineno-0-93" href="#__codelineno-0-93"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-94" name="__codelineno-0-94" href="#__codelineno-0-94"></a>            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">])</span>
<a id="__codelineno-0-95" name="__codelineno-0-95" href="#__codelineno-0-95"></a>
<a id="__codelineno-0-96" name="__codelineno-0-96" href="#__codelineno-0-96"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-97" name="__codelineno-0-97" href="#__codelineno-0-97"></a>    <span class="k">def</span> <span class="nf">A</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-98" name="__codelineno-0-98" href="#__codelineno-0-98"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Alias for self.sigma, for notational consistency with paper&quot;&quot;&quot;</span>
<a id="__codelineno-0-99" name="__codelineno-0-99" href="#__codelineno-0-99"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span>
<a id="__codelineno-0-100" name="__codelineno-0-100" href="#__codelineno-0-100"></a>
<a id="__codelineno-0-101" name="__codelineno-0-101" href="#__codelineno-0-101"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-102" name="__codelineno-0-102" href="#__codelineno-0-102"></a>    <span class="k">def</span> <span class="nf">A_inv</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-103" name="__codelineno-0-103" href="#__codelineno-0-103"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Alias for self.sigma_inv, for notational consistency with paper&quot;&quot;&quot;</span>
<a id="__codelineno-0-104" name="__codelineno-0-104" href="#__codelineno-0-104"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma_inv</span>
<a id="__codelineno-0-105" name="__codelineno-0-105" href="#__codelineno-0-105"></a>
<a id="__codelineno-0-106" name="__codelineno-0-106" href="#__codelineno-0-106"></a>    <span class="nd">@sigma</span><span class="o">.</span><span class="n">setter</span>
<a id="__codelineno-0-107" name="__codelineno-0-107" href="#__codelineno-0-107"></a>    <span class="k">def</span> <span class="nf">sigma</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_sigma</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">):</span>
<a id="__codelineno-0-108" name="__codelineno-0-108" href="#__codelineno-0-108"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Setter for sigma</span>
<a id="__codelineno-0-109" name="__codelineno-0-109" href="#__codelineno-0-109"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-110" name="__codelineno-0-110" href="#__codelineno-0-110"></a><span class="sd">            new_sigma (torch.Tensor): The new value of sigma, the square root of the covariance matrix</span>
<a id="__codelineno-0-111" name="__codelineno-0-111" href="#__codelineno-0-111"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-112" name="__codelineno-0-112" href="#__codelineno-0-112"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">new_sigma</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-113" name="__codelineno-0-113" href="#__codelineno-0-113"></a>
<a id="__codelineno-0-114" name="__codelineno-0-114" href="#__codelineno-0-114"></a>    <span class="k">def</span> <span class="nf">to_global_coordinates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">local_coordinates</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-115" name="__codelineno-0-115" href="#__codelineno-0-115"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Map samples from local coordinate space N(0, I_d) to global coordinate space N(mu, A^T A)</span>
<a id="__codelineno-0-116" name="__codelineno-0-116" href="#__codelineno-0-116"></a><span class="sd">        This function is the inverse of to_local_coordinates</span>
<a id="__codelineno-0-117" name="__codelineno-0-117" href="#__codelineno-0-117"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-118" name="__codelineno-0-118" href="#__codelineno-0-118"></a><span class="sd">            local_coordinates (torch.Tensor): The local coordinates sampled from N(0, I_d)</span>
<a id="__codelineno-0-119" name="__codelineno-0-119" href="#__codelineno-0-119"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-120" name="__codelineno-0-120" href="#__codelineno-0-120"></a><span class="sd">            global_coordinates (torch.Tensor): The global coordinates sampled from N(mu, A^T A)</span>
<a id="__codelineno-0-121" name="__codelineno-0-121" href="#__codelineno-0-121"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-122" name="__codelineno-0-122" href="#__codelineno-0-122"></a>        <span class="c1"># Global samples are constructed as x = mu + A z where z is local coordinate</span>
<a id="__codelineno-0-123" name="__codelineno-0-123" href="#__codelineno-0-123"></a>        <span class="c1"># We use transpose here to simplify the batched application of A</span>
<a id="__codelineno-0-124" name="__codelineno-0-124" href="#__codelineno-0-124"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span> <span class="o">@</span> <span class="n">local_coordinates</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<a id="__codelineno-0-125" name="__codelineno-0-125" href="#__codelineno-0-125"></a>
<a id="__codelineno-0-126" name="__codelineno-0-126" href="#__codelineno-0-126"></a>    <span class="k">def</span> <span class="nf">to_local_coordinates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">global_coordinates</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-127" name="__codelineno-0-127" href="#__codelineno-0-127"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Map samples from global coordinate space N(mu, A^T A) to local coordinate space N(0, I_d)</span>
<a id="__codelineno-0-128" name="__codelineno-0-128" href="#__codelineno-0-128"></a><span class="sd">        This function is the inverse of to_global_coordinates</span>
<a id="__codelineno-0-129" name="__codelineno-0-129" href="#__codelineno-0-129"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-130" name="__codelineno-0-130" href="#__codelineno-0-130"></a><span class="sd">            global_coordinates (torch.Tensor): The global coordinates sampled from N(mu, A^T A)</span>
<a id="__codelineno-0-131" name="__codelineno-0-131" href="#__codelineno-0-131"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-132" name="__codelineno-0-132" href="#__codelineno-0-132"></a><span class="sd">            local_coordinates (torch.Tensor): The local coordinates sampled from N(0, I_d)</span>
<a id="__codelineno-0-133" name="__codelineno-0-133" href="#__codelineno-0-133"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-134" name="__codelineno-0-134" href="#__codelineno-0-134"></a>        <span class="c1"># Global samples are constructed as x = mu + A z where z is local coordinate</span>
<a id="__codelineno-0-135" name="__codelineno-0-135" href="#__codelineno-0-135"></a>        <span class="c1"># Therefore, we can recover z according to z = A_inv (x - mu)</span>
<a id="__codelineno-0-136" name="__codelineno-0-136" href="#__codelineno-0-136"></a>        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A_inv</span> <span class="o">@</span> <span class="p">(</span><span class="n">global_coordinates</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<a id="__codelineno-0-137" name="__codelineno-0-137" href="#__codelineno-0-137"></a>
<a id="__codelineno-0-138" name="__codelineno-0-138" href="#__codelineno-0-138"></a>    <span class="k">def</span> <span class="nf">_fill</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">out</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">generator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-0-139" name="__codelineno-0-139" href="#__codelineno-0-139"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fill a tensor with samples from N(mu, A^T A)</span>
<a id="__codelineno-0-140" name="__codelineno-0-140" href="#__codelineno-0-140"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-141" name="__codelineno-0-141" href="#__codelineno-0-141"></a><span class="sd">            out (torch.Tensor): The tensor to fill</span>
<a id="__codelineno-0-142" name="__codelineno-0-142" href="#__codelineno-0-142"></a><span class="sd">            generator (Optional[torch.Generator]): A generator to use to generate random values</span>
<a id="__codelineno-0-143" name="__codelineno-0-143" href="#__codelineno-0-143"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-144" name="__codelineno-0-144" href="#__codelineno-0-144"></a>        <span class="c1"># Fill with local coordinates from N(0, I_d)</span>
<a id="__codelineno-0-145" name="__codelineno-0-145" href="#__codelineno-0-145"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">make_gaussian</span><span class="p">(</span><span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">)</span>
<a id="__codelineno-0-146" name="__codelineno-0-146" href="#__codelineno-0-146"></a>        <span class="c1"># Map local coordinates to global coordinate system</span>
<a id="__codelineno-0-147" name="__codelineno-0-147" href="#__codelineno-0-147"></a>        <span class="n">out</span><span class="p">[:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_global_coordinates</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<a id="__codelineno-0-148" name="__codelineno-0-148" href="#__codelineno-0-148"></a>
<a id="__codelineno-0-149" name="__codelineno-0-149" href="#__codelineno-0-149"></a>    <span class="k">def</span> <span class="nf">_compute_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">ranking_used</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<a id="__codelineno-0-150" name="__codelineno-0-150" href="#__codelineno-0-150"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute the gradients with respect to a given set of samples and weights</span>
<a id="__codelineno-0-151" name="__codelineno-0-151" href="#__codelineno-0-151"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-152" name="__codelineno-0-152" href="#__codelineno-0-152"></a><span class="sd">            samples (torch.Tensor): Samples drawn from N(mu, A^T A), ideally using self._fill</span>
<a id="__codelineno-0-153" name="__codelineno-0-153" href="#__codelineno-0-153"></a><span class="sd">            weights (torch.Tensor): Weights e.g. fitnesses or utilities assigned to samples</span>
<a id="__codelineno-0-154" name="__codelineno-0-154" href="#__codelineno-0-154"></a><span class="sd">            ranking_used (optional[str]): The ranking method used to compute weights</span>
<a id="__codelineno-0-155" name="__codelineno-0-155" href="#__codelineno-0-155"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-156" name="__codelineno-0-156" href="#__codelineno-0-156"></a><span class="sd">            grads (dict): A dictionary containing the approximated natural gradient on d and M</span>
<a id="__codelineno-0-157" name="__codelineno-0-157" href="#__codelineno-0-157"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-158" name="__codelineno-0-158" href="#__codelineno-0-158"></a>        <span class="c1"># Compute the local coordinates</span>
<a id="__codelineno-0-159" name="__codelineno-0-159" href="#__codelineno-0-159"></a>        <span class="n">local_coordinates</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_local_coordinates</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
<a id="__codelineno-0-160" name="__codelineno-0-160" href="#__codelineno-0-160"></a>
<a id="__codelineno-0-161" name="__codelineno-0-161" href="#__codelineno-0-161"></a>        <span class="c1"># Make sure that the weights (utilities) are 0-centered</span>
<a id="__codelineno-0-162" name="__codelineno-0-162" href="#__codelineno-0-162"></a>        <span class="c1"># (Otherwise the formulations would have to consider a bias term)</span>
<a id="__codelineno-0-163" name="__codelineno-0-163" href="#__codelineno-0-163"></a>        <span class="k">if</span> <span class="n">ranking_used</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;centered&quot;</span><span class="p">,</span> <span class="s2">&quot;normalized&quot;</span><span class="p">):</span>
<a id="__codelineno-0-164" name="__codelineno-0-164" href="#__codelineno-0-164"></a>            <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
<a id="__codelineno-0-165" name="__codelineno-0-165" href="#__codelineno-0-165"></a>
<a id="__codelineno-0-166" name="__codelineno-0-166" href="#__codelineno-0-166"></a>        <span class="n">d_grad</span> <span class="o">=</span> <span class="n">total</span><span class="p">(</span><span class="n">dot</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">local_coordinates</span><span class="p">))</span>
<a id="__codelineno-0-167" name="__codelineno-0-167" href="#__codelineno-0-167"></a>        <span class="n">local_coordinates_outer</span> <span class="o">=</span> <span class="n">local_coordinates</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">local_coordinates</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-168" name="__codelineno-0-168" href="#__codelineno-0-168"></a>        <span class="n">M_grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
<a id="__codelineno-0-169" name="__codelineno-0-169" href="#__codelineno-0-169"></a>            <span class="n">weights</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">local_coordinates_outer</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">eye</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span>
<a id="__codelineno-0-170" name="__codelineno-0-170" href="#__codelineno-0-170"></a>        <span class="p">)</span>
<a id="__codelineno-0-171" name="__codelineno-0-171" href="#__codelineno-0-171"></a>
<a id="__codelineno-0-172" name="__codelineno-0-172" href="#__codelineno-0-172"></a>        <span class="k">return</span> <span class="p">{</span>
<a id="__codelineno-0-173" name="__codelineno-0-173" href="#__codelineno-0-173"></a>            <span class="s2">&quot;d&quot;</span><span class="p">:</span> <span class="n">d_grad</span><span class="p">,</span>
<a id="__codelineno-0-174" name="__codelineno-0-174" href="#__codelineno-0-174"></a>            <span class="s2">&quot;M&quot;</span><span class="p">:</span> <span class="n">M_grad</span><span class="p">,</span>
<a id="__codelineno-0-175" name="__codelineno-0-175" href="#__codelineno-0-175"></a>        <span class="p">}</span>
<a id="__codelineno-0-176" name="__codelineno-0-176" href="#__codelineno-0-176"></a>
<a id="__codelineno-0-177" name="__codelineno-0-177" href="#__codelineno-0-177"></a>    <span class="k">def</span> <span class="nf">update_parameters</span><span class="p">(</span>
<a id="__codelineno-0-178" name="__codelineno-0-178" href="#__codelineno-0-178"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-179" name="__codelineno-0-179" href="#__codelineno-0-179"></a>        <span class="n">gradients</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
<a id="__codelineno-0-180" name="__codelineno-0-180" href="#__codelineno-0-180"></a>        <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-181" name="__codelineno-0-181" href="#__codelineno-0-181"></a>        <span class="n">learning_rates</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-182" name="__codelineno-0-182" href="#__codelineno-0-182"></a>        <span class="n">optimizers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-183" name="__codelineno-0-183" href="#__codelineno-0-183"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ExpGaussian&quot;</span><span class="p">:</span>
<a id="__codelineno-0-184" name="__codelineno-0-184" href="#__codelineno-0-184"></a>        <span class="n">d_grad</span> <span class="o">=</span> <span class="n">gradients</span><span class="p">[</span><span class="s2">&quot;d&quot;</span><span class="p">]</span>
<a id="__codelineno-0-185" name="__codelineno-0-185" href="#__codelineno-0-185"></a>        <span class="n">M_grad</span> <span class="o">=</span> <span class="n">gradients</span><span class="p">[</span><span class="s2">&quot;M&quot;</span><span class="p">]</span>
<a id="__codelineno-0-186" name="__codelineno-0-186" href="#__codelineno-0-186"></a>
<a id="__codelineno-0-187" name="__codelineno-0-187" href="#__codelineno-0-187"></a>        <span class="k">if</span> <span class="s2">&quot;d&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">learning_rates</span><span class="p">:</span>
<a id="__codelineno-0-188" name="__codelineno-0-188" href="#__codelineno-0-188"></a>            <span class="n">learning_rates</span><span class="p">[</span><span class="s2">&quot;d&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">learning_rates</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">]</span>
<a id="__codelineno-0-189" name="__codelineno-0-189" href="#__codelineno-0-189"></a>        <span class="k">if</span> <span class="s2">&quot;M&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">learning_rates</span><span class="p">:</span>
<a id="__codelineno-0-190" name="__codelineno-0-190" href="#__codelineno-0-190"></a>            <span class="n">learning_rates</span><span class="p">[</span><span class="s2">&quot;M&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">learning_rates</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">]</span>
<a id="__codelineno-0-191" name="__codelineno-0-191" href="#__codelineno-0-191"></a>
<a id="__codelineno-0-192" name="__codelineno-0-192" href="#__codelineno-0-192"></a>        <span class="c1"># Follow gradients for d, and M</span>
<a id="__codelineno-0-193" name="__codelineno-0-193" href="#__codelineno-0-193"></a>        <span class="n">update_d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_follow_gradient</span><span class="p">(</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">d_grad</span><span class="p">,</span> <span class="n">learning_rates</span><span class="o">=</span><span class="n">learning_rates</span><span class="p">,</span> <span class="n">optimizers</span><span class="o">=</span><span class="n">optimizers</span><span class="p">)</span>
<a id="__codelineno-0-194" name="__codelineno-0-194" href="#__codelineno-0-194"></a>        <span class="n">update_M</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_follow_gradient</span><span class="p">(</span><span class="s2">&quot;M&quot;</span><span class="p">,</span> <span class="n">M_grad</span><span class="p">,</span> <span class="n">learning_rates</span><span class="o">=</span><span class="n">learning_rates</span><span class="p">,</span> <span class="n">optimizers</span><span class="o">=</span><span class="n">optimizers</span><span class="p">)</span>
<a id="__codelineno-0-195" name="__codelineno-0-195" href="#__codelineno-0-195"></a>
<a id="__codelineno-0-196" name="__codelineno-0-196" href="#__codelineno-0-196"></a>        <span class="c1"># Fold into parameters mu, A and A inv</span>
<a id="__codelineno-0-197" name="__codelineno-0-197" href="#__codelineno-0-197"></a>        <span class="n">new_mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">mv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">,</span> <span class="n">update_d</span><span class="p">)</span>
<a id="__codelineno-0-198" name="__codelineno-0-198" href="#__codelineno-0-198"></a>        <span class="n">new_A</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span> <span class="o">@</span> <span class="n">torch</span><span class="o">.</span><span class="n">matrix_exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">update_M</span><span class="p">)</span>
<a id="__codelineno-0-199" name="__codelineno-0-199" href="#__codelineno-0-199"></a>        <span class="n">new_A_inv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matrix_exp</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">update_M</span><span class="p">)</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">A_inv</span>
<a id="__codelineno-0-200" name="__codelineno-0-200" href="#__codelineno-0-200"></a>
<a id="__codelineno-0-201" name="__codelineno-0-201" href="#__codelineno-0-201"></a>        <span class="c1"># Return modified distribution</span>
<a id="__codelineno-0-202" name="__codelineno-0-202" href="#__codelineno-0-202"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">modified_copy</span><span class="p">(</span><span class="n">mu</span><span class="o">=</span><span class="n">new_mu</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">new_A</span><span class="p">,</span> <span class="n">sigma_inv</span><span class="o">=</span><span class="n">new_A_inv</span><span class="p">)</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">






  <div class="doc doc-object doc-attribute">



<h4 id="evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.A" class="doc doc-heading">
<code class="highlight language-python"><span class="n">A</span><span class="p">:</span> <span class="n">Tensor</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

<a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.A" class="headerlink" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>Alias for self.sigma, for notational consistency with paper</p>
    </div>

  </div>



  <div class="doc doc-object doc-attribute">



<h4 id="evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.A_inv" class="doc doc-heading">
<code class="highlight language-python"><span class="n">A_inv</span><span class="p">:</span> <span class="n">Tensor</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

<a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.A_inv" class="headerlink" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>Alias for self.sigma_inv, for notational consistency with paper</p>
    </div>

  </div>





  <div class="doc doc-object doc-attribute">



<h4 id="evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.cov" class="doc doc-heading">
<code class="highlight language-python"><span class="n">cov</span><span class="p">:</span> <span class="n">Tensor</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

<a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.cov" class="headerlink" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>The covariance matrix A^T A</p>
    </div>

  </div>



  <div class="doc doc-object doc-attribute">



<h4 id="evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.mu" class="doc doc-heading">
<code class="highlight language-python"><span class="n">mu</span><span class="p">:</span> <span class="n">Tensor</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-writable"><code>writable</code></small>
  </span>

<a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.mu" class="headerlink" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>Getter for mu</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>mu (torch.Tensor)</code></td>
      <td><p>The center of the search distribution</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>



  <div class="doc doc-object doc-attribute">



<h4 id="evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.sigma" class="doc doc-heading">
<code class="highlight language-python"><span class="n">sigma</span><span class="p">:</span> <span class="n">Tensor</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-writable"><code>writable</code></small>
  </span>

<a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.sigma" class="headerlink" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>Getter for sigma</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>sigma (torch.Tensor)</code></td>
      <td><p>The square root of the covariance matrix</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>



  <div class="doc doc-object doc-attribute">



<h4 id="evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.sigma_inv" class="doc doc-heading">
<code class="highlight language-python"><span class="n">sigma_inv</span><span class="p">:</span> <span class="n">Tensor</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

<a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.sigma_inv" class="headerlink" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>Getter for sigma_inv</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>sigma_inv (torch.Tensor)</code></td>
      <td><p>The inverse square root of the covariance matrix</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>







  <div class="doc doc-object doc-method">



<h4 id="evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.to_global_coordinates" class="doc doc-heading">
<code class="highlight language-python"><span class="n">to_global_coordinates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">local_coordinates</span><span class="p">)</span></code>


<a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.to_global_coordinates" class="headerlink" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>Map samples from local coordinate space N(0, I_d) to global coordinate space N(mu, A^T A)
This function is the inverse of to_local_coordinates</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>local_coordinates</code></td>
        <td><code>torch.Tensor</code></td>
        <td><p>The local coordinates sampled from N(0, I_d)</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>global_coordinates (torch.Tensor)</code></td>
      <td><p>The global coordinates sampled from N(mu, A^T A)</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>evotorch/algorithms/distributed/gaussian.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">to_global_coordinates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">local_coordinates</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Map samples from local coordinate space N(0, I_d) to global coordinate space N(mu, A^T A)</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="sd">    This function is the inverse of to_local_coordinates</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">        local_coordinates (torch.Tensor): The local coordinates sampled from N(0, I_d)</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">        global_coordinates (torch.Tensor): The global coordinates sampled from N(mu, A^T A)</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="c1"># Global samples are constructed as x = mu + A z where z is local coordinate</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="c1"># We use transpose here to simplify the batched application of A</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span> <span class="o">@</span> <span class="n">local_coordinates</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 id="evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.to_local_coordinates" class="doc doc-heading">
<code class="highlight language-python"><span class="n">to_local_coordinates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">global_coordinates</span><span class="p">)</span></code>


<a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.to_local_coordinates" class="headerlink" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>Map samples from global coordinate space N(mu, A^T A) to local coordinate space N(0, I_d)
This function is the inverse of to_global_coordinates</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>global_coordinates</code></td>
        <td><code>torch.Tensor</code></td>
        <td><p>The global coordinates sampled from N(mu, A^T A)</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>local_coordinates (torch.Tensor)</code></td>
      <td><p>The local coordinates sampled from N(0, I_d)</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>evotorch/algorithms/distributed/gaussian.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">to_local_coordinates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">global_coordinates</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Map samples from global coordinate space N(mu, A^T A) to local coordinate space N(0, I_d)</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="sd">    This function is the inverse of to_global_coordinates</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">        global_coordinates (torch.Tensor): The global coordinates sampled from N(mu, A^T A)</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">        local_coordinates (torch.Tensor): The local coordinates sampled from N(0, I_d)</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="c1"># Global samples are constructed as x = mu + A z where z is local coordinate</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="c1"># Therefore, we can recover z according to z = A_inv (x - mu)</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A_inv</span> <span class="o">@</span> <span class="p">(</span><span class="n">global_coordinates</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 id="evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.update_parameters" class="doc doc-heading">
<code class="highlight language-python"><span class="n">update_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">learning_rates</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">optimizers</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>


<a href="#evotorch.algorithms.distributed.gaussian.XNES.DISTRIBUTION_TYPE.update_parameters" class="headerlink" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>Do an update on the distribution by following the given gradients.</p>
<p>It is expected that the inheriting class has its own implementation
for this method.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>gradients</code></td>
        <td><code>dict</code></td>
        <td><p>Gradients, as a dictionary, which will be used for
computing the necessary updates.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>learning_rates</code></td>
        <td><code>Optional[dict]</code></td>
        <td><p>A dictionary which contains learning rates
for parameters that will be updated using a learning rate
coefficient.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>optimizers</code></td>
        <td><code>Optional[dict]</code></td>
        <td><p>A dictionary which contains optimizer objects
for parameters that will be updated using an adaptive
optimizer.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>ExpGaussian</code></td>
      <td><p>The updated copy of the distribution.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>evotorch/algorithms/distributed/gaussian.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">update_parameters</span><span class="p">(</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">gradients</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">learning_rates</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">optimizers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ExpGaussian&quot;</span><span class="p">:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n">d_grad</span> <span class="o">=</span> <span class="n">gradients</span><span class="p">[</span><span class="s2">&quot;d&quot;</span><span class="p">]</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="n">M_grad</span> <span class="o">=</span> <span class="n">gradients</span><span class="p">[</span><span class="s2">&quot;M&quot;</span><span class="p">]</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="k">if</span> <span class="s2">&quot;d&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">learning_rates</span><span class="p">:</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>        <span class="n">learning_rates</span><span class="p">[</span><span class="s2">&quot;d&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">learning_rates</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">]</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    <span class="k">if</span> <span class="s2">&quot;M&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">learning_rates</span><span class="p">:</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>        <span class="n">learning_rates</span><span class="p">[</span><span class="s2">&quot;M&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">learning_rates</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">]</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="c1"># Follow gradients for d, and M</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>    <span class="n">update_d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_follow_gradient</span><span class="p">(</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">d_grad</span><span class="p">,</span> <span class="n">learning_rates</span><span class="o">=</span><span class="n">learning_rates</span><span class="p">,</span> <span class="n">optimizers</span><span class="o">=</span><span class="n">optimizers</span><span class="p">)</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>    <span class="n">update_M</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_follow_gradient</span><span class="p">(</span><span class="s2">&quot;M&quot;</span><span class="p">,</span> <span class="n">M_grad</span><span class="p">,</span> <span class="n">learning_rates</span><span class="o">=</span><span class="n">learning_rates</span><span class="p">,</span> <span class="n">optimizers</span><span class="o">=</span><span class="n">optimizers</span><span class="p">)</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>    <span class="c1"># Fold into parameters mu, A and A inv</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>    <span class="n">new_mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">mv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">,</span> <span class="n">update_d</span><span class="p">)</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>    <span class="n">new_A</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span> <span class="o">@</span> <span class="n">torch</span><span class="o">.</span><span class="n">matrix_exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">update_M</span><span class="p">)</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>    <span class="n">new_A_inv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matrix_exp</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">update_M</span><span class="p">)</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">A_inv</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>    <span class="c1"># Return modified distribution</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">modified_copy</span><span class="p">(</span><span class="n">mu</span><span class="o">=</span><span class="n">new_mu</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">new_A</span><span class="p">,</span> <span class="n">sigma_inv</span><span class="o">=</span><span class="n">new_A_inv</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>





  <div class="doc doc-object doc-method">



<h3 id="evotorch.algorithms.distributed.gaussian.XNES.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">problem</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">stdev_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">radius_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">popsize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">center_learning_rate</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stdev_learning_rate</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scale_learning_rate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_interactions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">popsize_max</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">optimizer_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ranking_method</span><span class="o">=</span><span class="s1">&#39;nes&#39;</span><span class="p">,</span> <span class="n">center_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">obj_index</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">distributed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">popsize_weighted_grad_avg</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

<a href="#evotorch.algorithms.distributed.gaussian.XNES.__init__" class="headerlink" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p><code>__init__(...)</code>: Initialize the XNES algorithm.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>problem</code></td>
        <td><code>Problem</code></td>
        <td><p>The problem object which is being worked on.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>stdev_init</code></td>
        <td><code>Union[float, Iterable[float], torch.Tensor]</code></td>
        <td><p>The initial standard deviation of the search
distribution, expressed as a scalar or as an array.
Determines the initial coverage area of the search
distribution.
If one wishes to configure the coverage area via the
argument <code>radius_init</code> instead, then <code>stdev_init</code> is expected
as None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>radius_init</code></td>
        <td><code>Union[float, Iterable[float], torch.Tensor]</code></td>
        <td><p>The initial radius of the search distribution,
expressed as a scalar.
Determines the initial coverage area of the search
distribution.
Here, "radius" is defined as the norm of the search
distribution.
If one wishes to configure the coverage area via the
argument <code>stdev_init</code> instead, then <code>radius_init</code> is expected
as None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>popsize</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>Population size. Can be specified as an int,
or can be left as None to let the solver decide.
In the case of SNES, <code>popsize</code> can be left as None,
in which case the default <code>popsize</code> will be computed
as <code>4 + floor(3 * log(n))</code> where <code>n</code> is the length
of a solution.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>center_learning_rate</code></td>
        <td><code>Optional[float]</code></td>
        <td><p>Learning rate for updating the mean
of the search distribution. Default value is 1.0</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>stdev_learning_rate</code></td>
        <td><code>Optional[float]</code></td>
        <td><p>Learning rate for updating the covariance
matrix of the search distribution.
The default value is <code>0.6 * (3 + log(n)) / (n * sqrt(n))</code>
where <code>n</code> is the length of a solution.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>scale_learning_rate</code></td>
        <td><code>bool</code></td>
        <td><p>For SNES, there is a default standard
deviation learning rate value which is computed as
<code>0.6 * (3 + log(n)) / (n * sqrt(n))</code> (where <code>n</code> is the solution
length).
If scale_learning_rate is True (which is the default),
then the effective learning rate for the standard deviation
becomes the provided <code>stdev_learning_rate</code> multiplied by this
default value. If <code>scale_learning_rate</code> is False, then the
effective standard deviation learning rate becomes
equal to the provided <code>stdev_learning_rate</code> value.</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>num_interactions</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>When given as an integer n,
it is ensured that a population has interacted with
the GymProblem's environment n times. If this target
has not been reached yet, then the population is declared
too small, and gets extended with more samples,
until n amount of interactions is reached.
When given as None, popsize is the only configuration
affecting the size of a population.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>popsize_max</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>Having <code>num_interactions</code> set as an integer
might cause the effective population size jump to
unnecesarily large numbers. To prevent this,
one can set <code>popsize_max</code> to specify an upper
bound for the effective population size.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>num_interactions</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>When given as an integer n,
it is ensured that a population has interacted with
the GymProblem's environment n times. If this target
has not been reached yet, then the population is declared
too small, and gets extended with more samples,
until n amount of interactions is reached.
When given as None, popsize is the only configuration
affecting the size of a population.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>optimizer</code></td>
        <td></td>
        <td><p>The optimizer to be used while following the
estimated the gradients.
Can be given as None if a momentum-based optimizer
is not required.
Otherwise, can be given as a str containing the name
of the optimizer (e.g. 'adam', 'clipup');
or as an instance of evotorch.optimizers.TorchOptimizer
or evotorch.optimizers.ClipUp.
The default is None.
Note that, for ClipUp, the default maximum speed is set
as twice the given <code>center_learning_rate</code>.
This maximum speed can be configured by passing
<code>{"max_speed": ...}</code> to <code>optimizer_config</code>.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>optimizer_config</code></td>
        <td><code>Optional[dict]</code></td>
        <td><p>Configuration which will be passed
to the optimizer as keyword arguments.
See <code>evotorch.optimizers</code> for details about
which optimizer accepts which keyword arguments.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>ranking_method</code></td>
        <td><code>Optional[str]</code></td>
        <td><p>Which ranking method will be used for
fitness shaping. See the documentation of
<code>evotorch.ranking.rank(...)</code> for details.
The default is 'nes'.
Can be given as None if no such ranking is required.</p></td>
        <td><code>&#39;nes&#39;</code></td>
      </tr>
      <tr>
        <td><code>center_init</code></td>
        <td><code>Union[float, Iterable[float], torch.Tensor]</code></td>
        <td><p>The initial center solution.
Can be left as None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>obj_index</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>Index of the objective according to which the
gradient estimations will be done.
For single-objective problems, this can be left as None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>distributed</code></td>
        <td><code>bool</code></td>
        <td><p>Whether or not the gradient computation will
be distributed. If <code>distributed</code> is given as False and
the problem is not parallelized, then everything will
be centralized (i.e. the entire computation will happen
in the main process).
If <code>distributed</code> is given as False, and the problem
is parallelized, then the population will be created
in the main process and then sent to remote workers
for parallelized evaluation, and then the remote fitnesses
will be collected by the main process again for computing
the search gradients.
If <code>distributed</code> is given as True, and the problem
is parallelized, then the search algorithm itself will
be distributed, in the sense that each remote actor will
generate its own population (such that the total population
size across all these actors becomes equal to <code>popsize</code>)
and will compute its own gradient, and then the main process
will collect these gradients, compute the averaged gradients
and update the main search distribution.
Non-distributed mode has the advantage of keeping the
population in the main process, which is good when one wishes
to do detailed monitoring during the evolutionary process,
but has the disadvantage of having to pass the solutions to
the remote actors and having to collect fitnesses, which
might result in increased interprocess communication traffic.
On the other hand, while it is not possible to monitor the
population in distributed mode, the distributed mode has the
advantage of significantly reducing the interprocess
communication traffic, since the only things communicated
with the remote actors are the search distributions (not the
solutions) and the gradients.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>popsize_weighted_grad_avg</code></td>
        <td><code>Optional[bool]</code></td>
        <td><p>Only to be used in distributed mode.
(where being in distributed mode means <code>distributed</code> is given
as True). In distributed mode, each actor remotely samples
its own solution batches and computes its own gradients.
These gradients are then collected, and a final average
gradient is computed.
If <code>popsize_weighted_grad_avg</code> is True, then, while averaging
over the gradients, each gradient will have its own weight
that is computed according to how many solutions were sampled
by the actor that produced the gradient.
If <code>popsize_weighted_grad_avg</code> is False, then, there will not
be weighted averaging (or, each gradient will have equal
weight).
If <code>popsize_weighted_grad_avg</code> is None, then, the gradient
weights will be equal a value for <code>num_interactions</code> is given
(because <code>num_interactions</code> affects the number of solutions
according to the episode lengths, and popsize-weighting the
gradients could be misleading); and the gradient weights will
be weighted according to the sub-population (i.e. sub-batch)
sizes if <code>num_interactions</code> is left as None.
The default value for <code>popsize_weighted_grad_avg</code> is None.
When the distributed mode is disabled (i.e. when <code>distributed</code>
is False), then the argument <code>popsize_weighted_grad_avg</code> is
expected as None.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>evotorch/algorithms/distributed/gaussian.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">problem</span><span class="p">:</span> <span class="n">Problem</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">stdev_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">radius_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">popsize</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n">center_learning_rate</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="n">stdev_learning_rate</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="n">scale_learning_rate</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="n">num_interactions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="n">popsize_max</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="n">optimizer_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="n">ranking_method</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;nes&quot;</span><span class="p">,</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="n">center_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RealOrVector</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>    <span class="n">obj_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>    <span class="n">distributed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>    <span class="n">popsize_weighted_grad_avg</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a><span class="p">):</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a><span class="sd">    `__init__(...)`: Initialize the XNES algorithm.</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a><span class="sd">        problem: The problem object which is being worked on.</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a><span class="sd">        stdev_init: The initial standard deviation of the search</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a><span class="sd">            distribution, expressed as a scalar or as an array.</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a><span class="sd">            Determines the initial coverage area of the search</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a><span class="sd">            distribution.</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a><span class="sd">            If one wishes to configure the coverage area via the</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a><span class="sd">            argument `radius_init` instead, then `stdev_init` is expected</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a><span class="sd">            as None.</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a><span class="sd">        radius_init: The initial radius of the search distribution,</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a><span class="sd">            expressed as a scalar.</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a><span class="sd">            Determines the initial coverage area of the search</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a><span class="sd">            distribution.</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a><span class="sd">            Here, &quot;radius&quot; is defined as the norm of the search</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a><span class="sd">            distribution.</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a><span class="sd">            If one wishes to configure the coverage area via the</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a><span class="sd">            argument `stdev_init` instead, then `radius_init` is expected</span>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a><span class="sd">            as None.</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a><span class="sd">        popsize: Population size. Can be specified as an int,</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a><span class="sd">            or can be left as None to let the solver decide.</span>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a><span class="sd">            In the case of SNES, `popsize` can be left as None,</span>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a><span class="sd">            in which case the default `popsize` will be computed</span>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a><span class="sd">            as `4 + floor(3 * log(n))` where `n` is the length</span>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a><span class="sd">            of a solution.</span>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a><span class="sd">        center_learning_rate: Learning rate for updating the mean</span>
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a><span class="sd">            of the search distribution. Default value is 1.0</span>
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a><span class="sd">        stdev_learning_rate: Learning rate for updating the covariance</span>
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a><span class="sd">            matrix of the search distribution.</span>
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a><span class="sd">            The default value is `0.6 * (3 + log(n)) / (n * sqrt(n))`</span>
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a><span class="sd">            where `n` is the length of a solution.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a><span class="sd">        scale_learning_rate: For SNES, there is a default standard</span>
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a><span class="sd">            deviation learning rate value which is computed as</span>
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a><span class="sd">            `0.6 * (3 + log(n)) / (n * sqrt(n))` (where `n` is the solution</span>
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a><span class="sd">            length).</span>
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a><span class="sd">            If scale_learning_rate is True (which is the default),</span>
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a><span class="sd">            then the effective learning rate for the standard deviation</span>
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a><span class="sd">            becomes the provided `stdev_learning_rate` multiplied by this</span>
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a><span class="sd">            default value. If `scale_learning_rate` is False, then the</span>
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#__codelineno-0-62"></a><span class="sd">            effective standard deviation learning rate becomes</span>
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#__codelineno-0-63"></a><span class="sd">            equal to the provided `stdev_learning_rate` value.</span>
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#__codelineno-0-64"></a><span class="sd">        num_interactions: When given as an integer n,</span>
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#__codelineno-0-65"></a><span class="sd">            it is ensured that a population has interacted with</span>
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#__codelineno-0-66"></a><span class="sd">            the GymProblem&#39;s environment n times. If this target</span>
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#__codelineno-0-67"></a><span class="sd">            has not been reached yet, then the population is declared</span>
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#__codelineno-0-68"></a><span class="sd">            too small, and gets extended with more samples,</span>
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#__codelineno-0-69"></a><span class="sd">            until n amount of interactions is reached.</span>
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#__codelineno-0-70"></a><span class="sd">            When given as None, popsize is the only configuration</span>
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#__codelineno-0-71"></a><span class="sd">            affecting the size of a population.</span>
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#__codelineno-0-72"></a><span class="sd">        popsize_max: Having `num_interactions` set as an integer</span>
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#__codelineno-0-73"></a><span class="sd">            might cause the effective population size jump to</span>
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#__codelineno-0-74"></a><span class="sd">            unnecesarily large numbers. To prevent this,</span>
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#__codelineno-0-75"></a><span class="sd">            one can set `popsize_max` to specify an upper</span>
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#__codelineno-0-76"></a><span class="sd">            bound for the effective population size.</span>
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#__codelineno-0-77"></a><span class="sd">        num_interactions: When given as an integer n,</span>
<a id="__codelineno-0-78" name="__codelineno-0-78" href="#__codelineno-0-78"></a><span class="sd">            it is ensured that a population has interacted with</span>
<a id="__codelineno-0-79" name="__codelineno-0-79" href="#__codelineno-0-79"></a><span class="sd">            the GymProblem&#39;s environment n times. If this target</span>
<a id="__codelineno-0-80" name="__codelineno-0-80" href="#__codelineno-0-80"></a><span class="sd">            has not been reached yet, then the population is declared</span>
<a id="__codelineno-0-81" name="__codelineno-0-81" href="#__codelineno-0-81"></a><span class="sd">            too small, and gets extended with more samples,</span>
<a id="__codelineno-0-82" name="__codelineno-0-82" href="#__codelineno-0-82"></a><span class="sd">            until n amount of interactions is reached.</span>
<a id="__codelineno-0-83" name="__codelineno-0-83" href="#__codelineno-0-83"></a><span class="sd">            When given as None, popsize is the only configuration</span>
<a id="__codelineno-0-84" name="__codelineno-0-84" href="#__codelineno-0-84"></a><span class="sd">            affecting the size of a population.</span>
<a id="__codelineno-0-85" name="__codelineno-0-85" href="#__codelineno-0-85"></a><span class="sd">        optimizer: The optimizer to be used while following the</span>
<a id="__codelineno-0-86" name="__codelineno-0-86" href="#__codelineno-0-86"></a><span class="sd">            estimated the gradients.</span>
<a id="__codelineno-0-87" name="__codelineno-0-87" href="#__codelineno-0-87"></a><span class="sd">            Can be given as None if a momentum-based optimizer</span>
<a id="__codelineno-0-88" name="__codelineno-0-88" href="#__codelineno-0-88"></a><span class="sd">            is not required.</span>
<a id="__codelineno-0-89" name="__codelineno-0-89" href="#__codelineno-0-89"></a><span class="sd">            Otherwise, can be given as a str containing the name</span>
<a id="__codelineno-0-90" name="__codelineno-0-90" href="#__codelineno-0-90"></a><span class="sd">            of the optimizer (e.g. &#39;adam&#39;, &#39;clipup&#39;);</span>
<a id="__codelineno-0-91" name="__codelineno-0-91" href="#__codelineno-0-91"></a><span class="sd">            or as an instance of evotorch.optimizers.TorchOptimizer</span>
<a id="__codelineno-0-92" name="__codelineno-0-92" href="#__codelineno-0-92"></a><span class="sd">            or evotorch.optimizers.ClipUp.</span>
<a id="__codelineno-0-93" name="__codelineno-0-93" href="#__codelineno-0-93"></a><span class="sd">            The default is None.</span>
<a id="__codelineno-0-94" name="__codelineno-0-94" href="#__codelineno-0-94"></a><span class="sd">            Note that, for ClipUp, the default maximum speed is set</span>
<a id="__codelineno-0-95" name="__codelineno-0-95" href="#__codelineno-0-95"></a><span class="sd">            as twice the given `center_learning_rate`.</span>
<a id="__codelineno-0-96" name="__codelineno-0-96" href="#__codelineno-0-96"></a><span class="sd">            This maximum speed can be configured by passing</span>
<a id="__codelineno-0-97" name="__codelineno-0-97" href="#__codelineno-0-97"></a><span class="sd">            `{&quot;max_speed&quot;: ...}` to `optimizer_config`.</span>
<a id="__codelineno-0-98" name="__codelineno-0-98" href="#__codelineno-0-98"></a><span class="sd">        optimizer_config: Configuration which will be passed</span>
<a id="__codelineno-0-99" name="__codelineno-0-99" href="#__codelineno-0-99"></a><span class="sd">            to the optimizer as keyword arguments.</span>
<a id="__codelineno-0-100" name="__codelineno-0-100" href="#__codelineno-0-100"></a><span class="sd">            See `evotorch.optimizers` for details about</span>
<a id="__codelineno-0-101" name="__codelineno-0-101" href="#__codelineno-0-101"></a><span class="sd">            which optimizer accepts which keyword arguments.</span>
<a id="__codelineno-0-102" name="__codelineno-0-102" href="#__codelineno-0-102"></a><span class="sd">        ranking_method: Which ranking method will be used for</span>
<a id="__codelineno-0-103" name="__codelineno-0-103" href="#__codelineno-0-103"></a><span class="sd">            fitness shaping. See the documentation of</span>
<a id="__codelineno-0-104" name="__codelineno-0-104" href="#__codelineno-0-104"></a><span class="sd">            `evotorch.ranking.rank(...)` for details.</span>
<a id="__codelineno-0-105" name="__codelineno-0-105" href="#__codelineno-0-105"></a><span class="sd">            The default is &#39;nes&#39;.</span>
<a id="__codelineno-0-106" name="__codelineno-0-106" href="#__codelineno-0-106"></a><span class="sd">            Can be given as None if no such ranking is required.</span>
<a id="__codelineno-0-107" name="__codelineno-0-107" href="#__codelineno-0-107"></a><span class="sd">        center_init: The initial center solution.</span>
<a id="__codelineno-0-108" name="__codelineno-0-108" href="#__codelineno-0-108"></a><span class="sd">            Can be left as None.</span>
<a id="__codelineno-0-109" name="__codelineno-0-109" href="#__codelineno-0-109"></a><span class="sd">        obj_index: Index of the objective according to which the</span>
<a id="__codelineno-0-110" name="__codelineno-0-110" href="#__codelineno-0-110"></a><span class="sd">            gradient estimations will be done.</span>
<a id="__codelineno-0-111" name="__codelineno-0-111" href="#__codelineno-0-111"></a><span class="sd">            For single-objective problems, this can be left as None.</span>
<a id="__codelineno-0-112" name="__codelineno-0-112" href="#__codelineno-0-112"></a><span class="sd">        distributed: Whether or not the gradient computation will</span>
<a id="__codelineno-0-113" name="__codelineno-0-113" href="#__codelineno-0-113"></a><span class="sd">            be distributed. If `distributed` is given as False and</span>
<a id="__codelineno-0-114" name="__codelineno-0-114" href="#__codelineno-0-114"></a><span class="sd">            the problem is not parallelized, then everything will</span>
<a id="__codelineno-0-115" name="__codelineno-0-115" href="#__codelineno-0-115"></a><span class="sd">            be centralized (i.e. the entire computation will happen</span>
<a id="__codelineno-0-116" name="__codelineno-0-116" href="#__codelineno-0-116"></a><span class="sd">            in the main process).</span>
<a id="__codelineno-0-117" name="__codelineno-0-117" href="#__codelineno-0-117"></a><span class="sd">            If `distributed` is given as False, and the problem</span>
<a id="__codelineno-0-118" name="__codelineno-0-118" href="#__codelineno-0-118"></a><span class="sd">            is parallelized, then the population will be created</span>
<a id="__codelineno-0-119" name="__codelineno-0-119" href="#__codelineno-0-119"></a><span class="sd">            in the main process and then sent to remote workers</span>
<a id="__codelineno-0-120" name="__codelineno-0-120" href="#__codelineno-0-120"></a><span class="sd">            for parallelized evaluation, and then the remote fitnesses</span>
<a id="__codelineno-0-121" name="__codelineno-0-121" href="#__codelineno-0-121"></a><span class="sd">            will be collected by the main process again for computing</span>
<a id="__codelineno-0-122" name="__codelineno-0-122" href="#__codelineno-0-122"></a><span class="sd">            the search gradients.</span>
<a id="__codelineno-0-123" name="__codelineno-0-123" href="#__codelineno-0-123"></a><span class="sd">            If `distributed` is given as True, and the problem</span>
<a id="__codelineno-0-124" name="__codelineno-0-124" href="#__codelineno-0-124"></a><span class="sd">            is parallelized, then the search algorithm itself will</span>
<a id="__codelineno-0-125" name="__codelineno-0-125" href="#__codelineno-0-125"></a><span class="sd">            be distributed, in the sense that each remote actor will</span>
<a id="__codelineno-0-126" name="__codelineno-0-126" href="#__codelineno-0-126"></a><span class="sd">            generate its own population (such that the total population</span>
<a id="__codelineno-0-127" name="__codelineno-0-127" href="#__codelineno-0-127"></a><span class="sd">            size across all these actors becomes equal to `popsize`)</span>
<a id="__codelineno-0-128" name="__codelineno-0-128" href="#__codelineno-0-128"></a><span class="sd">            and will compute its own gradient, and then the main process</span>
<a id="__codelineno-0-129" name="__codelineno-0-129" href="#__codelineno-0-129"></a><span class="sd">            will collect these gradients, compute the averaged gradients</span>
<a id="__codelineno-0-130" name="__codelineno-0-130" href="#__codelineno-0-130"></a><span class="sd">            and update the main search distribution.</span>
<a id="__codelineno-0-131" name="__codelineno-0-131" href="#__codelineno-0-131"></a><span class="sd">            Non-distributed mode has the advantage of keeping the</span>
<a id="__codelineno-0-132" name="__codelineno-0-132" href="#__codelineno-0-132"></a><span class="sd">            population in the main process, which is good when one wishes</span>
<a id="__codelineno-0-133" name="__codelineno-0-133" href="#__codelineno-0-133"></a><span class="sd">            to do detailed monitoring during the evolutionary process,</span>
<a id="__codelineno-0-134" name="__codelineno-0-134" href="#__codelineno-0-134"></a><span class="sd">            but has the disadvantage of having to pass the solutions to</span>
<a id="__codelineno-0-135" name="__codelineno-0-135" href="#__codelineno-0-135"></a><span class="sd">            the remote actors and having to collect fitnesses, which</span>
<a id="__codelineno-0-136" name="__codelineno-0-136" href="#__codelineno-0-136"></a><span class="sd">            might result in increased interprocess communication traffic.</span>
<a id="__codelineno-0-137" name="__codelineno-0-137" href="#__codelineno-0-137"></a><span class="sd">            On the other hand, while it is not possible to monitor the</span>
<a id="__codelineno-0-138" name="__codelineno-0-138" href="#__codelineno-0-138"></a><span class="sd">            population in distributed mode, the distributed mode has the</span>
<a id="__codelineno-0-139" name="__codelineno-0-139" href="#__codelineno-0-139"></a><span class="sd">            advantage of significantly reducing the interprocess</span>
<a id="__codelineno-0-140" name="__codelineno-0-140" href="#__codelineno-0-140"></a><span class="sd">            communication traffic, since the only things communicated</span>
<a id="__codelineno-0-141" name="__codelineno-0-141" href="#__codelineno-0-141"></a><span class="sd">            with the remote actors are the search distributions (not the</span>
<a id="__codelineno-0-142" name="__codelineno-0-142" href="#__codelineno-0-142"></a><span class="sd">            solutions) and the gradients.</span>
<a id="__codelineno-0-143" name="__codelineno-0-143" href="#__codelineno-0-143"></a><span class="sd">        popsize_weighted_grad_avg: Only to be used in distributed mode.</span>
<a id="__codelineno-0-144" name="__codelineno-0-144" href="#__codelineno-0-144"></a><span class="sd">            (where being in distributed mode means `distributed` is given</span>
<a id="__codelineno-0-145" name="__codelineno-0-145" href="#__codelineno-0-145"></a><span class="sd">            as True). In distributed mode, each actor remotely samples</span>
<a id="__codelineno-0-146" name="__codelineno-0-146" href="#__codelineno-0-146"></a><span class="sd">            its own solution batches and computes its own gradients.</span>
<a id="__codelineno-0-147" name="__codelineno-0-147" href="#__codelineno-0-147"></a><span class="sd">            These gradients are then collected, and a final average</span>
<a id="__codelineno-0-148" name="__codelineno-0-148" href="#__codelineno-0-148"></a><span class="sd">            gradient is computed.</span>
<a id="__codelineno-0-149" name="__codelineno-0-149" href="#__codelineno-0-149"></a><span class="sd">            If `popsize_weighted_grad_avg` is True, then, while averaging</span>
<a id="__codelineno-0-150" name="__codelineno-0-150" href="#__codelineno-0-150"></a><span class="sd">            over the gradients, each gradient will have its own weight</span>
<a id="__codelineno-0-151" name="__codelineno-0-151" href="#__codelineno-0-151"></a><span class="sd">            that is computed according to how many solutions were sampled</span>
<a id="__codelineno-0-152" name="__codelineno-0-152" href="#__codelineno-0-152"></a><span class="sd">            by the actor that produced the gradient.</span>
<a id="__codelineno-0-153" name="__codelineno-0-153" href="#__codelineno-0-153"></a><span class="sd">            If `popsize_weighted_grad_avg` is False, then, there will not</span>
<a id="__codelineno-0-154" name="__codelineno-0-154" href="#__codelineno-0-154"></a><span class="sd">            be weighted averaging (or, each gradient will have equal</span>
<a id="__codelineno-0-155" name="__codelineno-0-155" href="#__codelineno-0-155"></a><span class="sd">            weight).</span>
<a id="__codelineno-0-156" name="__codelineno-0-156" href="#__codelineno-0-156"></a><span class="sd">            If `popsize_weighted_grad_avg` is None, then, the gradient</span>
<a id="__codelineno-0-157" name="__codelineno-0-157" href="#__codelineno-0-157"></a><span class="sd">            weights will be equal a value for `num_interactions` is given</span>
<a id="__codelineno-0-158" name="__codelineno-0-158" href="#__codelineno-0-158"></a><span class="sd">            (because `num_interactions` affects the number of solutions</span>
<a id="__codelineno-0-159" name="__codelineno-0-159" href="#__codelineno-0-159"></a><span class="sd">            according to the episode lengths, and popsize-weighting the</span>
<a id="__codelineno-0-160" name="__codelineno-0-160" href="#__codelineno-0-160"></a><span class="sd">            gradients could be misleading); and the gradient weights will</span>
<a id="__codelineno-0-161" name="__codelineno-0-161" href="#__codelineno-0-161"></a><span class="sd">            be weighted according to the sub-population (i.e. sub-batch)</span>
<a id="__codelineno-0-162" name="__codelineno-0-162" href="#__codelineno-0-162"></a><span class="sd">            sizes if `num_interactions` is left as None.</span>
<a id="__codelineno-0-163" name="__codelineno-0-163" href="#__codelineno-0-163"></a><span class="sd">            The default value for `popsize_weighted_grad_avg` is None.</span>
<a id="__codelineno-0-164" name="__codelineno-0-164" href="#__codelineno-0-164"></a><span class="sd">            When the distributed mode is disabled (i.e. when `distributed`</span>
<a id="__codelineno-0-165" name="__codelineno-0-165" href="#__codelineno-0-165"></a><span class="sd">            is False), then the argument `popsize_weighted_grad_avg` is</span>
<a id="__codelineno-0-166" name="__codelineno-0-166" href="#__codelineno-0-166"></a><span class="sd">            expected as None.</span>
<a id="__codelineno-0-167" name="__codelineno-0-167" href="#__codelineno-0-167"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-168" name="__codelineno-0-168" href="#__codelineno-0-168"></a>
<a id="__codelineno-0-169" name="__codelineno-0-169" href="#__codelineno-0-169"></a>    <span class="k">if</span> <span class="n">popsize</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-170" name="__codelineno-0-170" href="#__codelineno-0-170"></a>        <span class="n">popsize</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">4</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="mi">3</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">problem</span><span class="o">.</span><span class="n">solution_length</span><span class="p">)))</span>
<a id="__codelineno-0-171" name="__codelineno-0-171" href="#__codelineno-0-171"></a>
<a id="__codelineno-0-172" name="__codelineno-0-172" href="#__codelineno-0-172"></a>    <span class="k">if</span> <span class="n">center_learning_rate</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-173" name="__codelineno-0-173" href="#__codelineno-0-173"></a>        <span class="n">center_learning_rate</span> <span class="o">=</span> <span class="mf">1.0</span>
<a id="__codelineno-0-174" name="__codelineno-0-174" href="#__codelineno-0-174"></a>
<a id="__codelineno-0-175" name="__codelineno-0-175" href="#__codelineno-0-175"></a>    <span class="k">def</span> <span class="nf">default_stdev_lr</span><span class="p">():</span>
<a id="__codelineno-0-176" name="__codelineno-0-176" href="#__codelineno-0-176"></a>        <span class="n">n</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">solution_length</span>
<a id="__codelineno-0-177" name="__codelineno-0-177" href="#__codelineno-0-177"></a>        <span class="k">return</span> <span class="mf">0.6</span> <span class="o">*</span> <span class="p">(</span><span class="mi">3</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
<a id="__codelineno-0-178" name="__codelineno-0-178" href="#__codelineno-0-178"></a>
<a id="__codelineno-0-179" name="__codelineno-0-179" href="#__codelineno-0-179"></a>    <span class="k">if</span> <span class="n">stdev_learning_rate</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-180" name="__codelineno-0-180" href="#__codelineno-0-180"></a>        <span class="n">stdev_learning_rate</span> <span class="o">=</span> <span class="n">default_stdev_lr</span><span class="p">()</span>
<a id="__codelineno-0-181" name="__codelineno-0-181" href="#__codelineno-0-181"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-182" name="__codelineno-0-182" href="#__codelineno-0-182"></a>        <span class="n">stdev_learning_rate</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">stdev_learning_rate</span><span class="p">)</span>
<a id="__codelineno-0-183" name="__codelineno-0-183" href="#__codelineno-0-183"></a>        <span class="k">if</span> <span class="n">scale_learning_rate</span><span class="p">:</span>
<a id="__codelineno-0-184" name="__codelineno-0-184" href="#__codelineno-0-184"></a>            <span class="n">stdev_learning_rate</span> <span class="o">*=</span> <span class="n">default_stdev_lr</span><span class="p">()</span>
<a id="__codelineno-0-185" name="__codelineno-0-185" href="#__codelineno-0-185"></a>
<a id="__codelineno-0-186" name="__codelineno-0-186" href="#__codelineno-0-186"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-187" name="__codelineno-0-187" href="#__codelineno-0-187"></a>        <span class="n">problem</span><span class="p">,</span>
<a id="__codelineno-0-188" name="__codelineno-0-188" href="#__codelineno-0-188"></a>        <span class="n">popsize</span><span class="o">=</span><span class="n">popsize</span><span class="p">,</span>
<a id="__codelineno-0-189" name="__codelineno-0-189" href="#__codelineno-0-189"></a>        <span class="n">center_learning_rate</span><span class="o">=</span><span class="n">center_learning_rate</span><span class="p">,</span>
<a id="__codelineno-0-190" name="__codelineno-0-190" href="#__codelineno-0-190"></a>        <span class="n">stdev_learning_rate</span><span class="o">=</span><span class="n">stdev_learning_rate</span><span class="p">,</span>
<a id="__codelineno-0-191" name="__codelineno-0-191" href="#__codelineno-0-191"></a>        <span class="n">stdev_init</span><span class="o">=</span><span class="n">stdev_init</span><span class="p">,</span>
<a id="__codelineno-0-192" name="__codelineno-0-192" href="#__codelineno-0-192"></a>        <span class="n">radius_init</span><span class="o">=</span><span class="n">radius_init</span><span class="p">,</span>
<a id="__codelineno-0-193" name="__codelineno-0-193" href="#__codelineno-0-193"></a>        <span class="n">popsize_max</span><span class="o">=</span><span class="n">popsize_max</span><span class="p">,</span>
<a id="__codelineno-0-194" name="__codelineno-0-194" href="#__codelineno-0-194"></a>        <span class="n">num_interactions</span><span class="o">=</span><span class="n">num_interactions</span><span class="p">,</span>
<a id="__codelineno-0-195" name="__codelineno-0-195" href="#__codelineno-0-195"></a>        <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
<a id="__codelineno-0-196" name="__codelineno-0-196" href="#__codelineno-0-196"></a>        <span class="n">optimizer_config</span><span class="o">=</span><span class="n">optimizer_config</span><span class="p">,</span>
<a id="__codelineno-0-197" name="__codelineno-0-197" href="#__codelineno-0-197"></a>        <span class="n">ranking_method</span><span class="o">=</span><span class="n">ranking_method</span><span class="p">,</span>
<a id="__codelineno-0-198" name="__codelineno-0-198" href="#__codelineno-0-198"></a>        <span class="n">center_init</span><span class="o">=</span><span class="n">center_init</span><span class="p">,</span>
<a id="__codelineno-0-199" name="__codelineno-0-199" href="#__codelineno-0-199"></a>        <span class="n">stdev_min</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-200" name="__codelineno-0-200" href="#__codelineno-0-200"></a>        <span class="n">stdev_max</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-201" name="__codelineno-0-201" href="#__codelineno-0-201"></a>        <span class="n">stdev_max_change</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-202" name="__codelineno-0-202" href="#__codelineno-0-202"></a>        <span class="n">obj_index</span><span class="o">=</span><span class="n">obj_index</span><span class="p">,</span>
<a id="__codelineno-0-203" name="__codelineno-0-203" href="#__codelineno-0-203"></a>        <span class="n">distributed</span><span class="o">=</span><span class="n">distributed</span><span class="p">,</span>
<a id="__codelineno-0-204" name="__codelineno-0-204" href="#__codelineno-0-204"></a>        <span class="n">popsize_weighted_grad_avg</span><span class="o">=</span><span class="n">popsize_weighted_grad_avg</span><span class="p">,</span>
<a id="__codelineno-0-205" name="__codelineno-0-205" href="#__codelineno-0-205"></a>    <span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>







  </div>

    </div>

  </div>





                
              </article>
            </div>
          
          
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" hidden>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
            Back to top
          </a>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2022 NNAISENSE SA
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../../../..", "features": ["content.code.annotate", "navigation.indexes", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest"], "search": "../../../../../assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../../../../../assets/javascripts/bundle.2a6f1dda.min.js"></script>
      
        <script src="../../../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>