
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="EvoTorch is an open source evolutionary computation library developed at NNAISENSE, built on top of PyTorch.">
      
      
      
      
        <link rel="prev" href="../vecgymne/">
      
      
        <link rel="next" href="functional/">
      
      
      <link rel="icon" href="../../../../assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>Index - EvoTorch</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="orange" data-md-color-accent="orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#evotorch.neuroevolution.net" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
          <aside class="md-banner md-banner--warning">
            <div class="md-banner__inner md-grid md-typeset">
              
  You're not viewing the latest version.
  <a href="../../../../..">
    <strong>Click here to go to latest.</strong>
  </a>

            </div>
            <script>var el=document.querySelector("[data-md-component=outdated]"),base=new URL("../../../.."),outdated=__md_get("__outdated",sessionStorage,base);!0===outdated&&el&&(el.hidden=!1)</script>
          </aside>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="https://evotorch.ai" title="EvoTorch" class="md-header__button md-logo" aria-label="EvoTorch" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            EvoTorch
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Index
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="orange" data-md-color-accent="orange"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="deep-orange" data-md-color-accent="deep-orange"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/nnaisense/evotorch" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    evotorch
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../quickstart/" class="md-tabs__link">
        
  
  
    
  
  Quickstart

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../user_guide/general_usage/" class="md-tabs__link">
          
  
  
    
  
  User Guide

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../advanced_usage/solution_batch/" class="md-tabs__link">
          
  
  
    
  
  Advanced Usage

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../examples/" class="md-tabs__link">
          
  
  
    
  
  Examples

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../" class="md-tabs__link">
          
  
  
    
  
  API Reference

        </a>
      </li>
    
  

    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="https://evotorch.ai" title="EvoTorch" class="md-nav__button md-logo" aria-label="EvoTorch" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    EvoTorch
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/nnaisense/evotorch" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    evotorch
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../quickstart/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Quickstart
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    User Guide
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            User Guide
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../user_guide/general_usage/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    General Usage
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../user_guide/algorithm_usage/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Algorithm Usage
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../user_guide/algorithms_tour/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Algorithms Tour
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../user_guide/problems/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Defining Problems
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../user_guide/problem_parallelization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Problem Parallelization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../user_guide/logging/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Logging
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../user_guide/neuroevolution/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Neuroevolution
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../user_guide/gym/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Neuroevolution for Gym
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../user_guide/supervised_ne/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Supervised Neuroevolution
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Advanced Usage
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Advanced Usage
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../advanced_usage/solution_batch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Manipulating Solutions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../advanced_usage/hooks/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Using Hooks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../advanced_usage/dist_based/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Distributed Evolution Strategies
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../advanced_usage/custom_ea/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Custom Searchers
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../advanced_usage/custom_logger/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Custom Loggers
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../advanced_usage/ray_cluster/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Using Ray Clusters
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../examples/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Examples
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5" id="__nav_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Examples
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2" >
        
          
          <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Notebooks
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2">
            <span class="md-nav__icon md-icon"></span>
            Notebooks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../examples/notebooks/Brax_Experiments_Visualization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Visualization of the brax Experiment Results
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../examples/notebooks/Brax_Experiments_with_PGPE/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Solving a Brax environment using EvoTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../examples/notebooks/Evolving_Objects/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Evolving Objects
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../examples/notebooks/Feature_Space_Illumination_with_MAPElites/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Feature Space Illumination with MAPElites
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../examples/notebooks/Genetic_Programming/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Genetic Programming using EvoTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../examples/notebooks/Gym_Experiments_with_PGPE_and_CoSyNE/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Gym Experiments with PGPE and CoSyNE
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../examples/notebooks/Minimizing_Lennard-Jones_Atom_Cluster_Potentials/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Minimising Lennard-Jones Atom Cluster Potentials with Evolution
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../examples/notebooks/Training_MNIST30K/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Training MNIST30K
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../examples/notebooks/Variational_Quantum_Eigensolvers_with_SNES/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Variational Quantum Eigensolvers with SNES
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../examples/notebooks/batched_searches/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Maintaining a batch of populations using the functional EvoTorch API
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../examples/notebooks/constrained/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Solving constrained optimization problems
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../examples/notebooks/func_rl_ga/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Evolving objects using the functional operators API of EvoTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../examples/notebooks/functional_ops/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Genetic algorithm with the help of functional operators
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../examples/notebooks/multiobj_batched_ops/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Multiobjective optimization via functional operators API
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../examples/notebooks/problem/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Solving reinforcement learning tasks using functional evolutionary algorithms
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../examples/notebooks/reacher_mpc/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Model Predictive Control (MPC) with EvoTorch
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" checked>
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    API Reference
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            API Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_1" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Evotorch
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6_1" id="__nav_6_1_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6_1">
            <span class="md-nav__icon md-icon"></span>
            Evotorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../core/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Core
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../decorators/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Decorators
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../distributions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Distributions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../logging/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Logging
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../optimizers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Optimizers
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../testing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Testing
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_1_8" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../algorithms/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Algorithms
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6_1_8" id="__nav_6_1_8_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_1_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_1_8">
            <span class="md-nav__icon md-icon"></span>
            Algorithms
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../algorithms/cmaes/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cmaes
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../algorithms/ga/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Ga
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../algorithms/mapelites/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Mapelites
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../algorithms/pycmaes/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Pycmaes
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../algorithms/searchalgorithm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Searchalgorithm
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_1_8_7" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../algorithms/distributed/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Distributed
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6_1_8_7" id="__nav_6_1_8_7_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_6_1_8_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_1_8_7">
            <span class="md-nav__icon md-icon"></span>
            Distributed
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../algorithms/distributed/gaussian/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Gaussian
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_1_8_8" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../algorithms/functional/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Functional
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6_1_8_8" id="__nav_6_1_8_8_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_6_1_8_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_1_8_8">
            <span class="md-nav__icon md-icon"></span>
            Functional
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../algorithms/functional/funcadam/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Funcadam
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../algorithms/functional/funccem/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Funccem
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../algorithms/functional/funcclipup/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Funcclipup
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../algorithms/functional/funcpgpe/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Funcpgpe
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../algorithms/functional/funcsgd/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Funcsgd
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../algorithms/functional/misc/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Misc
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_1_8_9" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../algorithms/restarter/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Restarter
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6_1_8_9" id="__nav_6_1_8_9_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_6_1_8_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_1_8_9">
            <span class="md-nav__icon md-icon"></span>
            Restarter
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../algorithms/restarter/modify_restart/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Modify restart
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../algorithms/restarter/restart/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Restart
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_1_9" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Neuroevolution
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6_1_9" id="__nav_6_1_9_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_1_9_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6_1_9">
            <span class="md-nav__icon md-icon"></span>
            Neuroevolution
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../baseneproblem/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Baseneproblem
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gymne/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Gymne
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../neproblem/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Neproblem
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../supervisedne/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Supervisedne
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vecgymne/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Vecgymne
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_1_9_7" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="./" class="md-nav__link md-nav__link--active">
              
  
  
  <span class="md-ellipsis">
    Net
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link md-nav__link--active" for="__nav_6_1_9_7" id="__nav_6_1_9_7_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_6_1_9_7_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6_1_9_7">
            <span class="md-nav__icon md-icon"></span>
            Net
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="functional/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Functional
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="layers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Layers
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="misc/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Misc
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="multilayered/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Multilayered
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="parser/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Parser
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="rl/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Rl
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="runningnorm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Runningnorm
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="runningstat/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Runningstat
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="statefulmodule/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Statefulmodule
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="vecrl/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Vecrl
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_1_10" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../operators/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Operators
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6_1_10" id="__nav_6_1_10_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_1_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_1_10">
            <span class="md-nav__icon md-icon"></span>
            Operators
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../operators/base/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Base
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../operators/functional/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Functional
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../operators/real/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Real
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../operators/sequence/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Sequence
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_1_11" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../tools/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Tools
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6_1_11" id="__nav_6_1_11_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_1_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_1_11">
            <span class="md-nav__icon md-icon"></span>
            Tools
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools/cloning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cloning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools/constraints/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Constraints
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools/hook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Hook
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools/immutable/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Immutable
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools/misc/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Misc
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools/objectarray/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Objectarray
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools/ranking/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Ranking
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools/readonlytensor/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Readonlytensor
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools/recursiveprintable/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Recursiveprintable
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools/structures/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Structures
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools/tensorframe/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Tensorframe
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools/tensormaker/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Tensormaker
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net" class="md-nav__link">
    <span class="md-ellipsis">
      net
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.ModuleExpectingFlatParameters" class="md-nav__link">
    <span class="md-ellipsis">
      ModuleExpectingFlatParameters
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ModuleExpectingFlatParameters">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.ModuleExpectingFlatParameters.buffers" class="md-nav__link">
    <span class="md-ellipsis">
      buffers
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.ModuleExpectingFlatParameters.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.ModuleExpectingFlatParameters.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.ModuleExpectingFlatParameters.__transfer_buffers" class="md-nav__link">
    <span class="md-ellipsis">
      __transfer_buffers
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.NetParsingError" class="md-nav__link">
    <span class="md-ellipsis">
      NetParsingError
    </span>
  </a>
  
    <nav class="md-nav" aria-label="NetParsingError">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.NetParsingError.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.Policy" class="md-nav__link">
    <span class="md-ellipsis">
      Policy
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Policy">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.Policy.h" class="md-nav__link">
    <span class="md-ellipsis">
      h
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.Policy.parameter_length" class="md-nav__link">
    <span class="md-ellipsis">
      parameter_length
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.Policy.parameters" class="md-nav__link">
    <span class="md-ellipsis">
      parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.Policy.wrapped_module" class="md-nav__link">
    <span class="md-ellipsis">
      wrapped_module
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.Policy.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.Policy.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.Policy.reset" class="md-nav__link">
    <span class="md-ellipsis">
      reset
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.Policy.set_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      set_parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.Policy.to_torch_module" class="md-nav__link">
    <span class="md-ellipsis">
      to_torch_module
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningNorm" class="md-nav__link">
    <span class="md-ellipsis">
      RunningNorm
    </span>
  </a>
  
    <nav class="md-nav" aria-label="RunningNorm">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningNorm.count" class="md-nav__link">
    <span class="md-ellipsis">
      count
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningNorm.device" class="md-nav__link">
    <span class="md-ellipsis">
      device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningNorm.dtype" class="md-nav__link">
    <span class="md-ellipsis">
      dtype
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningNorm.high" class="md-nav__link">
    <span class="md-ellipsis">
      high
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningNorm.low" class="md-nav__link">
    <span class="md-ellipsis">
      low
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningNorm.mean" class="md-nav__link">
    <span class="md-ellipsis">
      mean
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningNorm.min_variance" class="md-nav__link">
    <span class="md-ellipsis">
      min_variance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningNorm.shape" class="md-nav__link">
    <span class="md-ellipsis">
      shape
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningNorm.stats" class="md-nav__link">
    <span class="md-ellipsis">
      stats
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningNorm.stdev" class="md-nav__link">
    <span class="md-ellipsis">
      stdev
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningNorm.sum" class="md-nav__link">
    <span class="md-ellipsis">
      sum
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningNorm.sum_of_squares" class="md-nav__link">
    <span class="md-ellipsis">
      sum_of_squares
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningNorm.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningNorm.normalize" class="md-nav__link">
    <span class="md-ellipsis">
      normalize
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningNorm.reset" class="md-nav__link">
    <span class="md-ellipsis">
      reset
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningNorm.to" class="md-nav__link">
    <span class="md-ellipsis">
      to
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningNorm.to_layer" class="md-nav__link">
    <span class="md-ellipsis">
      to_layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningNorm.update" class="md-nav__link">
    <span class="md-ellipsis">
      update
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningNorm.update_and_normalize" class="md-nav__link">
    <span class="md-ellipsis">
      update_and_normalize
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningStat" class="md-nav__link">
    <span class="md-ellipsis">
      RunningStat
    </span>
  </a>
  
    <nav class="md-nav" aria-label="RunningStat">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningStat.count" class="md-nav__link">
    <span class="md-ellipsis">
      count
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningStat.mean" class="md-nav__link">
    <span class="md-ellipsis">
      mean
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningStat.stdev" class="md-nav__link">
    <span class="md-ellipsis">
      stdev
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningStat.sum" class="md-nav__link">
    <span class="md-ellipsis">
      sum
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningStat.sum_of_squares" class="md-nav__link">
    <span class="md-ellipsis">
      sum_of_squares
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningStat.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningStat.normalize" class="md-nav__link">
    <span class="md-ellipsis">
      normalize
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningStat.reset" class="md-nav__link">
    <span class="md-ellipsis">
      reset
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningStat.to" class="md-nav__link">
    <span class="md-ellipsis">
      to
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningStat.to_layer" class="md-nav__link">
    <span class="md-ellipsis">
      to_layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.RunningStat.update" class="md-nav__link">
    <span class="md-ellipsis">
      update
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.StatefulModule" class="md-nav__link">
    <span class="md-ellipsis">
      StatefulModule
    </span>
  </a>
  
    <nav class="md-nav" aria-label="StatefulModule">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.StatefulModule.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.StatefulModule.reset" class="md-nav__link">
    <span class="md-ellipsis">
      reset
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.count_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      count_parameters
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.device_of_module" class="md-nav__link">
    <span class="md-ellipsis">
      device_of_module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.fill_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      fill_parameters
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.make_functional_module" class="md-nav__link">
    <span class="md-ellipsis">
      make_functional_module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.parameter_vector" class="md-nav__link">
    <span class="md-ellipsis">
      parameter_vector
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evotorch.neuroevolution.net.str_to_net" class="md-nav__link">
    <span class="md-ellipsis">
      str_to_net
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


  <h1>Index</h1>

<div class="doc doc-object doc-module">



<a id="evotorch.neuroevolution.net"></a>
    <div class="doc doc-contents first">

        <p>Utility classes and functions for neural networks</p>









  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="evotorch.neuroevolution.net.ModuleExpectingFlatParameters" class="doc doc-heading">
            <code>ModuleExpectingFlatParameters</code>


<a href="#evotorch.neuroevolution.net.ModuleExpectingFlatParameters" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">


        <p>A wrapper which brings a functional interface around a torch module.</p>
<p>Similar to <code>functorch.FunctionalModule</code>, <code>ModuleExpectingFlatParameters</code>
turns a <code>torch.nn.Module</code> instance to a function which expects a new
leftmost argument representing the parameters of the network.
Unlike <code>functorch.FunctionalModule</code>, a <code>ModuleExpectingFlatParameters</code>
instance, as its name suggests, expects the network parameters to be
given as a 1-dimensional (i.e. flattened) tensor.
Also, unlike <code>functorch.FunctionalModule</code>, an instance of
<code>ModuleExpectingFlatParameters</code> is NOT an instance of <code>torch.nn.Module</code>.</p>
<p>PyTorch modules with buffers can be wrapped by this class, but it is
assumed that those buffers are constant. If the wrapped module changes
the value(s) of its buffer(s) during its forward passes, most probably
things will NOT work right.</p>
<p>As an example, let us consider the following linear layer.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
</code></pre></div>
<p>The functional counterpart of <code>net</code> can be obtained via:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">evotorch.neuroevolution.net</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModuleExpectingFlatParameters</span>
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="n">fnet</span> <span class="o">=</span> <span class="n">ModuleExpectingFlatParameters</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
</code></pre></div>
<p>Now, <code>fnet</code> is a callable object which expects network parameters
and network inputs. Let us call <code>fnet</code> with randomly generated network
parameters and with a randomly generated input tensor.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="n">param_length</span> <span class="o">=</span> <span class="n">fnet</span><span class="o">.</span><span class="n">parameter_length</span>
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="n">random_parameters</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">param_length</span><span class="p">)</span>
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="n">random_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>
<a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="n">result</span> <span class="o">=</span> <span class="n">fnet</span><span class="p">(</span><span class="n">random_parameters</span><span class="p">,</span> <span class="n">random_input</span><span class="p">)</span>
</code></pre></div>







              <details class="quote">
                <summary>Source code in <code>evotorch/neuroevolution/net/functional.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="k">class</span><span class="w"> </span><span class="nc">ModuleExpectingFlatParameters</span><span class="p">:</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="sd">    A wrapper which brings a functional interface around a torch module.</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">    Similar to `functorch.FunctionalModule`, `ModuleExpectingFlatParameters`</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">    turns a `torch.nn.Module` instance to a function which expects a new</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">    leftmost argument representing the parameters of the network.</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">    Unlike `functorch.FunctionalModule`, a `ModuleExpectingFlatParameters`</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">    instance, as its name suggests, expects the network parameters to be</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="sd">    given as a 1-dimensional (i.e. flattened) tensor.</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">    Also, unlike `functorch.FunctionalModule`, an instance of</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">    `ModuleExpectingFlatParameters` is NOT an instance of `torch.nn.Module`.</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">    PyTorch modules with buffers can be wrapped by this class, but it is</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">    assumed that those buffers are constant. If the wrapped module changes</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="sd">    the value(s) of its buffer(s) during its forward passes, most probably</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">    things will NOT work right.</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">    As an example, let us consider the following linear layer.</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">    import torch</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a><span class="sd">    from torch import nn</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="sd">    net = nn.Linear(3, 8)</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a><span class="sd">    ```</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a><span class="sd">    The functional counterpart of `net` can be obtained via:</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a><span class="sd">    from evotorch.neuroevolution.net import ModuleExpectingFlatParameters</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a><span class="sd">    fnet = ModuleExpectingFlatParameters(net)</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a><span class="sd">    ```</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a><span class="sd">    Now, `fnet` is a callable object which expects network parameters</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a><span class="sd">    and network inputs. Let us call `fnet` with randomly generated network</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a><span class="sd">    parameters and with a randomly generated input tensor.</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a><span class="sd">    param_length = fnet.parameter_length</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a><span class="sd">    random_parameters = torch.randn(param_length)</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a><span class="sd">    random_input = torch.randn(3)</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a><span class="sd">    result = fnet(random_parameters, random_input)</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="sd">    ```</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">disable_autograd_tracking</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="sd">        `__init__(...)`: Initialize the `ModuleExpectingFlatParameters` instance.</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a><span class="sd">            net: The module that is to be wrapped by a functional interface.</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a><span class="sd">            disable_autograd_tracking: If given as True, all operations</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a><span class="sd">                regarding the wrapped module will be performed in the context</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a><span class="sd">                `torch.no_grad()`, forcefully disabling the autograd.</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a><span class="sd">                If given as False, autograd will not be affected.</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a><span class="sd">                The default is False.</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>        <span class="c1"># Declare the variables which will store information regarding the parameters of the module.</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__param_names</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__param_shapes</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__param_length</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__param_slices</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__num_params</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>        <span class="c1"># Iterate over the parameters of the module and fill the related information.</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>        <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>        <span class="k">for</span> <span class="n">pname</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">__param_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pname</span><span class="p">)</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>            <span class="n">shape</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">__param_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>            <span class="n">length</span> <span class="o">=</span> <span class="n">_shape_length</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">__param_length</span> <span class="o">+=</span> <span class="n">length</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>            <span class="n">j</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="n">length</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">__param_slices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">))</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>            <span class="n">i</span> <span class="o">=</span> <span class="n">j</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">__num_params</span> <span class="o">+=</span> <span class="mi">1</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__buffer_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">bname</span><span class="p">:</span> <span class="n">b</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">bname</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">()}</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__net</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;meta&quot;</span><span class="p">)</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__disable_autograd_tracking</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">disable_autograd_tracking</span><span class="p">)</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">__transfer_buffers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a><span class="sd">        Transfer the buffer tensors to the device of the given tensor.</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a><span class="sd">            x: The tensor whose device will also store the buffer tensors.</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>        <span class="k">for</span> <span class="n">bname</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">__buffer_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">__buffer_dict</span><span class="p">[</span><span class="n">bname</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__buffer_dict</span><span class="p">[</span><span class="n">bname</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">buffers</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the stored buffers&quot;&quot;&quot;</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__buffer_dict</span><span class="p">)</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">parameter_length</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__param_length</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameter_vector</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">h</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a><span class="sd">        Call the wrapped module&#39;s forward pass procedure.</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a><span class="sd">            parameter_vector: A 1-dimensional tensor which represents the</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a><span class="sd">                parameters of the tensor.</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a><span class="sd">            x: The inputs.</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a><span class="sd">            h: Hidden state(s), in case this is a recurrent network.</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a><span class="sd">            The result of the forward pass.</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a>        <span class="k">if</span> <span class="n">parameter_vector</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>                <span class="sa">f</span><span class="s2">&quot;Expected the parameters as 1 dimensional,&quot;</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>                <span class="sa">f</span><span class="s2">&quot; but the received parameter vector has </span><span class="si">{</span><span class="n">parameter_vector</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2"> dimensions&quot;</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>            <span class="p">)</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parameter_vector</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__param_length</span><span class="p">:</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>                <span class="sa">f</span><span class="s2">&quot;Expected a parameter vector of length </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__param_length</span><span class="si">}</span><span class="s2">,&quot;</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>                <span class="sa">f</span><span class="s2">&quot; but the received parameter vector&#39;s length is </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">parameter_vector</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>            <span class="p">)</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a>        <span class="n">state_args</span> <span class="o">=</span> <span class="p">[]</span> <span class="k">if</span> <span class="n">h</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[</span><span class="n">h</span><span class="p">]</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a>        <span class="n">params_and_buffers</span> <span class="o">=</span> <span class="p">{}</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">pname</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__param_names</span><span class="p">):</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a>            <span class="n">param_slice</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__param_slices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>            <span class="n">param_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__param_shapes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>            <span class="n">param</span> <span class="o">=</span> <span class="n">parameter_vector</span><span class="p">[</span><span class="n">param_slice</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">param_shape</span><span class="p">)</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>            <span class="n">params_and_buffers</span><span class="p">[</span><span class="n">pname</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>        <span class="c1"># Make sure that the buffer tensors are in the same device with x</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__transfer_buffers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>        <span class="c1"># Add the buffer tensors to the dictionary `params_and_buffers`</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>        <span class="n">params_and_buffers</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__buffer_dict</span><span class="p">)</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a>        <span class="c1"># Prepare the no-gradient context if gradient tracking is disabled</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>        <span class="n">context</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__disable_autograd_tracking</span> <span class="k">else</span> <span class="n">nullcontext</span><span class="p">()</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a>        <span class="c1"># Run the module and return the results</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a>        <span class="k">with</span> <span class="n">context</span><span class="p">:</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>            <span class="k">return</span> <span class="n">functional_call</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__net</span><span class="p">,</span> <span class="n">params_and_buffers</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">state_args</span><span class="p">]))</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="evotorch.neuroevolution.net.ModuleExpectingFlatParameters.buffers" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">buffers</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#evotorch.neuroevolution.net.ModuleExpectingFlatParameters.buffers" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get the stored buffers</p>

    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="evotorch.neuroevolution.net.ModuleExpectingFlatParameters.__call__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__call__</span><span class="p">(</span><span class="n">parameter_vector</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#evotorch.neuroevolution.net.ModuleExpectingFlatParameters.__call__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Call the wrapped module's forward pass procedure.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>parameter_vector</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A 1-dimensional tensor which represents the
parameters of the tensor.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The inputs.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>h</code>
            </td>
            <td>
                  <code><span title="typing.Any">Any</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Hidden state(s), in case this is a recurrent network.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>
        


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/functional.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-158" name="__codelineno-0-158"></a><span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameter_vector</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">h</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a><span class="sd">    Call the wrapped module&#39;s forward pass procedure.</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a><span class="sd">        parameter_vector: A 1-dimensional tensor which represents the</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a><span class="sd">            parameters of the tensor.</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a><span class="sd">        x: The inputs.</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a><span class="sd">        h: Hidden state(s), in case this is a recurrent network.</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a><span class="sd">        The result of the forward pass.</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a>    <span class="k">if</span> <span class="n">parameter_vector</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>            <span class="sa">f</span><span class="s2">&quot;Expected the parameters as 1 dimensional,&quot;</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>            <span class="sa">f</span><span class="s2">&quot; but the received parameter vector has </span><span class="si">{</span><span class="n">parameter_vector</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2"> dimensions&quot;</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>        <span class="p">)</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parameter_vector</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__param_length</span><span class="p">:</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>            <span class="sa">f</span><span class="s2">&quot;Expected a parameter vector of length </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__param_length</span><span class="si">}</span><span class="s2">,&quot;</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>            <span class="sa">f</span><span class="s2">&quot; but the received parameter vector&#39;s length is </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">parameter_vector</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>        <span class="p">)</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a>    <span class="n">state_args</span> <span class="o">=</span> <span class="p">[]</span> <span class="k">if</span> <span class="n">h</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[</span><span class="n">h</span><span class="p">]</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a>    <span class="n">params_and_buffers</span> <span class="o">=</span> <span class="p">{}</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">pname</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__param_names</span><span class="p">):</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a>        <span class="n">param_slice</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__param_slices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>        <span class="n">param_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__param_shapes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>        <span class="n">param</span> <span class="o">=</span> <span class="n">parameter_vector</span><span class="p">[</span><span class="n">param_slice</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">param_shape</span><span class="p">)</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>        <span class="n">params_and_buffers</span><span class="p">[</span><span class="n">pname</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>    <span class="c1"># Make sure that the buffer tensors are in the same device with x</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">__transfer_buffers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>    <span class="c1"># Add the buffer tensors to the dictionary `params_and_buffers`</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>    <span class="n">params_and_buffers</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__buffer_dict</span><span class="p">)</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a>    <span class="c1"># Prepare the no-gradient context if gradient tracking is disabled</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>    <span class="n">context</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__disable_autograd_tracking</span> <span class="k">else</span> <span class="n">nullcontext</span><span class="p">()</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a>    <span class="c1"># Run the module and return the results</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a>    <span class="k">with</span> <span class="n">context</span><span class="p">:</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>        <span class="k">return</span> <span class="n">functional_call</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__net</span><span class="p">,</span> <span class="n">params_and_buffers</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">state_args</span><span class="p">]))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="evotorch.neuroevolution.net.ModuleExpectingFlatParameters.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">disable_autograd_tracking</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#evotorch.neuroevolution.net.ModuleExpectingFlatParameters.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p><code>__init__(...)</code>: Initialize the <code>ModuleExpectingFlatParameters</code> instance.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>net</code>
            </td>
            <td>
                  <code><span title="torch.nn.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The module that is to be wrapped by a functional interface.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>disable_autograd_tracking</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If given as True, all operations
regarding the wrapped module will be performed in the context
<code>torch.no_grad()</code>, forcefully disabling the autograd.
If given as False, autograd will not be affected.
The default is False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/functional.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">disable_autograd_tracking</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="sd">    `__init__(...)`: Initialize the `ModuleExpectingFlatParameters` instance.</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a><span class="sd">        net: The module that is to be wrapped by a functional interface.</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a><span class="sd">        disable_autograd_tracking: If given as True, all operations</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a><span class="sd">            regarding the wrapped module will be performed in the context</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a><span class="sd">            `torch.no_grad()`, forcefully disabling the autograd.</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a><span class="sd">            If given as False, autograd will not be affected.</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a><span class="sd">            The default is False.</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>    <span class="c1"># Declare the variables which will store information regarding the parameters of the module.</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">__param_names</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">__param_shapes</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">__param_length</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">__param_slices</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">__num_params</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>    <span class="c1"># Iterate over the parameters of the module and fill the related information.</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>    <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>    <span class="k">for</span> <span class="n">pname</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__param_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pname</span><span class="p">)</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>        <span class="n">shape</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__param_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>        <span class="n">length</span> <span class="o">=</span> <span class="n">_shape_length</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__param_length</span> <span class="o">+=</span> <span class="n">length</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>        <span class="n">j</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="n">length</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__param_slices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">))</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>        <span class="n">i</span> <span class="o">=</span> <span class="n">j</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__num_params</span> <span class="o">+=</span> <span class="mi">1</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">__buffer_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">bname</span><span class="p">:</span> <span class="n">b</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">bname</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">()}</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">__net</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">__net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;meta&quot;</span><span class="p">)</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">__disable_autograd_tracking</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">disable_autograd_tracking</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="evotorch.neuroevolution.net.ModuleExpectingFlatParameters.__transfer_buffers" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">__transfer_buffers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

<a href="#evotorch.neuroevolution.net.ModuleExpectingFlatParameters.__transfer_buffers" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Transfer the buffer tensors to the device of the given tensor.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The tensor whose device will also store the buffer tensors.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/functional.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-139" name="__codelineno-0-139"></a><span class="k">def</span><span class="w"> </span><span class="nf">__transfer_buffers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a><span class="sd">    Transfer the buffer tensors to the device of the given tensor.</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a><span class="sd">        x: The tensor whose device will also store the buffer tensors.</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>    <span class="k">for</span> <span class="n">bname</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">__buffer_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__buffer_dict</span><span class="p">[</span><span class="n">bname</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__buffer_dict</span><span class="p">[</span><span class="n">bname</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="evotorch.neuroevolution.net.NetParsingError" class="doc doc-heading">
            <code>NetParsingError</code>


<a href="#evotorch.neuroevolution.net.NetParsingError" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="Exception">Exception</span></code></p>


        <p>Representation of a parsing error</p>







              <details class="quote">
                <summary>Source code in <code>evotorch/neuroevolution/net/parser.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-30">30</a></span>
<span class="normal"><a href="#__codelineno-0-31">31</a></span>
<span class="normal"><a href="#__codelineno-0-32">32</a></span>
<span class="normal"><a href="#__codelineno-0-33">33</a></span>
<span class="normal"><a href="#__codelineno-0-34">34</a></span>
<span class="normal"><a href="#__codelineno-0-35">35</a></span>
<span class="normal"><a href="#__codelineno-0-36">36</a></span>
<span class="normal"><a href="#__codelineno-0-37">37</a></span>
<span class="normal"><a href="#__codelineno-0-38">38</a></span>
<span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span>
<span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span>
<span class="normal"><a href="#__codelineno-0-55">55</a></span>
<span class="normal"><a href="#__codelineno-0-56">56</a></span>
<span class="normal"><a href="#__codelineno-0-57">57</a></span>
<span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span>
<span class="normal"><a href="#__codelineno-0-66">66</a></span>
<span class="normal"><a href="#__codelineno-0-67">67</a></span>
<span class="normal"><a href="#__codelineno-0-68">68</a></span>
<span class="normal"><a href="#__codelineno-0-69">69</a></span>
<span class="normal"><a href="#__codelineno-0-70">70</a></span>
<span class="normal"><a href="#__codelineno-0-71">71</a></span>
<span class="normal"><a href="#__codelineno-0-72">72</a></span>
<span class="normal"><a href="#__codelineno-0-73">73</a></span>
<span class="normal"><a href="#__codelineno-0-74">74</a></span>
<span class="normal"><a href="#__codelineno-0-75">75</a></span>
<span class="normal"><a href="#__codelineno-0-76">76</a></span>
<span class="normal"><a href="#__codelineno-0-77">77</a></span>
<span class="normal"><a href="#__codelineno-0-78">78</a></span>
<span class="normal"><a href="#__codelineno-0-79">79</a></span>
<span class="normal"><a href="#__codelineno-0-80">80</a></span>
<span class="normal"><a href="#__codelineno-0-81">81</a></span>
<span class="normal"><a href="#__codelineno-0-82">82</a></span>
<span class="normal"><a href="#__codelineno-0-83">83</a></span>
<span class="normal"><a href="#__codelineno-0-84">84</a></span>
<span class="normal"><a href="#__codelineno-0-85">85</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="k">class</span><span class="w"> </span><span class="nc">NetParsingError</span><span class="p">(</span><span class="ne">Exception</span><span class="p">):</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">    Representation of a parsing error</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>        <span class="n">message</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>        <span class="n">lineno</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>        <span class="n">col_offset</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>        <span class="n">original_error</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="ne">Exception</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>    <span class="p">):</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">        `__init__(...)`: Initialize the NetParsingError.</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="sd">            message: Error message, as string.</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="sd">            lineno: Erroneous line number in the string representation of the</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="sd">                neural network structure.</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">            col_offset: Erroneous column number in the string representation</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">                of the neural network structure.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">            original_error: If another error caused this parsing error,</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">                that original error can be attached to this `NetParsingError`</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">                instance via this argument.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">message</span> <span class="o">=</span> <span class="n">message</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">lineno</span> <span class="o">=</span> <span class="n">lineno</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">col_offset</span> <span class="o">=</span> <span class="n">col_offset</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">original_error</span> <span class="o">=</span> <span class="n">original_error</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_to_string</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a>        <span class="n">parts</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>        <span class="n">parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lineno</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>            <span class="n">parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot; at line(&quot;</span><span class="p">)</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>            <span class="n">parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lineno</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>            <span class="n">parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;)&quot;</span><span class="p">)</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">col_offset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>            <span class="n">parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot; at column(&quot;</span><span class="p">)</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>            <span class="n">parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">col_offset</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>            <span class="n">parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;)&quot;</span><span class="p">)</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>        <span class="n">parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;: &quot;</span><span class="p">)</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>        <span class="n">parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">message</span><span class="p">)</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>        <span class="k">return</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">parts</span><span class="p">)</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_string</span><span class="p">()</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_string</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="evotorch.neuroevolution.net.NetParsingError.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="n">lineno</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">col_offset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">original_error</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#evotorch.neuroevolution.net.NetParsingError.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p><code>__init__(...)</code>: Initialize the NetParsingError.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>message</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Error message, as string.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>lineno</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="int">int</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Erroneous line number in the string representation of the
neural network structure.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>col_offset</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="int">int</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Erroneous column number in the string representation
of the neural network structure.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>original_error</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="Exception">Exception</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If another error caused this parsing error,
that original error can be attached to this <code>NetParsingError</code>
instance via this argument.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/parser.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-35">35</a></span>
<span class="normal"><a href="#__codelineno-0-36">36</a></span>
<span class="normal"><a href="#__codelineno-0-37">37</a></span>
<span class="normal"><a href="#__codelineno-0-38">38</a></span>
<span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span>
<span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span>
<span class="normal"><a href="#__codelineno-0-55">55</a></span>
<span class="normal"><a href="#__codelineno-0-56">56</a></span>
<span class="normal"><a href="#__codelineno-0-57">57</a></span>
<span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>    <span class="n">message</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>    <span class="n">lineno</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>    <span class="n">col_offset</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>    <span class="n">original_error</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="ne">Exception</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="p">):</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">    `__init__(...)`: Initialize the NetParsingError.</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="sd">        message: Error message, as string.</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="sd">        lineno: Erroneous line number in the string representation of the</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="sd">            neural network structure.</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">        col_offset: Erroneous column number in the string representation</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">            of the neural network structure.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">        original_error: If another error caused this parsing error,</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">            that original error can be attached to this `NetParsingError`</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">            instance via this argument.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">message</span> <span class="o">=</span> <span class="n">message</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">lineno</span> <span class="o">=</span> <span class="n">lineno</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">col_offset</span> <span class="o">=</span> <span class="n">col_offset</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">original_error</span> <span class="o">=</span> <span class="n">original_error</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="evotorch.neuroevolution.net.Policy" class="doc doc-heading">
            <code>Policy</code>


<a href="#evotorch.neuroevolution.net.Policy" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">


        <p>A Policy for deciding the actions for a reinforcement learning environment.</p>
<p>This can be seen as a stateful wrapper around a PyTorch module.</p>
<p>Let us assume that we have the following PyTorch module:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
</code></pre></div>
<p>which has 48 parameters (when all the parameters are flattened).
Let us randomly generate a parameter vector for our module <code>net</code>:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="n">parameters</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">48</span><span class="p">)</span>
</code></pre></div>
<p>We can now prepare a policy:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="n">policy</span> <span class="o">=</span> <span class="n">Policy</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="n">policy</span><span class="o">.</span><span class="n">set_parameters</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>
</code></pre></div>
<p>If we generate a random observation:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="n">observation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div>
<p>We can receive our action as follows:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="n">action</span> <span class="o">=</span> <span class="n">policy</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>
</code></pre></div>
<p>If the PyTorch module that we wish to wrap is a recurrent network (i.e.
a network which expects an optional second argument for the hidden state,
and returns a second value which represents the updated hidden state),
then, the hidden state is automatically managed by the Policy instance.</p>
<p>Let us assume that we have a recurrent network named <code>recnet</code>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="n">policy</span> <span class="o">=</span> <span class="n">Policy</span><span class="p">(</span><span class="n">recnet</span><span class="p">)</span>
<a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="n">policy</span><span class="o">.</span><span class="n">set_parameters</span><span class="p">(</span><span class="n">parameters_of_recnet</span><span class="p">)</span>
</code></pre></div>
<p>In this case, because the hidden state of the network is internally
managed, the usage is still the same with our previous non-recurrent
example:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="n">action</span> <span class="o">=</span> <span class="n">policy</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>
</code></pre></div>
<p>When using a recurrent module on multiple episodes, it is important
to reset the hidden state of the network. This is achieved by the
reset method:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="n">policy</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="n">action1</span> <span class="o">=</span> <span class="n">policy</span><span class="p">(</span><span class="n">observation1</span><span class="p">)</span>
<a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>
<a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a><span class="c1"># action2 will be computed with the hidden state generated by the</span>
<a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a><span class="c1"># previous forward-pass.</span>
<a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a><span class="n">action2</span> <span class="o">=</span> <span class="n">policy</span><span class="p">(</span><span class="n">observation2</span><span class="p">)</span>
<a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a>
<a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a><span class="n">policy</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a>
<a id="__codelineno-7-10" name="__codelineno-7-10" href="#__codelineno-7-10"></a><span class="c1"># action3 will be computed according to the renewed hidden state.</span>
<a id="__codelineno-7-11" name="__codelineno-7-11" href="#__codelineno-7-11"></a><span class="n">action3</span> <span class="o">=</span> <span class="n">policy</span><span class="p">(</span><span class="n">observation3</span><span class="p">)</span>
</code></pre></div>
<p>Both for non-recurrent and recurrent networks, it is possible to
perform vectorized operations. For now, let us return to our
first non-recurrent example:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
</code></pre></div>
<p>Instead of generating only one parameter vector, we now generate
a batch of parameter vectors. Let us say that our batch size is 10:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="n">batch_of_parameters</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">48</span><span class="p">)</span>
</code></pre></div>
<p>Like we did in the non-batched examples, we can do:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="n">policy</span> <span class="o">=</span> <span class="n">Policy</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a><span class="n">policy</span><span class="o">.</span><span class="n">set_parameters</span><span class="p">(</span><span class="n">batch_of_parameters</span><span class="p">)</span>
</code></pre></div>
<p>Because we are now in the batched mode, <code>policy</code> now expects a batch
of observations and will return a batch of actions:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="n">batch_of_observations</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a><span class="n">batch_of_actions</span> <span class="o">=</span> <span class="n">policy</span><span class="p">(</span><span class="n">batch_of_observations</span><span class="p">)</span>
</code></pre></div>
<p>When doing vectorized reinforcement learning with a recurrent module,
it can be the case that only some of the environments are finished,
and therefore it is necessary to reset the hidden states associated
with those environments only. The <code>reset(...)</code> method of Policy
has a second argument to specify which of the recurrent network
instances are to be reset. For example, if the episodes of the
environments with indices 2 and 5 are about to restart (and therefore
we wish to reset the states of the networks with indices 2 and 5),
then, we can do:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="n">policy</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">]))</span>
</code></pre></div>







              <details class="quote">
                <summary>Source code in <code>evotorch/neuroevolution/net/vecrl.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1019">1019</a></span>
<span class="normal"><a href="#__codelineno-0-1020">1020</a></span>
<span class="normal"><a href="#__codelineno-0-1021">1021</a></span>
<span class="normal"><a href="#__codelineno-0-1022">1022</a></span>
<span class="normal"><a href="#__codelineno-0-1023">1023</a></span>
<span class="normal"><a href="#__codelineno-0-1024">1024</a></span>
<span class="normal"><a href="#__codelineno-0-1025">1025</a></span>
<span class="normal"><a href="#__codelineno-0-1026">1026</a></span>
<span class="normal"><a href="#__codelineno-0-1027">1027</a></span>
<span class="normal"><a href="#__codelineno-0-1028">1028</a></span>
<span class="normal"><a href="#__codelineno-0-1029">1029</a></span>
<span class="normal"><a href="#__codelineno-0-1030">1030</a></span>
<span class="normal"><a href="#__codelineno-0-1031">1031</a></span>
<span class="normal"><a href="#__codelineno-0-1032">1032</a></span>
<span class="normal"><a href="#__codelineno-0-1033">1033</a></span>
<span class="normal"><a href="#__codelineno-0-1034">1034</a></span>
<span class="normal"><a href="#__codelineno-0-1035">1035</a></span>
<span class="normal"><a href="#__codelineno-0-1036">1036</a></span>
<span class="normal"><a href="#__codelineno-0-1037">1037</a></span>
<span class="normal"><a href="#__codelineno-0-1038">1038</a></span>
<span class="normal"><a href="#__codelineno-0-1039">1039</a></span>
<span class="normal"><a href="#__codelineno-0-1040">1040</a></span>
<span class="normal"><a href="#__codelineno-0-1041">1041</a></span>
<span class="normal"><a href="#__codelineno-0-1042">1042</a></span>
<span class="normal"><a href="#__codelineno-0-1043">1043</a></span>
<span class="normal"><a href="#__codelineno-0-1044">1044</a></span>
<span class="normal"><a href="#__codelineno-0-1045">1045</a></span>
<span class="normal"><a href="#__codelineno-0-1046">1046</a></span>
<span class="normal"><a href="#__codelineno-0-1047">1047</a></span>
<span class="normal"><a href="#__codelineno-0-1048">1048</a></span>
<span class="normal"><a href="#__codelineno-0-1049">1049</a></span>
<span class="normal"><a href="#__codelineno-0-1050">1050</a></span>
<span class="normal"><a href="#__codelineno-0-1051">1051</a></span>
<span class="normal"><a href="#__codelineno-0-1052">1052</a></span>
<span class="normal"><a href="#__codelineno-0-1053">1053</a></span>
<span class="normal"><a href="#__codelineno-0-1054">1054</a></span>
<span class="normal"><a href="#__codelineno-0-1055">1055</a></span>
<span class="normal"><a href="#__codelineno-0-1056">1056</a></span>
<span class="normal"><a href="#__codelineno-0-1057">1057</a></span>
<span class="normal"><a href="#__codelineno-0-1058">1058</a></span>
<span class="normal"><a href="#__codelineno-0-1059">1059</a></span>
<span class="normal"><a href="#__codelineno-0-1060">1060</a></span>
<span class="normal"><a href="#__codelineno-0-1061">1061</a></span>
<span class="normal"><a href="#__codelineno-0-1062">1062</a></span>
<span class="normal"><a href="#__codelineno-0-1063">1063</a></span>
<span class="normal"><a href="#__codelineno-0-1064">1064</a></span>
<span class="normal"><a href="#__codelineno-0-1065">1065</a></span>
<span class="normal"><a href="#__codelineno-0-1066">1066</a></span>
<span class="normal"><a href="#__codelineno-0-1067">1067</a></span>
<span class="normal"><a href="#__codelineno-0-1068">1068</a></span>
<span class="normal"><a href="#__codelineno-0-1069">1069</a></span>
<span class="normal"><a href="#__codelineno-0-1070">1070</a></span>
<span class="normal"><a href="#__codelineno-0-1071">1071</a></span>
<span class="normal"><a href="#__codelineno-0-1072">1072</a></span>
<span class="normal"><a href="#__codelineno-0-1073">1073</a></span>
<span class="normal"><a href="#__codelineno-0-1074">1074</a></span>
<span class="normal"><a href="#__codelineno-0-1075">1075</a></span>
<span class="normal"><a href="#__codelineno-0-1076">1076</a></span>
<span class="normal"><a href="#__codelineno-0-1077">1077</a></span>
<span class="normal"><a href="#__codelineno-0-1078">1078</a></span>
<span class="normal"><a href="#__codelineno-0-1079">1079</a></span>
<span class="normal"><a href="#__codelineno-0-1080">1080</a></span>
<span class="normal"><a href="#__codelineno-0-1081">1081</a></span>
<span class="normal"><a href="#__codelineno-0-1082">1082</a></span>
<span class="normal"><a href="#__codelineno-0-1083">1083</a></span>
<span class="normal"><a href="#__codelineno-0-1084">1084</a></span>
<span class="normal"><a href="#__codelineno-0-1085">1085</a></span>
<span class="normal"><a href="#__codelineno-0-1086">1086</a></span>
<span class="normal"><a href="#__codelineno-0-1087">1087</a></span>
<span class="normal"><a href="#__codelineno-0-1088">1088</a></span>
<span class="normal"><a href="#__codelineno-0-1089">1089</a></span>
<span class="normal"><a href="#__codelineno-0-1090">1090</a></span>
<span class="normal"><a href="#__codelineno-0-1091">1091</a></span>
<span class="normal"><a href="#__codelineno-0-1092">1092</a></span>
<span class="normal"><a href="#__codelineno-0-1093">1093</a></span>
<span class="normal"><a href="#__codelineno-0-1094">1094</a></span>
<span class="normal"><a href="#__codelineno-0-1095">1095</a></span>
<span class="normal"><a href="#__codelineno-0-1096">1096</a></span>
<span class="normal"><a href="#__codelineno-0-1097">1097</a></span>
<span class="normal"><a href="#__codelineno-0-1098">1098</a></span>
<span class="normal"><a href="#__codelineno-0-1099">1099</a></span>
<span class="normal"><a href="#__codelineno-0-1100">1100</a></span>
<span class="normal"><a href="#__codelineno-0-1101">1101</a></span>
<span class="normal"><a href="#__codelineno-0-1102">1102</a></span>
<span class="normal"><a href="#__codelineno-0-1103">1103</a></span>
<span class="normal"><a href="#__codelineno-0-1104">1104</a></span>
<span class="normal"><a href="#__codelineno-0-1105">1105</a></span>
<span class="normal"><a href="#__codelineno-0-1106">1106</a></span>
<span class="normal"><a href="#__codelineno-0-1107">1107</a></span>
<span class="normal"><a href="#__codelineno-0-1108">1108</a></span>
<span class="normal"><a href="#__codelineno-0-1109">1109</a></span>
<span class="normal"><a href="#__codelineno-0-1110">1110</a></span>
<span class="normal"><a href="#__codelineno-0-1111">1111</a></span>
<span class="normal"><a href="#__codelineno-0-1112">1112</a></span>
<span class="normal"><a href="#__codelineno-0-1113">1113</a></span>
<span class="normal"><a href="#__codelineno-0-1114">1114</a></span>
<span class="normal"><a href="#__codelineno-0-1115">1115</a></span>
<span class="normal"><a href="#__codelineno-0-1116">1116</a></span>
<span class="normal"><a href="#__codelineno-0-1117">1117</a></span>
<span class="normal"><a href="#__codelineno-0-1118">1118</a></span>
<span class="normal"><a href="#__codelineno-0-1119">1119</a></span>
<span class="normal"><a href="#__codelineno-0-1120">1120</a></span>
<span class="normal"><a href="#__codelineno-0-1121">1121</a></span>
<span class="normal"><a href="#__codelineno-0-1122">1122</a></span>
<span class="normal"><a href="#__codelineno-0-1123">1123</a></span>
<span class="normal"><a href="#__codelineno-0-1124">1124</a></span>
<span class="normal"><a href="#__codelineno-0-1125">1125</a></span>
<span class="normal"><a href="#__codelineno-0-1126">1126</a></span>
<span class="normal"><a href="#__codelineno-0-1127">1127</a></span>
<span class="normal"><a href="#__codelineno-0-1128">1128</a></span>
<span class="normal"><a href="#__codelineno-0-1129">1129</a></span>
<span class="normal"><a href="#__codelineno-0-1130">1130</a></span>
<span class="normal"><a href="#__codelineno-0-1131">1131</a></span>
<span class="normal"><a href="#__codelineno-0-1132">1132</a></span>
<span class="normal"><a href="#__codelineno-0-1133">1133</a></span>
<span class="normal"><a href="#__codelineno-0-1134">1134</a></span>
<span class="normal"><a href="#__codelineno-0-1135">1135</a></span>
<span class="normal"><a href="#__codelineno-0-1136">1136</a></span>
<span class="normal"><a href="#__codelineno-0-1137">1137</a></span>
<span class="normal"><a href="#__codelineno-0-1138">1138</a></span>
<span class="normal"><a href="#__codelineno-0-1139">1139</a></span>
<span class="normal"><a href="#__codelineno-0-1140">1140</a></span>
<span class="normal"><a href="#__codelineno-0-1141">1141</a></span>
<span class="normal"><a href="#__codelineno-0-1142">1142</a></span>
<span class="normal"><a href="#__codelineno-0-1143">1143</a></span>
<span class="normal"><a href="#__codelineno-0-1144">1144</a></span>
<span class="normal"><a href="#__codelineno-0-1145">1145</a></span>
<span class="normal"><a href="#__codelineno-0-1146">1146</a></span>
<span class="normal"><a href="#__codelineno-0-1147">1147</a></span>
<span class="normal"><a href="#__codelineno-0-1148">1148</a></span>
<span class="normal"><a href="#__codelineno-0-1149">1149</a></span>
<span class="normal"><a href="#__codelineno-0-1150">1150</a></span>
<span class="normal"><a href="#__codelineno-0-1151">1151</a></span>
<span class="normal"><a href="#__codelineno-0-1152">1152</a></span>
<span class="normal"><a href="#__codelineno-0-1153">1153</a></span>
<span class="normal"><a href="#__codelineno-0-1154">1154</a></span>
<span class="normal"><a href="#__codelineno-0-1155">1155</a></span>
<span class="normal"><a href="#__codelineno-0-1156">1156</a></span>
<span class="normal"><a href="#__codelineno-0-1157">1157</a></span>
<span class="normal"><a href="#__codelineno-0-1158">1158</a></span>
<span class="normal"><a href="#__codelineno-0-1159">1159</a></span>
<span class="normal"><a href="#__codelineno-0-1160">1160</a></span>
<span class="normal"><a href="#__codelineno-0-1161">1161</a></span>
<span class="normal"><a href="#__codelineno-0-1162">1162</a></span>
<span class="normal"><a href="#__codelineno-0-1163">1163</a></span>
<span class="normal"><a href="#__codelineno-0-1164">1164</a></span>
<span class="normal"><a href="#__codelineno-0-1165">1165</a></span>
<span class="normal"><a href="#__codelineno-0-1166">1166</a></span>
<span class="normal"><a href="#__codelineno-0-1167">1167</a></span>
<span class="normal"><a href="#__codelineno-0-1168">1168</a></span>
<span class="normal"><a href="#__codelineno-0-1169">1169</a></span>
<span class="normal"><a href="#__codelineno-0-1170">1170</a></span>
<span class="normal"><a href="#__codelineno-0-1171">1171</a></span>
<span class="normal"><a href="#__codelineno-0-1172">1172</a></span>
<span class="normal"><a href="#__codelineno-0-1173">1173</a></span>
<span class="normal"><a href="#__codelineno-0-1174">1174</a></span>
<span class="normal"><a href="#__codelineno-0-1175">1175</a></span>
<span class="normal"><a href="#__codelineno-0-1176">1176</a></span>
<span class="normal"><a href="#__codelineno-0-1177">1177</a></span>
<span class="normal"><a href="#__codelineno-0-1178">1178</a></span>
<span class="normal"><a href="#__codelineno-0-1179">1179</a></span>
<span class="normal"><a href="#__codelineno-0-1180">1180</a></span>
<span class="normal"><a href="#__codelineno-0-1181">1181</a></span>
<span class="normal"><a href="#__codelineno-0-1182">1182</a></span>
<span class="normal"><a href="#__codelineno-0-1183">1183</a></span>
<span class="normal"><a href="#__codelineno-0-1184">1184</a></span>
<span class="normal"><a href="#__codelineno-0-1185">1185</a></span>
<span class="normal"><a href="#__codelineno-0-1186">1186</a></span>
<span class="normal"><a href="#__codelineno-0-1187">1187</a></span>
<span class="normal"><a href="#__codelineno-0-1188">1188</a></span>
<span class="normal"><a href="#__codelineno-0-1189">1189</a></span>
<span class="normal"><a href="#__codelineno-0-1190">1190</a></span>
<span class="normal"><a href="#__codelineno-0-1191">1191</a></span>
<span class="normal"><a href="#__codelineno-0-1192">1192</a></span>
<span class="normal"><a href="#__codelineno-0-1193">1193</a></span>
<span class="normal"><a href="#__codelineno-0-1194">1194</a></span>
<span class="normal"><a href="#__codelineno-0-1195">1195</a></span>
<span class="normal"><a href="#__codelineno-0-1196">1196</a></span>
<span class="normal"><a href="#__codelineno-0-1197">1197</a></span>
<span class="normal"><a href="#__codelineno-0-1198">1198</a></span>
<span class="normal"><a href="#__codelineno-0-1199">1199</a></span>
<span class="normal"><a href="#__codelineno-0-1200">1200</a></span>
<span class="normal"><a href="#__codelineno-0-1201">1201</a></span>
<span class="normal"><a href="#__codelineno-0-1202">1202</a></span>
<span class="normal"><a href="#__codelineno-0-1203">1203</a></span>
<span class="normal"><a href="#__codelineno-0-1204">1204</a></span>
<span class="normal"><a href="#__codelineno-0-1205">1205</a></span>
<span class="normal"><a href="#__codelineno-0-1206">1206</a></span>
<span class="normal"><a href="#__codelineno-0-1207">1207</a></span>
<span class="normal"><a href="#__codelineno-0-1208">1208</a></span>
<span class="normal"><a href="#__codelineno-0-1209">1209</a></span>
<span class="normal"><a href="#__codelineno-0-1210">1210</a></span>
<span class="normal"><a href="#__codelineno-0-1211">1211</a></span>
<span class="normal"><a href="#__codelineno-0-1212">1212</a></span>
<span class="normal"><a href="#__codelineno-0-1213">1213</a></span>
<span class="normal"><a href="#__codelineno-0-1214">1214</a></span>
<span class="normal"><a href="#__codelineno-0-1215">1215</a></span>
<span class="normal"><a href="#__codelineno-0-1216">1216</a></span>
<span class="normal"><a href="#__codelineno-0-1217">1217</a></span>
<span class="normal"><a href="#__codelineno-0-1218">1218</a></span>
<span class="normal"><a href="#__codelineno-0-1219">1219</a></span>
<span class="normal"><a href="#__codelineno-0-1220">1220</a></span>
<span class="normal"><a href="#__codelineno-0-1221">1221</a></span>
<span class="normal"><a href="#__codelineno-0-1222">1222</a></span>
<span class="normal"><a href="#__codelineno-0-1223">1223</a></span>
<span class="normal"><a href="#__codelineno-0-1224">1224</a></span>
<span class="normal"><a href="#__codelineno-0-1225">1225</a></span>
<span class="normal"><a href="#__codelineno-0-1226">1226</a></span>
<span class="normal"><a href="#__codelineno-0-1227">1227</a></span>
<span class="normal"><a href="#__codelineno-0-1228">1228</a></span>
<span class="normal"><a href="#__codelineno-0-1229">1229</a></span>
<span class="normal"><a href="#__codelineno-0-1230">1230</a></span>
<span class="normal"><a href="#__codelineno-0-1231">1231</a></span>
<span class="normal"><a href="#__codelineno-0-1232">1232</a></span>
<span class="normal"><a href="#__codelineno-0-1233">1233</a></span>
<span class="normal"><a href="#__codelineno-0-1234">1234</a></span>
<span class="normal"><a href="#__codelineno-0-1235">1235</a></span>
<span class="normal"><a href="#__codelineno-0-1236">1236</a></span>
<span class="normal"><a href="#__codelineno-0-1237">1237</a></span>
<span class="normal"><a href="#__codelineno-0-1238">1238</a></span>
<span class="normal"><a href="#__codelineno-0-1239">1239</a></span>
<span class="normal"><a href="#__codelineno-0-1240">1240</a></span>
<span class="normal"><a href="#__codelineno-0-1241">1241</a></span>
<span class="normal"><a href="#__codelineno-0-1242">1242</a></span>
<span class="normal"><a href="#__codelineno-0-1243">1243</a></span>
<span class="normal"><a href="#__codelineno-0-1244">1244</a></span>
<span class="normal"><a href="#__codelineno-0-1245">1245</a></span>
<span class="normal"><a href="#__codelineno-0-1246">1246</a></span>
<span class="normal"><a href="#__codelineno-0-1247">1247</a></span>
<span class="normal"><a href="#__codelineno-0-1248">1248</a></span>
<span class="normal"><a href="#__codelineno-0-1249">1249</a></span>
<span class="normal"><a href="#__codelineno-0-1250">1250</a></span>
<span class="normal"><a href="#__codelineno-0-1251">1251</a></span>
<span class="normal"><a href="#__codelineno-0-1252">1252</a></span>
<span class="normal"><a href="#__codelineno-0-1253">1253</a></span>
<span class="normal"><a href="#__codelineno-0-1254">1254</a></span>
<span class="normal"><a href="#__codelineno-0-1255">1255</a></span>
<span class="normal"><a href="#__codelineno-0-1256">1256</a></span>
<span class="normal"><a href="#__codelineno-0-1257">1257</a></span>
<span class="normal"><a href="#__codelineno-0-1258">1258</a></span>
<span class="normal"><a href="#__codelineno-0-1259">1259</a></span>
<span class="normal"><a href="#__codelineno-0-1260">1260</a></span>
<span class="normal"><a href="#__codelineno-0-1261">1261</a></span>
<span class="normal"><a href="#__codelineno-0-1262">1262</a></span>
<span class="normal"><a href="#__codelineno-0-1263">1263</a></span>
<span class="normal"><a href="#__codelineno-0-1264">1264</a></span>
<span class="normal"><a href="#__codelineno-0-1265">1265</a></span>
<span class="normal"><a href="#__codelineno-0-1266">1266</a></span>
<span class="normal"><a href="#__codelineno-0-1267">1267</a></span>
<span class="normal"><a href="#__codelineno-0-1268">1268</a></span>
<span class="normal"><a href="#__codelineno-0-1269">1269</a></span>
<span class="normal"><a href="#__codelineno-0-1270">1270</a></span>
<span class="normal"><a href="#__codelineno-0-1271">1271</a></span>
<span class="normal"><a href="#__codelineno-0-1272">1272</a></span>
<span class="normal"><a href="#__codelineno-0-1273">1273</a></span>
<span class="normal"><a href="#__codelineno-0-1274">1274</a></span>
<span class="normal"><a href="#__codelineno-0-1275">1275</a></span>
<span class="normal"><a href="#__codelineno-0-1276">1276</a></span>
<span class="normal"><a href="#__codelineno-0-1277">1277</a></span>
<span class="normal"><a href="#__codelineno-0-1278">1278</a></span>
<span class="normal"><a href="#__codelineno-0-1279">1279</a></span>
<span class="normal"><a href="#__codelineno-0-1280">1280</a></span>
<span class="normal"><a href="#__codelineno-0-1281">1281</a></span>
<span class="normal"><a href="#__codelineno-0-1282">1282</a></span>
<span class="normal"><a href="#__codelineno-0-1283">1283</a></span>
<span class="normal"><a href="#__codelineno-0-1284">1284</a></span>
<span class="normal"><a href="#__codelineno-0-1285">1285</a></span>
<span class="normal"><a href="#__codelineno-0-1286">1286</a></span>
<span class="normal"><a href="#__codelineno-0-1287">1287</a></span>
<span class="normal"><a href="#__codelineno-0-1288">1288</a></span>
<span class="normal"><a href="#__codelineno-0-1289">1289</a></span>
<span class="normal"><a href="#__codelineno-0-1290">1290</a></span>
<span class="normal"><a href="#__codelineno-0-1291">1291</a></span>
<span class="normal"><a href="#__codelineno-0-1292">1292</a></span>
<span class="normal"><a href="#__codelineno-0-1293">1293</a></span>
<span class="normal"><a href="#__codelineno-0-1294">1294</a></span>
<span class="normal"><a href="#__codelineno-0-1295">1295</a></span>
<span class="normal"><a href="#__codelineno-0-1296">1296</a></span>
<span class="normal"><a href="#__codelineno-0-1297">1297</a></span>
<span class="normal"><a href="#__codelineno-0-1298">1298</a></span>
<span class="normal"><a href="#__codelineno-0-1299">1299</a></span>
<span class="normal"><a href="#__codelineno-0-1300">1300</a></span>
<span class="normal"><a href="#__codelineno-0-1301">1301</a></span>
<span class="normal"><a href="#__codelineno-0-1302">1302</a></span>
<span class="normal"><a href="#__codelineno-0-1303">1303</a></span>
<span class="normal"><a href="#__codelineno-0-1304">1304</a></span>
<span class="normal"><a href="#__codelineno-0-1305">1305</a></span>
<span class="normal"><a href="#__codelineno-0-1306">1306</a></span>
<span class="normal"><a href="#__codelineno-0-1307">1307</a></span>
<span class="normal"><a href="#__codelineno-0-1308">1308</a></span>
<span class="normal"><a href="#__codelineno-0-1309">1309</a></span>
<span class="normal"><a href="#__codelineno-0-1310">1310</a></span>
<span class="normal"><a href="#__codelineno-0-1311">1311</a></span>
<span class="normal"><a href="#__codelineno-0-1312">1312</a></span>
<span class="normal"><a href="#__codelineno-0-1313">1313</a></span>
<span class="normal"><a href="#__codelineno-0-1314">1314</a></span>
<span class="normal"><a href="#__codelineno-0-1315">1315</a></span>
<span class="normal"><a href="#__codelineno-0-1316">1316</a></span>
<span class="normal"><a href="#__codelineno-0-1317">1317</a></span>
<span class="normal"><a href="#__codelineno-0-1318">1318</a></span>
<span class="normal"><a href="#__codelineno-0-1319">1319</a></span>
<span class="normal"><a href="#__codelineno-0-1320">1320</a></span>
<span class="normal"><a href="#__codelineno-0-1321">1321</a></span>
<span class="normal"><a href="#__codelineno-0-1322">1322</a></span>
<span class="normal"><a href="#__codelineno-0-1323">1323</a></span>
<span class="normal"><a href="#__codelineno-0-1324">1324</a></span>
<span class="normal"><a href="#__codelineno-0-1325">1325</a></span>
<span class="normal"><a href="#__codelineno-0-1326">1326</a></span>
<span class="normal"><a href="#__codelineno-0-1327">1327</a></span>
<span class="normal"><a href="#__codelineno-0-1328">1328</a></span>
<span class="normal"><a href="#__codelineno-0-1329">1329</a></span>
<span class="normal"><a href="#__codelineno-0-1330">1330</a></span>
<span class="normal"><a href="#__codelineno-0-1331">1331</a></span>
<span class="normal"><a href="#__codelineno-0-1332">1332</a></span>
<span class="normal"><a href="#__codelineno-0-1333">1333</a></span>
<span class="normal"><a href="#__codelineno-0-1334">1334</a></span>
<span class="normal"><a href="#__codelineno-0-1335">1335</a></span>
<span class="normal"><a href="#__codelineno-0-1336">1336</a></span>
<span class="normal"><a href="#__codelineno-0-1337">1337</a></span>
<span class="normal"><a href="#__codelineno-0-1338">1338</a></span>
<span class="normal"><a href="#__codelineno-0-1339">1339</a></span>
<span class="normal"><a href="#__codelineno-0-1340">1340</a></span>
<span class="normal"><a href="#__codelineno-0-1341">1341</a></span>
<span class="normal"><a href="#__codelineno-0-1342">1342</a></span>
<span class="normal"><a href="#__codelineno-0-1343">1343</a></span>
<span class="normal"><a href="#__codelineno-0-1344">1344</a></span>
<span class="normal"><a href="#__codelineno-0-1345">1345</a></span>
<span class="normal"><a href="#__codelineno-0-1346">1346</a></span>
<span class="normal"><a href="#__codelineno-0-1347">1347</a></span>
<span class="normal"><a href="#__codelineno-0-1348">1348</a></span>
<span class="normal"><a href="#__codelineno-0-1349">1349</a></span>
<span class="normal"><a href="#__codelineno-0-1350">1350</a></span>
<span class="normal"><a href="#__codelineno-0-1351">1351</a></span>
<span class="normal"><a href="#__codelineno-0-1352">1352</a></span>
<span class="normal"><a href="#__codelineno-0-1353">1353</a></span>
<span class="normal"><a href="#__codelineno-0-1354">1354</a></span>
<span class="normal"><a href="#__codelineno-0-1355">1355</a></span>
<span class="normal"><a href="#__codelineno-0-1356">1356</a></span>
<span class="normal"><a href="#__codelineno-0-1357">1357</a></span>
<span class="normal"><a href="#__codelineno-0-1358">1358</a></span>
<span class="normal"><a href="#__codelineno-0-1359">1359</a></span>
<span class="normal"><a href="#__codelineno-0-1360">1360</a></span>
<span class="normal"><a href="#__codelineno-0-1361">1361</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1019" name="__codelineno-0-1019"></a><span class="k">class</span><span class="w"> </span><span class="nc">Policy</span><span class="p">:</span>
<a id="__codelineno-0-1020" name="__codelineno-0-1020"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-1021" name="__codelineno-0-1021"></a><span class="sd">    A Policy for deciding the actions for a reinforcement learning environment.</span>
<a id="__codelineno-0-1022" name="__codelineno-0-1022"></a>
<a id="__codelineno-0-1023" name="__codelineno-0-1023"></a><span class="sd">    This can be seen as a stateful wrapper around a PyTorch module.</span>
<a id="__codelineno-0-1024" name="__codelineno-0-1024"></a>
<a id="__codelineno-0-1025" name="__codelineno-0-1025"></a><span class="sd">    Let us assume that we have the following PyTorch module:</span>
<a id="__codelineno-0-1026" name="__codelineno-0-1026"></a>
<a id="__codelineno-0-1027" name="__codelineno-0-1027"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-1028" name="__codelineno-0-1028"></a><span class="sd">    from torch import nn</span>
<a id="__codelineno-0-1029" name="__codelineno-0-1029"></a>
<a id="__codelineno-0-1030" name="__codelineno-0-1030"></a><span class="sd">    net = nn.Linear(5, 8)</span>
<a id="__codelineno-0-1031" name="__codelineno-0-1031"></a><span class="sd">    ```</span>
<a id="__codelineno-0-1032" name="__codelineno-0-1032"></a>
<a id="__codelineno-0-1033" name="__codelineno-0-1033"></a><span class="sd">    which has 48 parameters (when all the parameters are flattened).</span>
<a id="__codelineno-0-1034" name="__codelineno-0-1034"></a><span class="sd">    Let us randomly generate a parameter vector for our module `net`:</span>
<a id="__codelineno-0-1035" name="__codelineno-0-1035"></a>
<a id="__codelineno-0-1036" name="__codelineno-0-1036"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-1037" name="__codelineno-0-1037"></a><span class="sd">    parameters = torch.randn(48)</span>
<a id="__codelineno-0-1038" name="__codelineno-0-1038"></a><span class="sd">    ```</span>
<a id="__codelineno-0-1039" name="__codelineno-0-1039"></a>
<a id="__codelineno-0-1040" name="__codelineno-0-1040"></a><span class="sd">    We can now prepare a policy:</span>
<a id="__codelineno-0-1041" name="__codelineno-0-1041"></a>
<a id="__codelineno-0-1042" name="__codelineno-0-1042"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-1043" name="__codelineno-0-1043"></a><span class="sd">    policy = Policy(net)</span>
<a id="__codelineno-0-1044" name="__codelineno-0-1044"></a><span class="sd">    policy.set_parameters(parameters)</span>
<a id="__codelineno-0-1045" name="__codelineno-0-1045"></a><span class="sd">    ```</span>
<a id="__codelineno-0-1046" name="__codelineno-0-1046"></a>
<a id="__codelineno-0-1047" name="__codelineno-0-1047"></a><span class="sd">    If we generate a random observation:</span>
<a id="__codelineno-0-1048" name="__codelineno-0-1048"></a>
<a id="__codelineno-0-1049" name="__codelineno-0-1049"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-1050" name="__codelineno-0-1050"></a><span class="sd">    observation = torch.randn(5)</span>
<a id="__codelineno-0-1051" name="__codelineno-0-1051"></a><span class="sd">    ```</span>
<a id="__codelineno-0-1052" name="__codelineno-0-1052"></a>
<a id="__codelineno-0-1053" name="__codelineno-0-1053"></a><span class="sd">    We can receive our action as follows:</span>
<a id="__codelineno-0-1054" name="__codelineno-0-1054"></a>
<a id="__codelineno-0-1055" name="__codelineno-0-1055"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-1056" name="__codelineno-0-1056"></a><span class="sd">    action = policy(observation)</span>
<a id="__codelineno-0-1057" name="__codelineno-0-1057"></a><span class="sd">    ```</span>
<a id="__codelineno-0-1058" name="__codelineno-0-1058"></a>
<a id="__codelineno-0-1059" name="__codelineno-0-1059"></a><span class="sd">    If the PyTorch module that we wish to wrap is a recurrent network (i.e.</span>
<a id="__codelineno-0-1060" name="__codelineno-0-1060"></a><span class="sd">    a network which expects an optional second argument for the hidden state,</span>
<a id="__codelineno-0-1061" name="__codelineno-0-1061"></a><span class="sd">    and returns a second value which represents the updated hidden state),</span>
<a id="__codelineno-0-1062" name="__codelineno-0-1062"></a><span class="sd">    then, the hidden state is automatically managed by the Policy instance.</span>
<a id="__codelineno-0-1063" name="__codelineno-0-1063"></a>
<a id="__codelineno-0-1064" name="__codelineno-0-1064"></a><span class="sd">    Let us assume that we have a recurrent network named `recnet`.</span>
<a id="__codelineno-0-1065" name="__codelineno-0-1065"></a>
<a id="__codelineno-0-1066" name="__codelineno-0-1066"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-1067" name="__codelineno-0-1067"></a><span class="sd">    policy = Policy(recnet)</span>
<a id="__codelineno-0-1068" name="__codelineno-0-1068"></a><span class="sd">    policy.set_parameters(parameters_of_recnet)</span>
<a id="__codelineno-0-1069" name="__codelineno-0-1069"></a><span class="sd">    ```</span>
<a id="__codelineno-0-1070" name="__codelineno-0-1070"></a>
<a id="__codelineno-0-1071" name="__codelineno-0-1071"></a><span class="sd">    In this case, because the hidden state of the network is internally</span>
<a id="__codelineno-0-1072" name="__codelineno-0-1072"></a><span class="sd">    managed, the usage is still the same with our previous non-recurrent</span>
<a id="__codelineno-0-1073" name="__codelineno-0-1073"></a><span class="sd">    example:</span>
<a id="__codelineno-0-1074" name="__codelineno-0-1074"></a>
<a id="__codelineno-0-1075" name="__codelineno-0-1075"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-1076" name="__codelineno-0-1076"></a><span class="sd">    action = policy(observation)</span>
<a id="__codelineno-0-1077" name="__codelineno-0-1077"></a><span class="sd">    ```</span>
<a id="__codelineno-0-1078" name="__codelineno-0-1078"></a>
<a id="__codelineno-0-1079" name="__codelineno-0-1079"></a><span class="sd">    When using a recurrent module on multiple episodes, it is important</span>
<a id="__codelineno-0-1080" name="__codelineno-0-1080"></a><span class="sd">    to reset the hidden state of the network. This is achieved by the</span>
<a id="__codelineno-0-1081" name="__codelineno-0-1081"></a><span class="sd">    reset method:</span>
<a id="__codelineno-0-1082" name="__codelineno-0-1082"></a>
<a id="__codelineno-0-1083" name="__codelineno-0-1083"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-1084" name="__codelineno-0-1084"></a><span class="sd">    policy.reset()</span>
<a id="__codelineno-0-1085" name="__codelineno-0-1085"></a><span class="sd">    action1 = policy(observation1)</span>
<a id="__codelineno-0-1086" name="__codelineno-0-1086"></a>
<a id="__codelineno-0-1087" name="__codelineno-0-1087"></a><span class="sd">    # action2 will be computed with the hidden state generated by the</span>
<a id="__codelineno-0-1088" name="__codelineno-0-1088"></a><span class="sd">    # previous forward-pass.</span>
<a id="__codelineno-0-1089" name="__codelineno-0-1089"></a><span class="sd">    action2 = policy(observation2)</span>
<a id="__codelineno-0-1090" name="__codelineno-0-1090"></a>
<a id="__codelineno-0-1091" name="__codelineno-0-1091"></a><span class="sd">    policy.reset()</span>
<a id="__codelineno-0-1092" name="__codelineno-0-1092"></a>
<a id="__codelineno-0-1093" name="__codelineno-0-1093"></a><span class="sd">    # action3 will be computed according to the renewed hidden state.</span>
<a id="__codelineno-0-1094" name="__codelineno-0-1094"></a><span class="sd">    action3 = policy(observation3)</span>
<a id="__codelineno-0-1095" name="__codelineno-0-1095"></a><span class="sd">    ```</span>
<a id="__codelineno-0-1096" name="__codelineno-0-1096"></a>
<a id="__codelineno-0-1097" name="__codelineno-0-1097"></a><span class="sd">    Both for non-recurrent and recurrent networks, it is possible to</span>
<a id="__codelineno-0-1098" name="__codelineno-0-1098"></a><span class="sd">    perform vectorized operations. For now, let us return to our</span>
<a id="__codelineno-0-1099" name="__codelineno-0-1099"></a><span class="sd">    first non-recurrent example:</span>
<a id="__codelineno-0-1100" name="__codelineno-0-1100"></a>
<a id="__codelineno-0-1101" name="__codelineno-0-1101"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-1102" name="__codelineno-0-1102"></a><span class="sd">    net = nn.Linear(5, 8)</span>
<a id="__codelineno-0-1103" name="__codelineno-0-1103"></a><span class="sd">    ```</span>
<a id="__codelineno-0-1104" name="__codelineno-0-1104"></a>
<a id="__codelineno-0-1105" name="__codelineno-0-1105"></a><span class="sd">    Instead of generating only one parameter vector, we now generate</span>
<a id="__codelineno-0-1106" name="__codelineno-0-1106"></a><span class="sd">    a batch of parameter vectors. Let us say that our batch size is 10:</span>
<a id="__codelineno-0-1107" name="__codelineno-0-1107"></a>
<a id="__codelineno-0-1108" name="__codelineno-0-1108"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-1109" name="__codelineno-0-1109"></a><span class="sd">    batch_of_parameters = torch.randn(10, 48)</span>
<a id="__codelineno-0-1110" name="__codelineno-0-1110"></a><span class="sd">    ```</span>
<a id="__codelineno-0-1111" name="__codelineno-0-1111"></a>
<a id="__codelineno-0-1112" name="__codelineno-0-1112"></a><span class="sd">    Like we did in the non-batched examples, we can do:</span>
<a id="__codelineno-0-1113" name="__codelineno-0-1113"></a>
<a id="__codelineno-0-1114" name="__codelineno-0-1114"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-1115" name="__codelineno-0-1115"></a><span class="sd">    policy = Policy(net)</span>
<a id="__codelineno-0-1116" name="__codelineno-0-1116"></a><span class="sd">    policy.set_parameters(batch_of_parameters)</span>
<a id="__codelineno-0-1117" name="__codelineno-0-1117"></a><span class="sd">    ```</span>
<a id="__codelineno-0-1118" name="__codelineno-0-1118"></a>
<a id="__codelineno-0-1119" name="__codelineno-0-1119"></a><span class="sd">    Because we are now in the batched mode, `policy` now expects a batch</span>
<a id="__codelineno-0-1120" name="__codelineno-0-1120"></a><span class="sd">    of observations and will return a batch of actions:</span>
<a id="__codelineno-0-1121" name="__codelineno-0-1121"></a>
<a id="__codelineno-0-1122" name="__codelineno-0-1122"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-1123" name="__codelineno-0-1123"></a><span class="sd">    batch_of_observations = torch.randn(10, 5)</span>
<a id="__codelineno-0-1124" name="__codelineno-0-1124"></a><span class="sd">    batch_of_actions = policy(batch_of_observations)</span>
<a id="__codelineno-0-1125" name="__codelineno-0-1125"></a><span class="sd">    ```</span>
<a id="__codelineno-0-1126" name="__codelineno-0-1126"></a>
<a id="__codelineno-0-1127" name="__codelineno-0-1127"></a><span class="sd">    When doing vectorized reinforcement learning with a recurrent module,</span>
<a id="__codelineno-0-1128" name="__codelineno-0-1128"></a><span class="sd">    it can be the case that only some of the environments are finished,</span>
<a id="__codelineno-0-1129" name="__codelineno-0-1129"></a><span class="sd">    and therefore it is necessary to reset the hidden states associated</span>
<a id="__codelineno-0-1130" name="__codelineno-0-1130"></a><span class="sd">    with those environments only. The `reset(...)` method of Policy</span>
<a id="__codelineno-0-1131" name="__codelineno-0-1131"></a><span class="sd">    has a second argument to specify which of the recurrent network</span>
<a id="__codelineno-0-1132" name="__codelineno-0-1132"></a><span class="sd">    instances are to be reset. For example, if the episodes of the</span>
<a id="__codelineno-0-1133" name="__codelineno-0-1133"></a><span class="sd">    environments with indices 2 and 5 are about to restart (and therefore</span>
<a id="__codelineno-0-1134" name="__codelineno-0-1134"></a><span class="sd">    we wish to reset the states of the networks with indices 2 and 5),</span>
<a id="__codelineno-0-1135" name="__codelineno-0-1135"></a><span class="sd">    then, we can do:</span>
<a id="__codelineno-0-1136" name="__codelineno-0-1136"></a>
<a id="__codelineno-0-1137" name="__codelineno-0-1137"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-1138" name="__codelineno-0-1138"></a><span class="sd">    policy.reset(torch.tensor([2, 5]))</span>
<a id="__codelineno-0-1139" name="__codelineno-0-1139"></a><span class="sd">    ```</span>
<a id="__codelineno-0-1140" name="__codelineno-0-1140"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1141" name="__codelineno-0-1141"></a>
<a id="__codelineno-0-1142" name="__codelineno-0-1142"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<a id="__codelineno-0-1143" name="__codelineno-0-1143"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-1144" name="__codelineno-0-1144"></a><span class="sd">        `__init__(...)`: Initialize the Policy.</span>
<a id="__codelineno-0-1145" name="__codelineno-0-1145"></a>
<a id="__codelineno-0-1146" name="__codelineno-0-1146"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-1147" name="__codelineno-0-1147"></a><span class="sd">            net: The network to be wrapped by the Policy object.</span>
<a id="__codelineno-0-1148" name="__codelineno-0-1148"></a><span class="sd">                This can be a string, a Callable (e.g. a `torch.nn.Module`</span>
<a id="__codelineno-0-1149" name="__codelineno-0-1149"></a><span class="sd">                subclass), or a `torch.nn.Module` instance.</span>
<a id="__codelineno-0-1150" name="__codelineno-0-1150"></a><span class="sd">                When this argument is a string, the network will be</span>
<a id="__codelineno-0-1151" name="__codelineno-0-1151"></a><span class="sd">                created with the help of the function</span>
<a id="__codelineno-0-1152" name="__codelineno-0-1152"></a><span class="sd">                `evotorch.neuroevolution.net.str_to_net(...)` and then</span>
<a id="__codelineno-0-1153" name="__codelineno-0-1153"></a><span class="sd">                wrapped. Please see the `str_to_net(...)` function&#39;s</span>
<a id="__codelineno-0-1154" name="__codelineno-0-1154"></a><span class="sd">                documentation for details regarding how a network structure</span>
<a id="__codelineno-0-1155" name="__codelineno-0-1155"></a><span class="sd">                can be expressed via strings.</span>
<a id="__codelineno-0-1156" name="__codelineno-0-1156"></a><span class="sd">            kwargs: Expected in the form of additional keyword arguments,</span>
<a id="__codelineno-0-1157" name="__codelineno-0-1157"></a><span class="sd">                these keyword arguments will be passed to the provided</span>
<a id="__codelineno-0-1158" name="__codelineno-0-1158"></a><span class="sd">                Callable object (if the argument `net` is a Callable)</span>
<a id="__codelineno-0-1159" name="__codelineno-0-1159"></a><span class="sd">                or to `str_to_net(...)` (if the argument `net` is a string)</span>
<a id="__codelineno-0-1160" name="__codelineno-0-1160"></a><span class="sd">                at the moment of generating the network.</span>
<a id="__codelineno-0-1161" name="__codelineno-0-1161"></a><span class="sd">                If the argument `net` is a `torch.nn.Module` instance,</span>
<a id="__codelineno-0-1162" name="__codelineno-0-1162"></a><span class="sd">                having any additional keyword arguments will trigger an</span>
<a id="__codelineno-0-1163" name="__codelineno-0-1163"></a><span class="sd">                error, because the network is already instantiated and</span>
<a id="__codelineno-0-1164" name="__codelineno-0-1164"></a><span class="sd">                therefore, it is not possible to pass these keyword arguments.</span>
<a id="__codelineno-0-1165" name="__codelineno-0-1165"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-1166" name="__codelineno-0-1166"></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">..net</span><span class="w"> </span><span class="kn">import</span> <span class="n">str_to_net</span>
<a id="__codelineno-0-1167" name="__codelineno-0-1167"></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">..net.functional</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModuleExpectingFlatParameters</span><span class="p">,</span> <span class="n">make_functional_module</span>
<a id="__codelineno-0-1168" name="__codelineno-0-1168"></a>
<a id="__codelineno-0-1169" name="__codelineno-0-1169"></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
<a id="__codelineno-0-1170" name="__codelineno-0-1170"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">__module</span> <span class="o">=</span> <span class="n">str_to_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<a id="__codelineno-0-1171" name="__codelineno-0-1171"></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-1172" name="__codelineno-0-1172"></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-1173" name="__codelineno-0-1173"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-1174" name="__codelineno-0-1174"></a>                    <span class="sa">f</span><span class="s2">&quot;When the network is given as an `nn.Module` instance, extra network arguments cannot be used&quot;</span>
<a id="__codelineno-0-1175" name="__codelineno-0-1175"></a>                    <span class="sa">f</span><span class="s2">&quot; (because the network is already instantiated).&quot;</span>
<a id="__codelineno-0-1176" name="__codelineno-0-1176"></a>                    <span class="sa">f</span><span class="s2">&quot; However, these extra keyword arguments were received: </span><span class="si">{</span><span class="n">kwargs</span><span class="si">}</span><span class="s2">.&quot;</span>
<a id="__codelineno-0-1177" name="__codelineno-0-1177"></a>                <span class="p">)</span>
<a id="__codelineno-0-1178" name="__codelineno-0-1178"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">__module</span> <span class="o">=</span> <span class="n">net</span>
<a id="__codelineno-0-1179" name="__codelineno-0-1179"></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">Callable</span><span class="p">):</span>
<a id="__codelineno-0-1180" name="__codelineno-0-1180"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">__module</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<a id="__codelineno-0-1181" name="__codelineno-0-1181"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-1182" name="__codelineno-0-1182"></a>            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
<a id="__codelineno-0-1183" name="__codelineno-0-1183"></a>                <span class="sa">f</span><span class="s2">&quot;The class `Policy` expected a string or an `nn.Module` instance, or a Callable, but received </span><span class="si">{</span><span class="n">net</span><span class="si">}</span><span class="s2">&quot;</span>
<a id="__codelineno-0-1184" name="__codelineno-0-1184"></a>                <span class="sa">f</span><span class="s2">&quot; (whose type is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">net</span><span class="p">)</span><span class="si">}</span><span class="s2">).&quot;</span>
<a id="__codelineno-0-1185" name="__codelineno-0-1185"></a>            <span class="p">)</span>
<a id="__codelineno-0-1186" name="__codelineno-0-1186"></a>
<a id="__codelineno-0-1187" name="__codelineno-0-1187"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__fmodule</span><span class="p">:</span> <span class="n">ModuleExpectingFlatParameters</span> <span class="o">=</span> <span class="n">make_functional_module</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__module</span><span class="p">)</span>
<a id="__codelineno-0-1188" name="__codelineno-0-1188"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__state</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-1189" name="__codelineno-0-1189"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-1190" name="__codelineno-0-1190"></a>
<a id="__codelineno-0-1191" name="__codelineno-0-1191"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">set_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MaskOrIndices</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">reset</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
<a id="__codelineno-0-1192" name="__codelineno-0-1192"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-1193" name="__codelineno-0-1193"></a><span class="sd">        Set the parameters of the policy.</span>
<a id="__codelineno-0-1194" name="__codelineno-0-1194"></a>
<a id="__codelineno-0-1195" name="__codelineno-0-1195"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-1196" name="__codelineno-0-1196"></a><span class="sd">            parameters: A 1-dimensional or a 2-dimensional tensor containing</span>
<a id="__codelineno-0-1197" name="__codelineno-0-1197"></a><span class="sd">                the flattened parameters to be used with the neural network.</span>
<a id="__codelineno-0-1198" name="__codelineno-0-1198"></a><span class="sd">                If the given parameters are two-dimensional, then, given that</span>
<a id="__codelineno-0-1199" name="__codelineno-0-1199"></a><span class="sd">                the leftmost size of the parameter tensor is `n`, the</span>
<a id="__codelineno-0-1200" name="__codelineno-0-1200"></a><span class="sd">                observations will be expected in a batch with leftmost size</span>
<a id="__codelineno-0-1201" name="__codelineno-0-1201"></a><span class="sd">                `n`, and the returned actions will also be in a batch,</span>
<a id="__codelineno-0-1202" name="__codelineno-0-1202"></a><span class="sd">                again with the leftmost size `n`.</span>
<a id="__codelineno-0-1203" name="__codelineno-0-1203"></a><span class="sd">            indices: For when the parameters were previously given via a</span>
<a id="__codelineno-0-1204" name="__codelineno-0-1204"></a><span class="sd">                2-dimensional tensor, provide this argument if you would like</span>
<a id="__codelineno-0-1205" name="__codelineno-0-1205"></a><span class="sd">                to change only some rows of the previously given parameters.</span>
<a id="__codelineno-0-1206" name="__codelineno-0-1206"></a><span class="sd">                For example, if `indices` is given as `torch.tensor([2, 4])`</span>
<a id="__codelineno-0-1207" name="__codelineno-0-1207"></a><span class="sd">                and the argument `parameters` is given as a 2-dimensional</span>
<a id="__codelineno-0-1208" name="__codelineno-0-1208"></a><span class="sd">                tensor with leftmost size 2, then the rows with indices</span>
<a id="__codelineno-0-1209" name="__codelineno-0-1209"></a><span class="sd">                2 and 4 will be replaced by these new parameters provided</span>
<a id="__codelineno-0-1210" name="__codelineno-0-1210"></a><span class="sd">                via the argument `parameters`.</span>
<a id="__codelineno-0-1211" name="__codelineno-0-1211"></a><span class="sd">            reset: If given as True, the hidden states of the networks whose</span>
<a id="__codelineno-0-1212" name="__codelineno-0-1212"></a><span class="sd">                parameters just changed will be reset. If `indices` was not</span>
<a id="__codelineno-0-1213" name="__codelineno-0-1213"></a><span class="sd">                provided at all, then this means that the parameters of all</span>
<a id="__codelineno-0-1214" name="__codelineno-0-1214"></a><span class="sd">                networks are modified, in which case, all the hidden states</span>
<a id="__codelineno-0-1215" name="__codelineno-0-1215"></a><span class="sd">                will be reset.</span>
<a id="__codelineno-0-1216" name="__codelineno-0-1216"></a><span class="sd">                If given as False, no such resetting will be done.</span>
<a id="__codelineno-0-1217" name="__codelineno-0-1217"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-1218" name="__codelineno-0-1218"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__parameters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1219" name="__codelineno-0-1219"></a>            <span class="k">if</span> <span class="n">indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1220" name="__codelineno-0-1220"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-1221" name="__codelineno-0-1221"></a>                    <span class="s2">&quot;The argument `indices` can be used only if network parameters were previously specified.&quot;</span>
<a id="__codelineno-0-1222" name="__codelineno-0-1222"></a>                    <span class="s2">&quot; However, it seems that the method `set_parameters(...)` was not called before.&quot;</span>
<a id="__codelineno-0-1223" name="__codelineno-0-1223"></a>                <span class="p">)</span>
<a id="__codelineno-0-1224" name="__codelineno-0-1224"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">__parameters</span> <span class="o">=</span> <span class="n">parameters</span>
<a id="__codelineno-0-1225" name="__codelineno-0-1225"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-1226" name="__codelineno-0-1226"></a>            <span class="k">if</span> <span class="n">indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1227" name="__codelineno-0-1227"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">__parameters</span> <span class="o">=</span> <span class="n">parameters</span>
<a id="__codelineno-0-1228" name="__codelineno-0-1228"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-1229" name="__codelineno-0-1229"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">__parameters</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">parameters</span>
<a id="__codelineno-0-1230" name="__codelineno-0-1230"></a>
<a id="__codelineno-0-1231" name="__codelineno-0-1231"></a>        <span class="k">if</span> <span class="n">reset</span><span class="p">:</span>
<a id="__codelineno-0-1232" name="__codelineno-0-1232"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
<a id="__codelineno-0-1233" name="__codelineno-0-1233"></a>
<a id="__codelineno-0-1234" name="__codelineno-0-1234"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-1235" name="__codelineno-0-1235"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-1236" name="__codelineno-0-1236"></a><span class="sd">        Pass the given observations through the network.</span>
<a id="__codelineno-0-1237" name="__codelineno-0-1237"></a>
<a id="__codelineno-0-1238" name="__codelineno-0-1238"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-1239" name="__codelineno-0-1239"></a><span class="sd">            x: The observations, as a PyTorch tensor.</span>
<a id="__codelineno-0-1240" name="__codelineno-0-1240"></a><span class="sd">                If the parameters were given (via the method</span>
<a id="__codelineno-0-1241" name="__codelineno-0-1241"></a><span class="sd">                `set_parameters(...)`) as a 1-dimensional tensor, then this</span>
<a id="__codelineno-0-1242" name="__codelineno-0-1242"></a><span class="sd">                argument is expected to store a single observation.</span>
<a id="__codelineno-0-1243" name="__codelineno-0-1243"></a><span class="sd">                If the parameters were given as a 2-dimensional tensor,</span>
<a id="__codelineno-0-1244" name="__codelineno-0-1244"></a><span class="sd">                then, this argument is expected to store a batch of</span>
<a id="__codelineno-0-1245" name="__codelineno-0-1245"></a><span class="sd">                observations, and the leftmost size of this observation</span>
<a id="__codelineno-0-1246" name="__codelineno-0-1246"></a><span class="sd">                tensor must match with the leftmost size of the parameter</span>
<a id="__codelineno-0-1247" name="__codelineno-0-1247"></a><span class="sd">                tensor.</span>
<a id="__codelineno-0-1248" name="__codelineno-0-1248"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-1249" name="__codelineno-0-1249"></a><span class="sd">            The output tensor, which represents the action to take.</span>
<a id="__codelineno-0-1250" name="__codelineno-0-1250"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-1251" name="__codelineno-0-1251"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__parameters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1252" name="__codelineno-0-1252"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Please use the method `set_parameters(...)` before calling the policy.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1253" name="__codelineno-0-1253"></a>
<a id="__codelineno-0-1254" name="__codelineno-0-1254"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__state</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1255" name="__codelineno-0-1255"></a>            <span class="n">further_args</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span>
<a id="__codelineno-0-1256" name="__codelineno-0-1256"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-1257" name="__codelineno-0-1257"></a>            <span class="n">further_args</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__state</span><span class="p">)</span>
<a id="__codelineno-0-1258" name="__codelineno-0-1258"></a>
<a id="__codelineno-0-1259" name="__codelineno-0-1259"></a>        <span class="n">parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__parameters</span>
<a id="__codelineno-0-1260" name="__codelineno-0-1260"></a>        <span class="n">ndim</span> <span class="o">=</span> <span class="n">parameters</span><span class="o">.</span><span class="n">ndim</span>
<a id="__codelineno-0-1261" name="__codelineno-0-1261"></a>        <span class="k">if</span> <span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
<a id="__codelineno-0-1262" name="__codelineno-0-1262"></a>            <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__fmodule</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="o">*</span><span class="n">further_args</span><span class="p">)</span>
<a id="__codelineno-0-1263" name="__codelineno-0-1263"></a>        <span class="k">elif</span> <span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
<a id="__codelineno-0-1264" name="__codelineno-0-1264"></a>            <span class="n">vmapped</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__fmodule</span><span class="p">)</span>
<a id="__codelineno-0-1265" name="__codelineno-0-1265"></a>            <span class="n">result</span> <span class="o">=</span> <span class="n">vmapped</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="o">*</span><span class="n">further_args</span><span class="p">)</span>
<a id="__codelineno-0-1266" name="__codelineno-0-1266"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-1267" name="__codelineno-0-1267"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-1268" name="__codelineno-0-1268"></a>                <span class="sa">f</span><span class="s2">&quot;Expected the parameters as a 1 or 2 dimensional tensor.&quot;</span>
<a id="__codelineno-0-1269" name="__codelineno-0-1269"></a>                <span class="sa">f</span><span class="s2">&quot; However, the received parameters tensor has </span><span class="si">{</span><span class="n">ndim</span><span class="si">}</span><span class="s2"> dimensions.&quot;</span>
<a id="__codelineno-0-1270" name="__codelineno-0-1270"></a>            <span class="p">)</span>
<a id="__codelineno-0-1271" name="__codelineno-0-1271"></a>
<a id="__codelineno-0-1272" name="__codelineno-0-1272"></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<a id="__codelineno-0-1273" name="__codelineno-0-1273"></a>            <span class="k">return</span> <span class="n">result</span>
<a id="__codelineno-0-1274" name="__codelineno-0-1274"></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
<a id="__codelineno-0-1275" name="__codelineno-0-1275"></a>            <span class="n">result</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">result</span>
<a id="__codelineno-0-1276" name="__codelineno-0-1276"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">__state</span> <span class="o">=</span> <span class="n">state</span>
<a id="__codelineno-0-1277" name="__codelineno-0-1277"></a>            <span class="k">return</span> <span class="n">result</span>
<a id="__codelineno-0-1278" name="__codelineno-0-1278"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-1279" name="__codelineno-0-1279"></a>            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The torch module used by the Policy returned an unexpected object: </span><span class="si">{</span><span class="n">result</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1280" name="__codelineno-0-1280"></a>
<a id="__codelineno-0-1281" name="__codelineno-0-1281"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MaskOrIndices</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">copy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
<a id="__codelineno-0-1282" name="__codelineno-0-1282"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-1283" name="__codelineno-0-1283"></a><span class="sd">        Reset the hidden states, if the contained module is a recurrent network.</span>
<a id="__codelineno-0-1284" name="__codelineno-0-1284"></a>
<a id="__codelineno-0-1285" name="__codelineno-0-1285"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-1286" name="__codelineno-0-1286"></a><span class="sd">            indices: Optionally a sequence of integers or a sequence of</span>
<a id="__codelineno-0-1287" name="__codelineno-0-1287"></a><span class="sd">                booleans, specifying which networks&#39; states will be</span>
<a id="__codelineno-0-1288" name="__codelineno-0-1288"></a><span class="sd">                reset. If left as None, then the states of all the networks</span>
<a id="__codelineno-0-1289" name="__codelineno-0-1289"></a><span class="sd">                will be reset.</span>
<a id="__codelineno-0-1290" name="__codelineno-0-1290"></a><span class="sd">            copy: When `indices` is given as something other than None,</span>
<a id="__codelineno-0-1291" name="__codelineno-0-1291"></a><span class="sd">                if `copy` is given as True, then the resetting will NOT</span>
<a id="__codelineno-0-1292" name="__codelineno-0-1292"></a><span class="sd">                be done in-place. Instead, a new copy of the hidden state</span>
<a id="__codelineno-0-1293" name="__codelineno-0-1293"></a><span class="sd">                will first be created, and then the specified regions</span>
<a id="__codelineno-0-1294" name="__codelineno-0-1294"></a><span class="sd">                of this new copy will be cleared, and then finally this</span>
<a id="__codelineno-0-1295" name="__codelineno-0-1295"></a><span class="sd">                modified copy will be declared as the new hidden state.</span>
<a id="__codelineno-0-1296" name="__codelineno-0-1296"></a><span class="sd">                It is a common practice for recurrent neural network</span>
<a id="__codelineno-0-1297" name="__codelineno-0-1297"></a><span class="sd">                implementations to return the same tensor both as its</span>
<a id="__codelineno-0-1298" name="__codelineno-0-1298"></a><span class="sd">                output and as (part of) its hidden state. With `copy=False`,</span>
<a id="__codelineno-0-1299" name="__codelineno-0-1299"></a><span class="sd">                the resetting would be done in-place, and the action</span>
<a id="__codelineno-0-1300" name="__codelineno-0-1300"></a><span class="sd">                tensor could be involuntarily reset as well.</span>
<a id="__codelineno-0-1301" name="__codelineno-0-1301"></a><span class="sd">                This in-place modification could cause silent bugs</span>
<a id="__codelineno-0-1302" name="__codelineno-0-1302"></a><span class="sd">                if the unintended modification on the action tensor</span>
<a id="__codelineno-0-1303" name="__codelineno-0-1303"></a><span class="sd">                happens BEFORE the action is sent to the reinforcement</span>
<a id="__codelineno-0-1304" name="__codelineno-0-1304"></a><span class="sd">                learning environment.</span>
<a id="__codelineno-0-1305" name="__codelineno-0-1305"></a><span class="sd">                To prevent such situations, the default value for the argument</span>
<a id="__codelineno-0-1306" name="__codelineno-0-1306"></a><span class="sd">                `copy` is True.</span>
<a id="__codelineno-0-1307" name="__codelineno-0-1307"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-1308" name="__codelineno-0-1308"></a>        <span class="k">if</span> <span class="n">indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1309" name="__codelineno-0-1309"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">__state</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-1310" name="__codelineno-0-1310"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-1311" name="__codelineno-0-1311"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1312" name="__codelineno-0-1312"></a>                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<a id="__codelineno-0-1313" name="__codelineno-0-1313"></a>                    <span class="k">if</span> <span class="n">copy</span><span class="p">:</span>
<a id="__codelineno-0-1314" name="__codelineno-0-1314"></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__state</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__state</span><span class="p">)</span>
<a id="__codelineno-0-1315" name="__codelineno-0-1315"></a>                    <span class="n">reset_tensors</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__state</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>
<a id="__codelineno-0-1316" name="__codelineno-0-1316"></a>
<a id="__codelineno-0-1317" name="__codelineno-0-1317"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-1318" name="__codelineno-0-1318"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-1319" name="__codelineno-0-1319"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-1320" name="__codelineno-0-1320"></a><span class="sd">        The currently used parameters.</span>
<a id="__codelineno-0-1321" name="__codelineno-0-1321"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-1322" name="__codelineno-0-1322"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__parameters</span>
<a id="__codelineno-0-1323" name="__codelineno-0-1323"></a>
<a id="__codelineno-0-1324" name="__codelineno-0-1324"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-1325" name="__codelineno-0-1325"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">h</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-1326" name="__codelineno-0-1326"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-1327" name="__codelineno-0-1327"></a><span class="sd">        The hidden state of the contained recurrent network, if any.</span>
<a id="__codelineno-0-1328" name="__codelineno-0-1328"></a>
<a id="__codelineno-0-1329" name="__codelineno-0-1329"></a><span class="sd">        If the contained recurrent network did not generate a hidden state</span>
<a id="__codelineno-0-1330" name="__codelineno-0-1330"></a><span class="sd">        yet, or if the contained network is not recurrent, then the result</span>
<a id="__codelineno-0-1331" name="__codelineno-0-1331"></a><span class="sd">        will be None.</span>
<a id="__codelineno-0-1332" name="__codelineno-0-1332"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-1333" name="__codelineno-0-1333"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__state</span>
<a id="__codelineno-0-1334" name="__codelineno-0-1334"></a>
<a id="__codelineno-0-1335" name="__codelineno-0-1335"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-1336" name="__codelineno-0-1336"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">parameter_length</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-1337" name="__codelineno-0-1337"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-1338" name="__codelineno-0-1338"></a><span class="sd">        Length of the parameter tensor.</span>
<a id="__codelineno-0-1339" name="__codelineno-0-1339"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-1340" name="__codelineno-0-1340"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__fmodule</span><span class="o">.</span><span class="n">parameter_length</span>
<a id="__codelineno-0-1341" name="__codelineno-0-1341"></a>
<a id="__codelineno-0-1342" name="__codelineno-0-1342"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-1343" name="__codelineno-0-1343"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">wrapped_module</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
<a id="__codelineno-0-1344" name="__codelineno-0-1344"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-1345" name="__codelineno-0-1345"></a><span class="sd">        The wrapped `torch.nn.Module` instance.</span>
<a id="__codelineno-0-1346" name="__codelineno-0-1346"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-1347" name="__codelineno-0-1347"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__module</span>
<a id="__codelineno-0-1348" name="__codelineno-0-1348"></a>
<a id="__codelineno-0-1349" name="__codelineno-0-1349"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">to_torch_module</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameter_vector</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
<a id="__codelineno-0-1350" name="__codelineno-0-1350"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-1351" name="__codelineno-0-1351"></a><span class="sd">        Get a copy of the contained network, parameterized as specified.</span>
<a id="__codelineno-0-1352" name="__codelineno-0-1352"></a>
<a id="__codelineno-0-1353" name="__codelineno-0-1353"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-1354" name="__codelineno-0-1354"></a><span class="sd">            parameter_vector: The parameters to be used by the new network.</span>
<a id="__codelineno-0-1355" name="__codelineno-0-1355"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-1356" name="__codelineno-0-1356"></a><span class="sd">            Copy of the contained network, as a `torch.nn.Module` instance.</span>
<a id="__codelineno-0-1357" name="__codelineno-0-1357"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-1358" name="__codelineno-0-1358"></a>        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<a id="__codelineno-0-1359" name="__codelineno-0-1359"></a>            <span class="n">net</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__module</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">parameter_vector</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-1360" name="__codelineno-0-1360"></a>            <span class="n">nnu</span><span class="o">.</span><span class="n">vector_to_parameters</span><span class="p">(</span><span class="n">parameter_vector</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<a id="__codelineno-0-1361" name="__codelineno-0-1361"></a>        <span class="k">return</span> <span class="n">net</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="evotorch.neuroevolution.net.Policy.h" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">h</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#evotorch.neuroevolution.net.Policy.h" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>The hidden state of the contained recurrent network, if any.</p>
<p>If the contained recurrent network did not generate a hidden state
yet, or if the contained network is not recurrent, then the result
will be None.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="evotorch.neuroevolution.net.Policy.parameter_length" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">parameter_length</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#evotorch.neuroevolution.net.Policy.parameter_length" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Length of the parameter tensor.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="evotorch.neuroevolution.net.Policy.parameters" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">parameters</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#evotorch.neuroevolution.net.Policy.parameters" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>The currently used parameters.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="evotorch.neuroevolution.net.Policy.wrapped_module" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">wrapped_module</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#evotorch.neuroevolution.net.Policy.wrapped_module" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>The wrapped <code>torch.nn.Module</code> instance.</p>

    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="evotorch.neuroevolution.net.Policy.__call__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__call__</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

<a href="#evotorch.neuroevolution.net.Policy.__call__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Pass the given observations through the network.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The observations, as a PyTorch tensor.
If the parameters were given (via the method
<code>set_parameters(...)</code>) as a 1-dimensional tensor, then this
argument is expected to store a single observation.
If the parameters were given as a 2-dimensional tensor,
then, this argument is expected to store a batch of
observations, and the leftmost size of this observation
tensor must match with the leftmost size of the parameter
tensor.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>
        


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/vecrl.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1234">1234</a></span>
<span class="normal"><a href="#__codelineno-0-1235">1235</a></span>
<span class="normal"><a href="#__codelineno-0-1236">1236</a></span>
<span class="normal"><a href="#__codelineno-0-1237">1237</a></span>
<span class="normal"><a href="#__codelineno-0-1238">1238</a></span>
<span class="normal"><a href="#__codelineno-0-1239">1239</a></span>
<span class="normal"><a href="#__codelineno-0-1240">1240</a></span>
<span class="normal"><a href="#__codelineno-0-1241">1241</a></span>
<span class="normal"><a href="#__codelineno-0-1242">1242</a></span>
<span class="normal"><a href="#__codelineno-0-1243">1243</a></span>
<span class="normal"><a href="#__codelineno-0-1244">1244</a></span>
<span class="normal"><a href="#__codelineno-0-1245">1245</a></span>
<span class="normal"><a href="#__codelineno-0-1246">1246</a></span>
<span class="normal"><a href="#__codelineno-0-1247">1247</a></span>
<span class="normal"><a href="#__codelineno-0-1248">1248</a></span>
<span class="normal"><a href="#__codelineno-0-1249">1249</a></span>
<span class="normal"><a href="#__codelineno-0-1250">1250</a></span>
<span class="normal"><a href="#__codelineno-0-1251">1251</a></span>
<span class="normal"><a href="#__codelineno-0-1252">1252</a></span>
<span class="normal"><a href="#__codelineno-0-1253">1253</a></span>
<span class="normal"><a href="#__codelineno-0-1254">1254</a></span>
<span class="normal"><a href="#__codelineno-0-1255">1255</a></span>
<span class="normal"><a href="#__codelineno-0-1256">1256</a></span>
<span class="normal"><a href="#__codelineno-0-1257">1257</a></span>
<span class="normal"><a href="#__codelineno-0-1258">1258</a></span>
<span class="normal"><a href="#__codelineno-0-1259">1259</a></span>
<span class="normal"><a href="#__codelineno-0-1260">1260</a></span>
<span class="normal"><a href="#__codelineno-0-1261">1261</a></span>
<span class="normal"><a href="#__codelineno-0-1262">1262</a></span>
<span class="normal"><a href="#__codelineno-0-1263">1263</a></span>
<span class="normal"><a href="#__codelineno-0-1264">1264</a></span>
<span class="normal"><a href="#__codelineno-0-1265">1265</a></span>
<span class="normal"><a href="#__codelineno-0-1266">1266</a></span>
<span class="normal"><a href="#__codelineno-0-1267">1267</a></span>
<span class="normal"><a href="#__codelineno-0-1268">1268</a></span>
<span class="normal"><a href="#__codelineno-0-1269">1269</a></span>
<span class="normal"><a href="#__codelineno-0-1270">1270</a></span>
<span class="normal"><a href="#__codelineno-0-1271">1271</a></span>
<span class="normal"><a href="#__codelineno-0-1272">1272</a></span>
<span class="normal"><a href="#__codelineno-0-1273">1273</a></span>
<span class="normal"><a href="#__codelineno-0-1274">1274</a></span>
<span class="normal"><a href="#__codelineno-0-1275">1275</a></span>
<span class="normal"><a href="#__codelineno-0-1276">1276</a></span>
<span class="normal"><a href="#__codelineno-0-1277">1277</a></span>
<span class="normal"><a href="#__codelineno-0-1278">1278</a></span>
<span class="normal"><a href="#__codelineno-0-1279">1279</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1234" name="__codelineno-0-1234"></a><span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-1235" name="__codelineno-0-1235"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-1236" name="__codelineno-0-1236"></a><span class="sd">    Pass the given observations through the network.</span>
<a id="__codelineno-0-1237" name="__codelineno-0-1237"></a>
<a id="__codelineno-0-1238" name="__codelineno-0-1238"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-1239" name="__codelineno-0-1239"></a><span class="sd">        x: The observations, as a PyTorch tensor.</span>
<a id="__codelineno-0-1240" name="__codelineno-0-1240"></a><span class="sd">            If the parameters were given (via the method</span>
<a id="__codelineno-0-1241" name="__codelineno-0-1241"></a><span class="sd">            `set_parameters(...)`) as a 1-dimensional tensor, then this</span>
<a id="__codelineno-0-1242" name="__codelineno-0-1242"></a><span class="sd">            argument is expected to store a single observation.</span>
<a id="__codelineno-0-1243" name="__codelineno-0-1243"></a><span class="sd">            If the parameters were given as a 2-dimensional tensor,</span>
<a id="__codelineno-0-1244" name="__codelineno-0-1244"></a><span class="sd">            then, this argument is expected to store a batch of</span>
<a id="__codelineno-0-1245" name="__codelineno-0-1245"></a><span class="sd">            observations, and the leftmost size of this observation</span>
<a id="__codelineno-0-1246" name="__codelineno-0-1246"></a><span class="sd">            tensor must match with the leftmost size of the parameter</span>
<a id="__codelineno-0-1247" name="__codelineno-0-1247"></a><span class="sd">            tensor.</span>
<a id="__codelineno-0-1248" name="__codelineno-0-1248"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-1249" name="__codelineno-0-1249"></a><span class="sd">        The output tensor, which represents the action to take.</span>
<a id="__codelineno-0-1250" name="__codelineno-0-1250"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1251" name="__codelineno-0-1251"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__parameters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1252" name="__codelineno-0-1252"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Please use the method `set_parameters(...)` before calling the policy.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1253" name="__codelineno-0-1253"></a>
<a id="__codelineno-0-1254" name="__codelineno-0-1254"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__state</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1255" name="__codelineno-0-1255"></a>        <span class="n">further_args</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span>
<a id="__codelineno-0-1256" name="__codelineno-0-1256"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-1257" name="__codelineno-0-1257"></a>        <span class="n">further_args</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__state</span><span class="p">)</span>
<a id="__codelineno-0-1258" name="__codelineno-0-1258"></a>
<a id="__codelineno-0-1259" name="__codelineno-0-1259"></a>    <span class="n">parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__parameters</span>
<a id="__codelineno-0-1260" name="__codelineno-0-1260"></a>    <span class="n">ndim</span> <span class="o">=</span> <span class="n">parameters</span><span class="o">.</span><span class="n">ndim</span>
<a id="__codelineno-0-1261" name="__codelineno-0-1261"></a>    <span class="k">if</span> <span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
<a id="__codelineno-0-1262" name="__codelineno-0-1262"></a>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__fmodule</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="o">*</span><span class="n">further_args</span><span class="p">)</span>
<a id="__codelineno-0-1263" name="__codelineno-0-1263"></a>    <span class="k">elif</span> <span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
<a id="__codelineno-0-1264" name="__codelineno-0-1264"></a>        <span class="n">vmapped</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__fmodule</span><span class="p">)</span>
<a id="__codelineno-0-1265" name="__codelineno-0-1265"></a>        <span class="n">result</span> <span class="o">=</span> <span class="n">vmapped</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="o">*</span><span class="n">further_args</span><span class="p">)</span>
<a id="__codelineno-0-1266" name="__codelineno-0-1266"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-1267" name="__codelineno-0-1267"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-1268" name="__codelineno-0-1268"></a>            <span class="sa">f</span><span class="s2">&quot;Expected the parameters as a 1 or 2 dimensional tensor.&quot;</span>
<a id="__codelineno-0-1269" name="__codelineno-0-1269"></a>            <span class="sa">f</span><span class="s2">&quot; However, the received parameters tensor has </span><span class="si">{</span><span class="n">ndim</span><span class="si">}</span><span class="s2"> dimensions.&quot;</span>
<a id="__codelineno-0-1270" name="__codelineno-0-1270"></a>        <span class="p">)</span>
<a id="__codelineno-0-1271" name="__codelineno-0-1271"></a>
<a id="__codelineno-0-1272" name="__codelineno-0-1272"></a>    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<a id="__codelineno-0-1273" name="__codelineno-0-1273"></a>        <span class="k">return</span> <span class="n">result</span>
<a id="__codelineno-0-1274" name="__codelineno-0-1274"></a>    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
<a id="__codelineno-0-1275" name="__codelineno-0-1275"></a>        <span class="n">result</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">result</span>
<a id="__codelineno-0-1276" name="__codelineno-0-1276"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__state</span> <span class="o">=</span> <span class="n">state</span>
<a id="__codelineno-0-1277" name="__codelineno-0-1277"></a>        <span class="k">return</span> <span class="n">result</span>
<a id="__codelineno-0-1278" name="__codelineno-0-1278"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-1279" name="__codelineno-0-1279"></a>        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The torch module used by the Policy returned an unexpected object: </span><span class="si">{</span><span class="n">result</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="evotorch.neuroevolution.net.Policy.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#evotorch.neuroevolution.net.Policy.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p><code>__init__(...)</code>: Initialize the Policy.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>net</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="typing.Callable">Callable</span>, <span title="torch.nn.Module">Module</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The network to be wrapped by the Policy object.
This can be a string, a Callable (e.g. a <code>torch.nn.Module</code>
subclass), or a <code>torch.nn.Module</code> instance.
When this argument is a string, the network will be
created with the help of the function
<code>evotorch.neuroevolution.net.str_to_net(...)</code> and then
wrapped. Please see the <code>str_to_net(...)</code> function's
documentation for details regarding how a network structure
can be expressed via strings.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>kwargs</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Expected in the form of additional keyword arguments,
these keyword arguments will be passed to the provided
Callable object (if the argument <code>net</code> is a Callable)
or to <code>str_to_net(...)</code> (if the argument <code>net</code> is a string)
at the moment of generating the network.
If the argument <code>net</code> is a <code>torch.nn.Module</code> instance,
having any additional keyword arguments will trigger an
error, because the network is already instantiated and
therefore, it is not possible to pass these keyword arguments.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/vecrl.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1142">1142</a></span>
<span class="normal"><a href="#__codelineno-0-1143">1143</a></span>
<span class="normal"><a href="#__codelineno-0-1144">1144</a></span>
<span class="normal"><a href="#__codelineno-0-1145">1145</a></span>
<span class="normal"><a href="#__codelineno-0-1146">1146</a></span>
<span class="normal"><a href="#__codelineno-0-1147">1147</a></span>
<span class="normal"><a href="#__codelineno-0-1148">1148</a></span>
<span class="normal"><a href="#__codelineno-0-1149">1149</a></span>
<span class="normal"><a href="#__codelineno-0-1150">1150</a></span>
<span class="normal"><a href="#__codelineno-0-1151">1151</a></span>
<span class="normal"><a href="#__codelineno-0-1152">1152</a></span>
<span class="normal"><a href="#__codelineno-0-1153">1153</a></span>
<span class="normal"><a href="#__codelineno-0-1154">1154</a></span>
<span class="normal"><a href="#__codelineno-0-1155">1155</a></span>
<span class="normal"><a href="#__codelineno-0-1156">1156</a></span>
<span class="normal"><a href="#__codelineno-0-1157">1157</a></span>
<span class="normal"><a href="#__codelineno-0-1158">1158</a></span>
<span class="normal"><a href="#__codelineno-0-1159">1159</a></span>
<span class="normal"><a href="#__codelineno-0-1160">1160</a></span>
<span class="normal"><a href="#__codelineno-0-1161">1161</a></span>
<span class="normal"><a href="#__codelineno-0-1162">1162</a></span>
<span class="normal"><a href="#__codelineno-0-1163">1163</a></span>
<span class="normal"><a href="#__codelineno-0-1164">1164</a></span>
<span class="normal"><a href="#__codelineno-0-1165">1165</a></span>
<span class="normal"><a href="#__codelineno-0-1166">1166</a></span>
<span class="normal"><a href="#__codelineno-0-1167">1167</a></span>
<span class="normal"><a href="#__codelineno-0-1168">1168</a></span>
<span class="normal"><a href="#__codelineno-0-1169">1169</a></span>
<span class="normal"><a href="#__codelineno-0-1170">1170</a></span>
<span class="normal"><a href="#__codelineno-0-1171">1171</a></span>
<span class="normal"><a href="#__codelineno-0-1172">1172</a></span>
<span class="normal"><a href="#__codelineno-0-1173">1173</a></span>
<span class="normal"><a href="#__codelineno-0-1174">1174</a></span>
<span class="normal"><a href="#__codelineno-0-1175">1175</a></span>
<span class="normal"><a href="#__codelineno-0-1176">1176</a></span>
<span class="normal"><a href="#__codelineno-0-1177">1177</a></span>
<span class="normal"><a href="#__codelineno-0-1178">1178</a></span>
<span class="normal"><a href="#__codelineno-0-1179">1179</a></span>
<span class="normal"><a href="#__codelineno-0-1180">1180</a></span>
<span class="normal"><a href="#__codelineno-0-1181">1181</a></span>
<span class="normal"><a href="#__codelineno-0-1182">1182</a></span>
<span class="normal"><a href="#__codelineno-0-1183">1183</a></span>
<span class="normal"><a href="#__codelineno-0-1184">1184</a></span>
<span class="normal"><a href="#__codelineno-0-1185">1185</a></span>
<span class="normal"><a href="#__codelineno-0-1186">1186</a></span>
<span class="normal"><a href="#__codelineno-0-1187">1187</a></span>
<span class="normal"><a href="#__codelineno-0-1188">1188</a></span>
<span class="normal"><a href="#__codelineno-0-1189">1189</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1142" name="__codelineno-0-1142"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<a id="__codelineno-0-1143" name="__codelineno-0-1143"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-1144" name="__codelineno-0-1144"></a><span class="sd">    `__init__(...)`: Initialize the Policy.</span>
<a id="__codelineno-0-1145" name="__codelineno-0-1145"></a>
<a id="__codelineno-0-1146" name="__codelineno-0-1146"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-1147" name="__codelineno-0-1147"></a><span class="sd">        net: The network to be wrapped by the Policy object.</span>
<a id="__codelineno-0-1148" name="__codelineno-0-1148"></a><span class="sd">            This can be a string, a Callable (e.g. a `torch.nn.Module`</span>
<a id="__codelineno-0-1149" name="__codelineno-0-1149"></a><span class="sd">            subclass), or a `torch.nn.Module` instance.</span>
<a id="__codelineno-0-1150" name="__codelineno-0-1150"></a><span class="sd">            When this argument is a string, the network will be</span>
<a id="__codelineno-0-1151" name="__codelineno-0-1151"></a><span class="sd">            created with the help of the function</span>
<a id="__codelineno-0-1152" name="__codelineno-0-1152"></a><span class="sd">            `evotorch.neuroevolution.net.str_to_net(...)` and then</span>
<a id="__codelineno-0-1153" name="__codelineno-0-1153"></a><span class="sd">            wrapped. Please see the `str_to_net(...)` function&#39;s</span>
<a id="__codelineno-0-1154" name="__codelineno-0-1154"></a><span class="sd">            documentation for details regarding how a network structure</span>
<a id="__codelineno-0-1155" name="__codelineno-0-1155"></a><span class="sd">            can be expressed via strings.</span>
<a id="__codelineno-0-1156" name="__codelineno-0-1156"></a><span class="sd">        kwargs: Expected in the form of additional keyword arguments,</span>
<a id="__codelineno-0-1157" name="__codelineno-0-1157"></a><span class="sd">            these keyword arguments will be passed to the provided</span>
<a id="__codelineno-0-1158" name="__codelineno-0-1158"></a><span class="sd">            Callable object (if the argument `net` is a Callable)</span>
<a id="__codelineno-0-1159" name="__codelineno-0-1159"></a><span class="sd">            or to `str_to_net(...)` (if the argument `net` is a string)</span>
<a id="__codelineno-0-1160" name="__codelineno-0-1160"></a><span class="sd">            at the moment of generating the network.</span>
<a id="__codelineno-0-1161" name="__codelineno-0-1161"></a><span class="sd">            If the argument `net` is a `torch.nn.Module` instance,</span>
<a id="__codelineno-0-1162" name="__codelineno-0-1162"></a><span class="sd">            having any additional keyword arguments will trigger an</span>
<a id="__codelineno-0-1163" name="__codelineno-0-1163"></a><span class="sd">            error, because the network is already instantiated and</span>
<a id="__codelineno-0-1164" name="__codelineno-0-1164"></a><span class="sd">            therefore, it is not possible to pass these keyword arguments.</span>
<a id="__codelineno-0-1165" name="__codelineno-0-1165"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1166" name="__codelineno-0-1166"></a>    <span class="kn">from</span><span class="w"> </span><span class="nn">..net</span><span class="w"> </span><span class="kn">import</span> <span class="n">str_to_net</span>
<a id="__codelineno-0-1167" name="__codelineno-0-1167"></a>    <span class="kn">from</span><span class="w"> </span><span class="nn">..net.functional</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModuleExpectingFlatParameters</span><span class="p">,</span> <span class="n">make_functional_module</span>
<a id="__codelineno-0-1168" name="__codelineno-0-1168"></a>
<a id="__codelineno-0-1169" name="__codelineno-0-1169"></a>    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
<a id="__codelineno-0-1170" name="__codelineno-0-1170"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__module</span> <span class="o">=</span> <span class="n">str_to_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<a id="__codelineno-0-1171" name="__codelineno-0-1171"></a>    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-1172" name="__codelineno-0-1172"></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-1173" name="__codelineno-0-1173"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-1174" name="__codelineno-0-1174"></a>                <span class="sa">f</span><span class="s2">&quot;When the network is given as an `nn.Module` instance, extra network arguments cannot be used&quot;</span>
<a id="__codelineno-0-1175" name="__codelineno-0-1175"></a>                <span class="sa">f</span><span class="s2">&quot; (because the network is already instantiated).&quot;</span>
<a id="__codelineno-0-1176" name="__codelineno-0-1176"></a>                <span class="sa">f</span><span class="s2">&quot; However, these extra keyword arguments were received: </span><span class="si">{</span><span class="n">kwargs</span><span class="si">}</span><span class="s2">.&quot;</span>
<a id="__codelineno-0-1177" name="__codelineno-0-1177"></a>            <span class="p">)</span>
<a id="__codelineno-0-1178" name="__codelineno-0-1178"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__module</span> <span class="o">=</span> <span class="n">net</span>
<a id="__codelineno-0-1179" name="__codelineno-0-1179"></a>    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">Callable</span><span class="p">):</span>
<a id="__codelineno-0-1180" name="__codelineno-0-1180"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__module</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<a id="__codelineno-0-1181" name="__codelineno-0-1181"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-1182" name="__codelineno-0-1182"></a>        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
<a id="__codelineno-0-1183" name="__codelineno-0-1183"></a>            <span class="sa">f</span><span class="s2">&quot;The class `Policy` expected a string or an `nn.Module` instance, or a Callable, but received </span><span class="si">{</span><span class="n">net</span><span class="si">}</span><span class="s2">&quot;</span>
<a id="__codelineno-0-1184" name="__codelineno-0-1184"></a>            <span class="sa">f</span><span class="s2">&quot; (whose type is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">net</span><span class="p">)</span><span class="si">}</span><span class="s2">).&quot;</span>
<a id="__codelineno-0-1185" name="__codelineno-0-1185"></a>        <span class="p">)</span>
<a id="__codelineno-0-1186" name="__codelineno-0-1186"></a>
<a id="__codelineno-0-1187" name="__codelineno-0-1187"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">__fmodule</span><span class="p">:</span> <span class="n">ModuleExpectingFlatParameters</span> <span class="o">=</span> <span class="n">make_functional_module</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__module</span><span class="p">)</span>
<a id="__codelineno-0-1188" name="__codelineno-0-1188"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">__state</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-1189" name="__codelineno-0-1189"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">__parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="evotorch.neuroevolution.net.Policy.reset" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">reset</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

<a href="#evotorch.neuroevolution.net.Policy.reset" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Reset the hidden states, if the contained module is a recurrent network.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>indices</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="evotorch.neuroevolution.net.vecrl.MaskOrIndices">MaskOrIndices</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optionally a sequence of integers or a sequence of
booleans, specifying which networks' states will be
reset. If left as None, then the states of all the networks
will be reset.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>copy</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>When <code>indices</code> is given as something other than None,
if <code>copy</code> is given as True, then the resetting will NOT
be done in-place. Instead, a new copy of the hidden state
will first be created, and then the specified regions
of this new copy will be cleared, and then finally this
modified copy will be declared as the new hidden state.
It is a common practice for recurrent neural network
implementations to return the same tensor both as its
output and as (part of) its hidden state. With <code>copy=False</code>,
the resetting would be done in-place, and the action
tensor could be involuntarily reset as well.
This in-place modification could cause silent bugs
if the unintended modification on the action tensor
happens BEFORE the action is sent to the reinforcement
learning environment.
To prevent such situations, the default value for the argument
<code>copy</code> is True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/vecrl.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1281">1281</a></span>
<span class="normal"><a href="#__codelineno-0-1282">1282</a></span>
<span class="normal"><a href="#__codelineno-0-1283">1283</a></span>
<span class="normal"><a href="#__codelineno-0-1284">1284</a></span>
<span class="normal"><a href="#__codelineno-0-1285">1285</a></span>
<span class="normal"><a href="#__codelineno-0-1286">1286</a></span>
<span class="normal"><a href="#__codelineno-0-1287">1287</a></span>
<span class="normal"><a href="#__codelineno-0-1288">1288</a></span>
<span class="normal"><a href="#__codelineno-0-1289">1289</a></span>
<span class="normal"><a href="#__codelineno-0-1290">1290</a></span>
<span class="normal"><a href="#__codelineno-0-1291">1291</a></span>
<span class="normal"><a href="#__codelineno-0-1292">1292</a></span>
<span class="normal"><a href="#__codelineno-0-1293">1293</a></span>
<span class="normal"><a href="#__codelineno-0-1294">1294</a></span>
<span class="normal"><a href="#__codelineno-0-1295">1295</a></span>
<span class="normal"><a href="#__codelineno-0-1296">1296</a></span>
<span class="normal"><a href="#__codelineno-0-1297">1297</a></span>
<span class="normal"><a href="#__codelineno-0-1298">1298</a></span>
<span class="normal"><a href="#__codelineno-0-1299">1299</a></span>
<span class="normal"><a href="#__codelineno-0-1300">1300</a></span>
<span class="normal"><a href="#__codelineno-0-1301">1301</a></span>
<span class="normal"><a href="#__codelineno-0-1302">1302</a></span>
<span class="normal"><a href="#__codelineno-0-1303">1303</a></span>
<span class="normal"><a href="#__codelineno-0-1304">1304</a></span>
<span class="normal"><a href="#__codelineno-0-1305">1305</a></span>
<span class="normal"><a href="#__codelineno-0-1306">1306</a></span>
<span class="normal"><a href="#__codelineno-0-1307">1307</a></span>
<span class="normal"><a href="#__codelineno-0-1308">1308</a></span>
<span class="normal"><a href="#__codelineno-0-1309">1309</a></span>
<span class="normal"><a href="#__codelineno-0-1310">1310</a></span>
<span class="normal"><a href="#__codelineno-0-1311">1311</a></span>
<span class="normal"><a href="#__codelineno-0-1312">1312</a></span>
<span class="normal"><a href="#__codelineno-0-1313">1313</a></span>
<span class="normal"><a href="#__codelineno-0-1314">1314</a></span>
<span class="normal"><a href="#__codelineno-0-1315">1315</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1281" name="__codelineno-0-1281"></a><span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MaskOrIndices</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">copy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
<a id="__codelineno-0-1282" name="__codelineno-0-1282"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-1283" name="__codelineno-0-1283"></a><span class="sd">    Reset the hidden states, if the contained module is a recurrent network.</span>
<a id="__codelineno-0-1284" name="__codelineno-0-1284"></a>
<a id="__codelineno-0-1285" name="__codelineno-0-1285"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-1286" name="__codelineno-0-1286"></a><span class="sd">        indices: Optionally a sequence of integers or a sequence of</span>
<a id="__codelineno-0-1287" name="__codelineno-0-1287"></a><span class="sd">            booleans, specifying which networks&#39; states will be</span>
<a id="__codelineno-0-1288" name="__codelineno-0-1288"></a><span class="sd">            reset. If left as None, then the states of all the networks</span>
<a id="__codelineno-0-1289" name="__codelineno-0-1289"></a><span class="sd">            will be reset.</span>
<a id="__codelineno-0-1290" name="__codelineno-0-1290"></a><span class="sd">        copy: When `indices` is given as something other than None,</span>
<a id="__codelineno-0-1291" name="__codelineno-0-1291"></a><span class="sd">            if `copy` is given as True, then the resetting will NOT</span>
<a id="__codelineno-0-1292" name="__codelineno-0-1292"></a><span class="sd">            be done in-place. Instead, a new copy of the hidden state</span>
<a id="__codelineno-0-1293" name="__codelineno-0-1293"></a><span class="sd">            will first be created, and then the specified regions</span>
<a id="__codelineno-0-1294" name="__codelineno-0-1294"></a><span class="sd">            of this new copy will be cleared, and then finally this</span>
<a id="__codelineno-0-1295" name="__codelineno-0-1295"></a><span class="sd">            modified copy will be declared as the new hidden state.</span>
<a id="__codelineno-0-1296" name="__codelineno-0-1296"></a><span class="sd">            It is a common practice for recurrent neural network</span>
<a id="__codelineno-0-1297" name="__codelineno-0-1297"></a><span class="sd">            implementations to return the same tensor both as its</span>
<a id="__codelineno-0-1298" name="__codelineno-0-1298"></a><span class="sd">            output and as (part of) its hidden state. With `copy=False`,</span>
<a id="__codelineno-0-1299" name="__codelineno-0-1299"></a><span class="sd">            the resetting would be done in-place, and the action</span>
<a id="__codelineno-0-1300" name="__codelineno-0-1300"></a><span class="sd">            tensor could be involuntarily reset as well.</span>
<a id="__codelineno-0-1301" name="__codelineno-0-1301"></a><span class="sd">            This in-place modification could cause silent bugs</span>
<a id="__codelineno-0-1302" name="__codelineno-0-1302"></a><span class="sd">            if the unintended modification on the action tensor</span>
<a id="__codelineno-0-1303" name="__codelineno-0-1303"></a><span class="sd">            happens BEFORE the action is sent to the reinforcement</span>
<a id="__codelineno-0-1304" name="__codelineno-0-1304"></a><span class="sd">            learning environment.</span>
<a id="__codelineno-0-1305" name="__codelineno-0-1305"></a><span class="sd">            To prevent such situations, the default value for the argument</span>
<a id="__codelineno-0-1306" name="__codelineno-0-1306"></a><span class="sd">            `copy` is True.</span>
<a id="__codelineno-0-1307" name="__codelineno-0-1307"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1308" name="__codelineno-0-1308"></a>    <span class="k">if</span> <span class="n">indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1309" name="__codelineno-0-1309"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__state</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-1310" name="__codelineno-0-1310"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-1311" name="__codelineno-0-1311"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1312" name="__codelineno-0-1312"></a>            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<a id="__codelineno-0-1313" name="__codelineno-0-1313"></a>                <span class="k">if</span> <span class="n">copy</span><span class="p">:</span>
<a id="__codelineno-0-1314" name="__codelineno-0-1314"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">__state</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__state</span><span class="p">)</span>
<a id="__codelineno-0-1315" name="__codelineno-0-1315"></a>                <span class="n">reset_tensors</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__state</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="evotorch.neuroevolution.net.Policy.set_parameters" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">set_parameters</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">reset</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

<a href="#evotorch.neuroevolution.net.Policy.set_parameters" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Set the parameters of the policy.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>parameters</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A 1-dimensional or a 2-dimensional tensor containing
the flattened parameters to be used with the neural network.
If the given parameters are two-dimensional, then, given that
the leftmost size of the parameter tensor is <code>n</code>, the
observations will be expected in a batch with leftmost size
<code>n</code>, and the returned actions will also be in a batch,
again with the leftmost size <code>n</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>indices</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="evotorch.neuroevolution.net.vecrl.MaskOrIndices">MaskOrIndices</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>For when the parameters were previously given via a
2-dimensional tensor, provide this argument if you would like
to change only some rows of the previously given parameters.
For example, if <code>indices</code> is given as <code>torch.tensor([2, 4])</code>
and the argument <code>parameters</code> is given as a 2-dimensional
tensor with leftmost size 2, then the rows with indices
2 and 4 will be replaced by these new parameters provided
via the argument <code>parameters</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>reset</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If given as True, the hidden states of the networks whose
parameters just changed will be reset. If <code>indices</code> was not
provided at all, then this means that the parameters of all
networks are modified, in which case, all the hidden states
will be reset.
If given as False, no such resetting will be done.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/vecrl.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1191">1191</a></span>
<span class="normal"><a href="#__codelineno-0-1192">1192</a></span>
<span class="normal"><a href="#__codelineno-0-1193">1193</a></span>
<span class="normal"><a href="#__codelineno-0-1194">1194</a></span>
<span class="normal"><a href="#__codelineno-0-1195">1195</a></span>
<span class="normal"><a href="#__codelineno-0-1196">1196</a></span>
<span class="normal"><a href="#__codelineno-0-1197">1197</a></span>
<span class="normal"><a href="#__codelineno-0-1198">1198</a></span>
<span class="normal"><a href="#__codelineno-0-1199">1199</a></span>
<span class="normal"><a href="#__codelineno-0-1200">1200</a></span>
<span class="normal"><a href="#__codelineno-0-1201">1201</a></span>
<span class="normal"><a href="#__codelineno-0-1202">1202</a></span>
<span class="normal"><a href="#__codelineno-0-1203">1203</a></span>
<span class="normal"><a href="#__codelineno-0-1204">1204</a></span>
<span class="normal"><a href="#__codelineno-0-1205">1205</a></span>
<span class="normal"><a href="#__codelineno-0-1206">1206</a></span>
<span class="normal"><a href="#__codelineno-0-1207">1207</a></span>
<span class="normal"><a href="#__codelineno-0-1208">1208</a></span>
<span class="normal"><a href="#__codelineno-0-1209">1209</a></span>
<span class="normal"><a href="#__codelineno-0-1210">1210</a></span>
<span class="normal"><a href="#__codelineno-0-1211">1211</a></span>
<span class="normal"><a href="#__codelineno-0-1212">1212</a></span>
<span class="normal"><a href="#__codelineno-0-1213">1213</a></span>
<span class="normal"><a href="#__codelineno-0-1214">1214</a></span>
<span class="normal"><a href="#__codelineno-0-1215">1215</a></span>
<span class="normal"><a href="#__codelineno-0-1216">1216</a></span>
<span class="normal"><a href="#__codelineno-0-1217">1217</a></span>
<span class="normal"><a href="#__codelineno-0-1218">1218</a></span>
<span class="normal"><a href="#__codelineno-0-1219">1219</a></span>
<span class="normal"><a href="#__codelineno-0-1220">1220</a></span>
<span class="normal"><a href="#__codelineno-0-1221">1221</a></span>
<span class="normal"><a href="#__codelineno-0-1222">1222</a></span>
<span class="normal"><a href="#__codelineno-0-1223">1223</a></span>
<span class="normal"><a href="#__codelineno-0-1224">1224</a></span>
<span class="normal"><a href="#__codelineno-0-1225">1225</a></span>
<span class="normal"><a href="#__codelineno-0-1226">1226</a></span>
<span class="normal"><a href="#__codelineno-0-1227">1227</a></span>
<span class="normal"><a href="#__codelineno-0-1228">1228</a></span>
<span class="normal"><a href="#__codelineno-0-1229">1229</a></span>
<span class="normal"><a href="#__codelineno-0-1230">1230</a></span>
<span class="normal"><a href="#__codelineno-0-1231">1231</a></span>
<span class="normal"><a href="#__codelineno-0-1232">1232</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1191" name="__codelineno-0-1191"></a><span class="k">def</span><span class="w"> </span><span class="nf">set_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MaskOrIndices</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">reset</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
<a id="__codelineno-0-1192" name="__codelineno-0-1192"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-1193" name="__codelineno-0-1193"></a><span class="sd">    Set the parameters of the policy.</span>
<a id="__codelineno-0-1194" name="__codelineno-0-1194"></a>
<a id="__codelineno-0-1195" name="__codelineno-0-1195"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-1196" name="__codelineno-0-1196"></a><span class="sd">        parameters: A 1-dimensional or a 2-dimensional tensor containing</span>
<a id="__codelineno-0-1197" name="__codelineno-0-1197"></a><span class="sd">            the flattened parameters to be used with the neural network.</span>
<a id="__codelineno-0-1198" name="__codelineno-0-1198"></a><span class="sd">            If the given parameters are two-dimensional, then, given that</span>
<a id="__codelineno-0-1199" name="__codelineno-0-1199"></a><span class="sd">            the leftmost size of the parameter tensor is `n`, the</span>
<a id="__codelineno-0-1200" name="__codelineno-0-1200"></a><span class="sd">            observations will be expected in a batch with leftmost size</span>
<a id="__codelineno-0-1201" name="__codelineno-0-1201"></a><span class="sd">            `n`, and the returned actions will also be in a batch,</span>
<a id="__codelineno-0-1202" name="__codelineno-0-1202"></a><span class="sd">            again with the leftmost size `n`.</span>
<a id="__codelineno-0-1203" name="__codelineno-0-1203"></a><span class="sd">        indices: For when the parameters were previously given via a</span>
<a id="__codelineno-0-1204" name="__codelineno-0-1204"></a><span class="sd">            2-dimensional tensor, provide this argument if you would like</span>
<a id="__codelineno-0-1205" name="__codelineno-0-1205"></a><span class="sd">            to change only some rows of the previously given parameters.</span>
<a id="__codelineno-0-1206" name="__codelineno-0-1206"></a><span class="sd">            For example, if `indices` is given as `torch.tensor([2, 4])`</span>
<a id="__codelineno-0-1207" name="__codelineno-0-1207"></a><span class="sd">            and the argument `parameters` is given as a 2-dimensional</span>
<a id="__codelineno-0-1208" name="__codelineno-0-1208"></a><span class="sd">            tensor with leftmost size 2, then the rows with indices</span>
<a id="__codelineno-0-1209" name="__codelineno-0-1209"></a><span class="sd">            2 and 4 will be replaced by these new parameters provided</span>
<a id="__codelineno-0-1210" name="__codelineno-0-1210"></a><span class="sd">            via the argument `parameters`.</span>
<a id="__codelineno-0-1211" name="__codelineno-0-1211"></a><span class="sd">        reset: If given as True, the hidden states of the networks whose</span>
<a id="__codelineno-0-1212" name="__codelineno-0-1212"></a><span class="sd">            parameters just changed will be reset. If `indices` was not</span>
<a id="__codelineno-0-1213" name="__codelineno-0-1213"></a><span class="sd">            provided at all, then this means that the parameters of all</span>
<a id="__codelineno-0-1214" name="__codelineno-0-1214"></a><span class="sd">            networks are modified, in which case, all the hidden states</span>
<a id="__codelineno-0-1215" name="__codelineno-0-1215"></a><span class="sd">            will be reset.</span>
<a id="__codelineno-0-1216" name="__codelineno-0-1216"></a><span class="sd">            If given as False, no such resetting will be done.</span>
<a id="__codelineno-0-1217" name="__codelineno-0-1217"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1218" name="__codelineno-0-1218"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__parameters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1219" name="__codelineno-0-1219"></a>        <span class="k">if</span> <span class="n">indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1220" name="__codelineno-0-1220"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-1221" name="__codelineno-0-1221"></a>                <span class="s2">&quot;The argument `indices` can be used only if network parameters were previously specified.&quot;</span>
<a id="__codelineno-0-1222" name="__codelineno-0-1222"></a>                <span class="s2">&quot; However, it seems that the method `set_parameters(...)` was not called before.&quot;</span>
<a id="__codelineno-0-1223" name="__codelineno-0-1223"></a>            <span class="p">)</span>
<a id="__codelineno-0-1224" name="__codelineno-0-1224"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">__parameters</span> <span class="o">=</span> <span class="n">parameters</span>
<a id="__codelineno-0-1225" name="__codelineno-0-1225"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-1226" name="__codelineno-0-1226"></a>        <span class="k">if</span> <span class="n">indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1227" name="__codelineno-0-1227"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">__parameters</span> <span class="o">=</span> <span class="n">parameters</span>
<a id="__codelineno-0-1228" name="__codelineno-0-1228"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-1229" name="__codelineno-0-1229"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">__parameters</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">parameters</span>
<a id="__codelineno-0-1230" name="__codelineno-0-1230"></a>
<a id="__codelineno-0-1231" name="__codelineno-0-1231"></a>    <span class="k">if</span> <span class="n">reset</span><span class="p">:</span>
<a id="__codelineno-0-1232" name="__codelineno-0-1232"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="evotorch.neuroevolution.net.Policy.to_torch_module" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">to_torch_module</span><span class="p">(</span><span class="n">parameter_vector</span><span class="p">)</span></code>

<a href="#evotorch.neuroevolution.net.Policy.to_torch_module" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get a copy of the contained network, parameterized as specified.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>parameter_vector</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The parameters to be used by the new network.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>
        


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/vecrl.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1349">1349</a></span>
<span class="normal"><a href="#__codelineno-0-1350">1350</a></span>
<span class="normal"><a href="#__codelineno-0-1351">1351</a></span>
<span class="normal"><a href="#__codelineno-0-1352">1352</a></span>
<span class="normal"><a href="#__codelineno-0-1353">1353</a></span>
<span class="normal"><a href="#__codelineno-0-1354">1354</a></span>
<span class="normal"><a href="#__codelineno-0-1355">1355</a></span>
<span class="normal"><a href="#__codelineno-0-1356">1356</a></span>
<span class="normal"><a href="#__codelineno-0-1357">1357</a></span>
<span class="normal"><a href="#__codelineno-0-1358">1358</a></span>
<span class="normal"><a href="#__codelineno-0-1359">1359</a></span>
<span class="normal"><a href="#__codelineno-0-1360">1360</a></span>
<span class="normal"><a href="#__codelineno-0-1361">1361</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1349" name="__codelineno-0-1349"></a><span class="k">def</span><span class="w"> </span><span class="nf">to_torch_module</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameter_vector</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
<a id="__codelineno-0-1350" name="__codelineno-0-1350"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-1351" name="__codelineno-0-1351"></a><span class="sd">    Get a copy of the contained network, parameterized as specified.</span>
<a id="__codelineno-0-1352" name="__codelineno-0-1352"></a>
<a id="__codelineno-0-1353" name="__codelineno-0-1353"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-1354" name="__codelineno-0-1354"></a><span class="sd">        parameter_vector: The parameters to be used by the new network.</span>
<a id="__codelineno-0-1355" name="__codelineno-0-1355"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-1356" name="__codelineno-0-1356"></a><span class="sd">        Copy of the contained network, as a `torch.nn.Module` instance.</span>
<a id="__codelineno-0-1357" name="__codelineno-0-1357"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1358" name="__codelineno-0-1358"></a>    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<a id="__codelineno-0-1359" name="__codelineno-0-1359"></a>        <span class="n">net</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__module</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">parameter_vector</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-1360" name="__codelineno-0-1360"></a>        <span class="n">nnu</span><span class="o">.</span><span class="n">vector_to_parameters</span><span class="p">(</span><span class="n">parameter_vector</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<a id="__codelineno-0-1361" name="__codelineno-0-1361"></a>    <span class="k">return</span> <span class="n">net</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="evotorch.neuroevolution.net.RunningNorm" class="doc doc-heading">
            <code>RunningNorm</code>


<a href="#evotorch.neuroevolution.net.RunningNorm" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">


        <p>An online observation normalization tool</p>







              <details class="quote">
                <summary>Source code in <code>evotorch/neuroevolution/net/runningnorm.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span>
<span class="normal"><a href="#__codelineno-0-211">211</a></span>
<span class="normal"><a href="#__codelineno-0-212">212</a></span>
<span class="normal"><a href="#__codelineno-0-213">213</a></span>
<span class="normal"><a href="#__codelineno-0-214">214</a></span>
<span class="normal"><a href="#__codelineno-0-215">215</a></span>
<span class="normal"><a href="#__codelineno-0-216">216</a></span>
<span class="normal"><a href="#__codelineno-0-217">217</a></span>
<span class="normal"><a href="#__codelineno-0-218">218</a></span>
<span class="normal"><a href="#__codelineno-0-219">219</a></span>
<span class="normal"><a href="#__codelineno-0-220">220</a></span>
<span class="normal"><a href="#__codelineno-0-221">221</a></span>
<span class="normal"><a href="#__codelineno-0-222">222</a></span>
<span class="normal"><a href="#__codelineno-0-223">223</a></span>
<span class="normal"><a href="#__codelineno-0-224">224</a></span>
<span class="normal"><a href="#__codelineno-0-225">225</a></span>
<span class="normal"><a href="#__codelineno-0-226">226</a></span>
<span class="normal"><a href="#__codelineno-0-227">227</a></span>
<span class="normal"><a href="#__codelineno-0-228">228</a></span>
<span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span>
<span class="normal"><a href="#__codelineno-0-255">255</a></span>
<span class="normal"><a href="#__codelineno-0-256">256</a></span>
<span class="normal"><a href="#__codelineno-0-257">257</a></span>
<span class="normal"><a href="#__codelineno-0-258">258</a></span>
<span class="normal"><a href="#__codelineno-0-259">259</a></span>
<span class="normal"><a href="#__codelineno-0-260">260</a></span>
<span class="normal"><a href="#__codelineno-0-261">261</a></span>
<span class="normal"><a href="#__codelineno-0-262">262</a></span>
<span class="normal"><a href="#__codelineno-0-263">263</a></span>
<span class="normal"><a href="#__codelineno-0-264">264</a></span>
<span class="normal"><a href="#__codelineno-0-265">265</a></span>
<span class="normal"><a href="#__codelineno-0-266">266</a></span>
<span class="normal"><a href="#__codelineno-0-267">267</a></span>
<span class="normal"><a href="#__codelineno-0-268">268</a></span>
<span class="normal"><a href="#__codelineno-0-269">269</a></span>
<span class="normal"><a href="#__codelineno-0-270">270</a></span>
<span class="normal"><a href="#__codelineno-0-271">271</a></span>
<span class="normal"><a href="#__codelineno-0-272">272</a></span>
<span class="normal"><a href="#__codelineno-0-273">273</a></span>
<span class="normal"><a href="#__codelineno-0-274">274</a></span>
<span class="normal"><a href="#__codelineno-0-275">275</a></span>
<span class="normal"><a href="#__codelineno-0-276">276</a></span>
<span class="normal"><a href="#__codelineno-0-277">277</a></span>
<span class="normal"><a href="#__codelineno-0-278">278</a></span>
<span class="normal"><a href="#__codelineno-0-279">279</a></span>
<span class="normal"><a href="#__codelineno-0-280">280</a></span>
<span class="normal"><a href="#__codelineno-0-281">281</a></span>
<span class="normal"><a href="#__codelineno-0-282">282</a></span>
<span class="normal"><a href="#__codelineno-0-283">283</a></span>
<span class="normal"><a href="#__codelineno-0-284">284</a></span>
<span class="normal"><a href="#__codelineno-0-285">285</a></span>
<span class="normal"><a href="#__codelineno-0-286">286</a></span>
<span class="normal"><a href="#__codelineno-0-287">287</a></span>
<span class="normal"><a href="#__codelineno-0-288">288</a></span>
<span class="normal"><a href="#__codelineno-0-289">289</a></span>
<span class="normal"><a href="#__codelineno-0-290">290</a></span>
<span class="normal"><a href="#__codelineno-0-291">291</a></span>
<span class="normal"><a href="#__codelineno-0-292">292</a></span>
<span class="normal"><a href="#__codelineno-0-293">293</a></span>
<span class="normal"><a href="#__codelineno-0-294">294</a></span>
<span class="normal"><a href="#__codelineno-0-295">295</a></span>
<span class="normal"><a href="#__codelineno-0-296">296</a></span>
<span class="normal"><a href="#__codelineno-0-297">297</a></span>
<span class="normal"><a href="#__codelineno-0-298">298</a></span>
<span class="normal"><a href="#__codelineno-0-299">299</a></span>
<span class="normal"><a href="#__codelineno-0-300">300</a></span>
<span class="normal"><a href="#__codelineno-0-301">301</a></span>
<span class="normal"><a href="#__codelineno-0-302">302</a></span>
<span class="normal"><a href="#__codelineno-0-303">303</a></span>
<span class="normal"><a href="#__codelineno-0-304">304</a></span>
<span class="normal"><a href="#__codelineno-0-305">305</a></span>
<span class="normal"><a href="#__codelineno-0-306">306</a></span>
<span class="normal"><a href="#__codelineno-0-307">307</a></span>
<span class="normal"><a href="#__codelineno-0-308">308</a></span>
<span class="normal"><a href="#__codelineno-0-309">309</a></span>
<span class="normal"><a href="#__codelineno-0-310">310</a></span>
<span class="normal"><a href="#__codelineno-0-311">311</a></span>
<span class="normal"><a href="#__codelineno-0-312">312</a></span>
<span class="normal"><a href="#__codelineno-0-313">313</a></span>
<span class="normal"><a href="#__codelineno-0-314">314</a></span>
<span class="normal"><a href="#__codelineno-0-315">315</a></span>
<span class="normal"><a href="#__codelineno-0-316">316</a></span>
<span class="normal"><a href="#__codelineno-0-317">317</a></span>
<span class="normal"><a href="#__codelineno-0-318">318</a></span>
<span class="normal"><a href="#__codelineno-0-319">319</a></span>
<span class="normal"><a href="#__codelineno-0-320">320</a></span>
<span class="normal"><a href="#__codelineno-0-321">321</a></span>
<span class="normal"><a href="#__codelineno-0-322">322</a></span>
<span class="normal"><a href="#__codelineno-0-323">323</a></span>
<span class="normal"><a href="#__codelineno-0-324">324</a></span>
<span class="normal"><a href="#__codelineno-0-325">325</a></span>
<span class="normal"><a href="#__codelineno-0-326">326</a></span>
<span class="normal"><a href="#__codelineno-0-327">327</a></span>
<span class="normal"><a href="#__codelineno-0-328">328</a></span>
<span class="normal"><a href="#__codelineno-0-329">329</a></span>
<span class="normal"><a href="#__codelineno-0-330">330</a></span>
<span class="normal"><a href="#__codelineno-0-331">331</a></span>
<span class="normal"><a href="#__codelineno-0-332">332</a></span>
<span class="normal"><a href="#__codelineno-0-333">333</a></span>
<span class="normal"><a href="#__codelineno-0-334">334</a></span>
<span class="normal"><a href="#__codelineno-0-335">335</a></span>
<span class="normal"><a href="#__codelineno-0-336">336</a></span>
<span class="normal"><a href="#__codelineno-0-337">337</a></span>
<span class="normal"><a href="#__codelineno-0-338">338</a></span>
<span class="normal"><a href="#__codelineno-0-339">339</a></span>
<span class="normal"><a href="#__codelineno-0-340">340</a></span>
<span class="normal"><a href="#__codelineno-0-341">341</a></span>
<span class="normal"><a href="#__codelineno-0-342">342</a></span>
<span class="normal"><a href="#__codelineno-0-343">343</a></span>
<span class="normal"><a href="#__codelineno-0-344">344</a></span>
<span class="normal"><a href="#__codelineno-0-345">345</a></span>
<span class="normal"><a href="#__codelineno-0-346">346</a></span>
<span class="normal"><a href="#__codelineno-0-347">347</a></span>
<span class="normal"><a href="#__codelineno-0-348">348</a></span>
<span class="normal"><a href="#__codelineno-0-349">349</a></span>
<span class="normal"><a href="#__codelineno-0-350">350</a></span>
<span class="normal"><a href="#__codelineno-0-351">351</a></span>
<span class="normal"><a href="#__codelineno-0-352">352</a></span>
<span class="normal"><a href="#__codelineno-0-353">353</a></span>
<span class="normal"><a href="#__codelineno-0-354">354</a></span>
<span class="normal"><a href="#__codelineno-0-355">355</a></span>
<span class="normal"><a href="#__codelineno-0-356">356</a></span>
<span class="normal"><a href="#__codelineno-0-357">357</a></span>
<span class="normal"><a href="#__codelineno-0-358">358</a></span>
<span class="normal"><a href="#__codelineno-0-359">359</a></span>
<span class="normal"><a href="#__codelineno-0-360">360</a></span>
<span class="normal"><a href="#__codelineno-0-361">361</a></span>
<span class="normal"><a href="#__codelineno-0-362">362</a></span>
<span class="normal"><a href="#__codelineno-0-363">363</a></span>
<span class="normal"><a href="#__codelineno-0-364">364</a></span>
<span class="normal"><a href="#__codelineno-0-365">365</a></span>
<span class="normal"><a href="#__codelineno-0-366">366</a></span>
<span class="normal"><a href="#__codelineno-0-367">367</a></span>
<span class="normal"><a href="#__codelineno-0-368">368</a></span>
<span class="normal"><a href="#__codelineno-0-369">369</a></span>
<span class="normal"><a href="#__codelineno-0-370">370</a></span>
<span class="normal"><a href="#__codelineno-0-371">371</a></span>
<span class="normal"><a href="#__codelineno-0-372">372</a></span>
<span class="normal"><a href="#__codelineno-0-373">373</a></span>
<span class="normal"><a href="#__codelineno-0-374">374</a></span>
<span class="normal"><a href="#__codelineno-0-375">375</a></span>
<span class="normal"><a href="#__codelineno-0-376">376</a></span>
<span class="normal"><a href="#__codelineno-0-377">377</a></span>
<span class="normal"><a href="#__codelineno-0-378">378</a></span>
<span class="normal"><a href="#__codelineno-0-379">379</a></span>
<span class="normal"><a href="#__codelineno-0-380">380</a></span>
<span class="normal"><a href="#__codelineno-0-381">381</a></span>
<span class="normal"><a href="#__codelineno-0-382">382</a></span>
<span class="normal"><a href="#__codelineno-0-383">383</a></span>
<span class="normal"><a href="#__codelineno-0-384">384</a></span>
<span class="normal"><a href="#__codelineno-0-385">385</a></span>
<span class="normal"><a href="#__codelineno-0-386">386</a></span>
<span class="normal"><a href="#__codelineno-0-387">387</a></span>
<span class="normal"><a href="#__codelineno-0-388">388</a></span>
<span class="normal"><a href="#__codelineno-0-389">389</a></span>
<span class="normal"><a href="#__codelineno-0-390">390</a></span>
<span class="normal"><a href="#__codelineno-0-391">391</a></span>
<span class="normal"><a href="#__codelineno-0-392">392</a></span>
<span class="normal"><a href="#__codelineno-0-393">393</a></span>
<span class="normal"><a href="#__codelineno-0-394">394</a></span>
<span class="normal"><a href="#__codelineno-0-395">395</a></span>
<span class="normal"><a href="#__codelineno-0-396">396</a></span>
<span class="normal"><a href="#__codelineno-0-397">397</a></span>
<span class="normal"><a href="#__codelineno-0-398">398</a></span>
<span class="normal"><a href="#__codelineno-0-399">399</a></span>
<span class="normal"><a href="#__codelineno-0-400">400</a></span>
<span class="normal"><a href="#__codelineno-0-401">401</a></span>
<span class="normal"><a href="#__codelineno-0-402">402</a></span>
<span class="normal"><a href="#__codelineno-0-403">403</a></span>
<span class="normal"><a href="#__codelineno-0-404">404</a></span>
<span class="normal"><a href="#__codelineno-0-405">405</a></span>
<span class="normal"><a href="#__codelineno-0-406">406</a></span>
<span class="normal"><a href="#__codelineno-0-407">407</a></span>
<span class="normal"><a href="#__codelineno-0-408">408</a></span>
<span class="normal"><a href="#__codelineno-0-409">409</a></span>
<span class="normal"><a href="#__codelineno-0-410">410</a></span>
<span class="normal"><a href="#__codelineno-0-411">411</a></span>
<span class="normal"><a href="#__codelineno-0-412">412</a></span>
<span class="normal"><a href="#__codelineno-0-413">413</a></span>
<span class="normal"><a href="#__codelineno-0-414">414</a></span>
<span class="normal"><a href="#__codelineno-0-415">415</a></span>
<span class="normal"><a href="#__codelineno-0-416">416</a></span>
<span class="normal"><a href="#__codelineno-0-417">417</a></span>
<span class="normal"><a href="#__codelineno-0-418">418</a></span>
<span class="normal"><a href="#__codelineno-0-419">419</a></span>
<span class="normal"><a href="#__codelineno-0-420">420</a></span>
<span class="normal"><a href="#__codelineno-0-421">421</a></span>
<span class="normal"><a href="#__codelineno-0-422">422</a></span>
<span class="normal"><a href="#__codelineno-0-423">423</a></span>
<span class="normal"><a href="#__codelineno-0-424">424</a></span>
<span class="normal"><a href="#__codelineno-0-425">425</a></span>
<span class="normal"><a href="#__codelineno-0-426">426</a></span>
<span class="normal"><a href="#__codelineno-0-427">427</a></span>
<span class="normal"><a href="#__codelineno-0-428">428</a></span>
<span class="normal"><a href="#__codelineno-0-429">429</a></span>
<span class="normal"><a href="#__codelineno-0-430">430</a></span>
<span class="normal"><a href="#__codelineno-0-431">431</a></span>
<span class="normal"><a href="#__codelineno-0-432">432</a></span>
<span class="normal"><a href="#__codelineno-0-433">433</a></span>
<span class="normal"><a href="#__codelineno-0-434">434</a></span>
<span class="normal"><a href="#__codelineno-0-435">435</a></span>
<span class="normal"><a href="#__codelineno-0-436">436</a></span>
<span class="normal"><a href="#__codelineno-0-437">437</a></span>
<span class="normal"><a href="#__codelineno-0-438">438</a></span>
<span class="normal"><a href="#__codelineno-0-439">439</a></span>
<span class="normal"><a href="#__codelineno-0-440">440</a></span>
<span class="normal"><a href="#__codelineno-0-441">441</a></span>
<span class="normal"><a href="#__codelineno-0-442">442</a></span>
<span class="normal"><a href="#__codelineno-0-443">443</a></span>
<span class="normal"><a href="#__codelineno-0-444">444</a></span>
<span class="normal"><a href="#__codelineno-0-445">445</a></span>
<span class="normal"><a href="#__codelineno-0-446">446</a></span>
<span class="normal"><a href="#__codelineno-0-447">447</a></span>
<span class="normal"><a href="#__codelineno-0-448">448</a></span>
<span class="normal"><a href="#__codelineno-0-449">449</a></span>
<span class="normal"><a href="#__codelineno-0-450">450</a></span>
<span class="normal"><a href="#__codelineno-0-451">451</a></span>
<span class="normal"><a href="#__codelineno-0-452">452</a></span>
<span class="normal"><a href="#__codelineno-0-453">453</a></span>
<span class="normal"><a href="#__codelineno-0-454">454</a></span>
<span class="normal"><a href="#__codelineno-0-455">455</a></span>
<span class="normal"><a href="#__codelineno-0-456">456</a></span>
<span class="normal"><a href="#__codelineno-0-457">457</a></span>
<span class="normal"><a href="#__codelineno-0-458">458</a></span>
<span class="normal"><a href="#__codelineno-0-459">459</a></span>
<span class="normal"><a href="#__codelineno-0-460">460</a></span>
<span class="normal"><a href="#__codelineno-0-461">461</a></span>
<span class="normal"><a href="#__codelineno-0-462">462</a></span>
<span class="normal"><a href="#__codelineno-0-463">463</a></span>
<span class="normal"><a href="#__codelineno-0-464">464</a></span>
<span class="normal"><a href="#__codelineno-0-465">465</a></span>
<span class="normal"><a href="#__codelineno-0-466">466</a></span>
<span class="normal"><a href="#__codelineno-0-467">467</a></span>
<span class="normal"><a href="#__codelineno-0-468">468</a></span>
<span class="normal"><a href="#__codelineno-0-469">469</a></span>
<span class="normal"><a href="#__codelineno-0-470">470</a></span>
<span class="normal"><a href="#__codelineno-0-471">471</a></span>
<span class="normal"><a href="#__codelineno-0-472">472</a></span>
<span class="normal"><a href="#__codelineno-0-473">473</a></span>
<span class="normal"><a href="#__codelineno-0-474">474</a></span>
<span class="normal"><a href="#__codelineno-0-475">475</a></span>
<span class="normal"><a href="#__codelineno-0-476">476</a></span>
<span class="normal"><a href="#__codelineno-0-477">477</a></span>
<span class="normal"><a href="#__codelineno-0-478">478</a></span>
<span class="normal"><a href="#__codelineno-0-479">479</a></span>
<span class="normal"><a href="#__codelineno-0-480">480</a></span>
<span class="normal"><a href="#__codelineno-0-481">481</a></span>
<span class="normal"><a href="#__codelineno-0-482">482</a></span>
<span class="normal"><a href="#__codelineno-0-483">483</a></span>
<span class="normal"><a href="#__codelineno-0-484">484</a></span>
<span class="normal"><a href="#__codelineno-0-485">485</a></span>
<span class="normal"><a href="#__codelineno-0-486">486</a></span>
<span class="normal"><a href="#__codelineno-0-487">487</a></span>
<span class="normal"><a href="#__codelineno-0-488">488</a></span>
<span class="normal"><a href="#__codelineno-0-489">489</a></span>
<span class="normal"><a href="#__codelineno-0-490">490</a></span>
<span class="normal"><a href="#__codelineno-0-491">491</a></span>
<span class="normal"><a href="#__codelineno-0-492">492</a></span>
<span class="normal"><a href="#__codelineno-0-493">493</a></span>
<span class="normal"><a href="#__codelineno-0-494">494</a></span>
<span class="normal"><a href="#__codelineno-0-495">495</a></span>
<span class="normal"><a href="#__codelineno-0-496">496</a></span>
<span class="normal"><a href="#__codelineno-0-497">497</a></span>
<span class="normal"><a href="#__codelineno-0-498">498</a></span>
<span class="normal"><a href="#__codelineno-0-499">499</a></span>
<span class="normal"><a href="#__codelineno-0-500">500</a></span>
<span class="normal"><a href="#__codelineno-0-501">501</a></span>
<span class="normal"><a href="#__codelineno-0-502">502</a></span>
<span class="normal"><a href="#__codelineno-0-503">503</a></span>
<span class="normal"><a href="#__codelineno-0-504">504</a></span>
<span class="normal"><a href="#__codelineno-0-505">505</a></span>
<span class="normal"><a href="#__codelineno-0-506">506</a></span>
<span class="normal"><a href="#__codelineno-0-507">507</a></span>
<span class="normal"><a href="#__codelineno-0-508">508</a></span>
<span class="normal"><a href="#__codelineno-0-509">509</a></span>
<span class="normal"><a href="#__codelineno-0-510">510</a></span>
<span class="normal"><a href="#__codelineno-0-511">511</a></span>
<span class="normal"><a href="#__codelineno-0-512">512</a></span>
<span class="normal"><a href="#__codelineno-0-513">513</a></span>
<span class="normal"><a href="#__codelineno-0-514">514</a></span>
<span class="normal"><a href="#__codelineno-0-515">515</a></span>
<span class="normal"><a href="#__codelineno-0-516">516</a></span>
<span class="normal"><a href="#__codelineno-0-517">517</a></span>
<span class="normal"><a href="#__codelineno-0-518">518</a></span>
<span class="normal"><a href="#__codelineno-0-519">519</a></span>
<span class="normal"><a href="#__codelineno-0-520">520</a></span>
<span class="normal"><a href="#__codelineno-0-521">521</a></span>
<span class="normal"><a href="#__codelineno-0-522">522</a></span>
<span class="normal"><a href="#__codelineno-0-523">523</a></span>
<span class="normal"><a href="#__codelineno-0-524">524</a></span>
<span class="normal"><a href="#__codelineno-0-525">525</a></span>
<span class="normal"><a href="#__codelineno-0-526">526</a></span>
<span class="normal"><a href="#__codelineno-0-527">527</a></span>
<span class="normal"><a href="#__codelineno-0-528">528</a></span>
<span class="normal"><a href="#__codelineno-0-529">529</a></span>
<span class="normal"><a href="#__codelineno-0-530">530</a></span>
<span class="normal"><a href="#__codelineno-0-531">531</a></span>
<span class="normal"><a href="#__codelineno-0-532">532</a></span>
<span class="normal"><a href="#__codelineno-0-533">533</a></span>
<span class="normal"><a href="#__codelineno-0-534">534</a></span>
<span class="normal"><a href="#__codelineno-0-535">535</a></span>
<span class="normal"><a href="#__codelineno-0-536">536</a></span>
<span class="normal"><a href="#__codelineno-0-537">537</a></span>
<span class="normal"><a href="#__codelineno-0-538">538</a></span>
<span class="normal"><a href="#__codelineno-0-539">539</a></span>
<span class="normal"><a href="#__codelineno-0-540">540</a></span>
<span class="normal"><a href="#__codelineno-0-541">541</a></span>
<span class="normal"><a href="#__codelineno-0-542">542</a></span>
<span class="normal"><a href="#__codelineno-0-543">543</a></span>
<span class="normal"><a href="#__codelineno-0-544">544</a></span>
<span class="normal"><a href="#__codelineno-0-545">545</a></span>
<span class="normal"><a href="#__codelineno-0-546">546</a></span>
<span class="normal"><a href="#__codelineno-0-547">547</a></span>
<span class="normal"><a href="#__codelineno-0-548">548</a></span>
<span class="normal"><a href="#__codelineno-0-549">549</a></span>
<span class="normal"><a href="#__codelineno-0-550">550</a></span>
<span class="normal"><a href="#__codelineno-0-551">551</a></span>
<span class="normal"><a href="#__codelineno-0-552">552</a></span>
<span class="normal"><a href="#__codelineno-0-553">553</a></span>
<span class="normal"><a href="#__codelineno-0-554">554</a></span>
<span class="normal"><a href="#__codelineno-0-555">555</a></span>
<span class="normal"><a href="#__codelineno-0-556">556</a></span>
<span class="normal"><a href="#__codelineno-0-557">557</a></span>
<span class="normal"><a href="#__codelineno-0-558">558</a></span>
<span class="normal"><a href="#__codelineno-0-559">559</a></span>
<span class="normal"><a href="#__codelineno-0-560">560</a></span>
<span class="normal"><a href="#__codelineno-0-561">561</a></span>
<span class="normal"><a href="#__codelineno-0-562">562</a></span>
<span class="normal"><a href="#__codelineno-0-563">563</a></span>
<span class="normal"><a href="#__codelineno-0-564">564</a></span>
<span class="normal"><a href="#__codelineno-0-565">565</a></span>
<span class="normal"><a href="#__codelineno-0-566">566</a></span>
<span class="normal"><a href="#__codelineno-0-567">567</a></span>
<span class="normal"><a href="#__codelineno-0-568">568</a></span>
<span class="normal"><a href="#__codelineno-0-569">569</a></span>
<span class="normal"><a href="#__codelineno-0-570">570</a></span>
<span class="normal"><a href="#__codelineno-0-571">571</a></span>
<span class="normal"><a href="#__codelineno-0-572">572</a></span>
<span class="normal"><a href="#__codelineno-0-573">573</a></span>
<span class="normal"><a href="#__codelineno-0-574">574</a></span>
<span class="normal"><a href="#__codelineno-0-575">575</a></span>
<span class="normal"><a href="#__codelineno-0-576">576</a></span>
<span class="normal"><a href="#__codelineno-0-577">577</a></span>
<span class="normal"><a href="#__codelineno-0-578">578</a></span>
<span class="normal"><a href="#__codelineno-0-579">579</a></span>
<span class="normal"><a href="#__codelineno-0-580">580</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="k">class</span><span class="w"> </span><span class="nc">RunningNorm</span><span class="p">:</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">    An online observation normalization tool</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>        <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>        <span class="n">shape</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>        <span class="n">dtype</span><span class="p">:</span> <span class="n">DType</span><span class="p">,</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>        <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>        <span class="n">min_variance</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-2</span><span class="p">,</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>        <span class="n">clip</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">tuple</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">        `__init__(...)`: Initialize the RunningNorm</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">            shape: Observation shape. Can be an integer or a tuple.</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">            dtype: The dtype of the observations.</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">            device: The device in which the observation stats are held.</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a><span class="sd">                If left as None, the device is assumed to be &quot;cpu&quot;.</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a><span class="sd">            min_variance: A lower bound for the variance to be used in</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="sd">                the normalization computations.</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a><span class="sd">                In other words, if the computed variance according to the</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a><span class="sd">                collected observations ends up lower than `min_variance`,</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a><span class="sd">                this `min_variance` will be used instead (in an elementwise</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a><span class="sd">                manner) while computing the normalized observations.</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a><span class="sd">                As in Salimans et al. (2017), the default is 1e-2.</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a><span class="sd">            clip: Can be left as None (which is the default), or can be</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a><span class="sd">                given as a pair of real numbers.</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a><span class="sd">                This is used for clipping the observations after the</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a><span class="sd">                normalization operation.</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a><span class="sd">                In Salimans et al. (2017), (-5.0, +5.0) was used.</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>        <span class="c1"># Make sure that the shape is stored as a torch.Size object.</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">):</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">shape</span><span class="p">)])</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>        <span class="c1"># Store the number of dimensions</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_ndim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">)</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>        <span class="c1"># Store the dtype and the device</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span> <span class="o">=</span> <span class="n">to_torch_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span> <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">device</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>        <span class="c1"># Initialize the internally stored data as empty</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_sum</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_sum_of_squares</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_count</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>        <span class="c1"># Store the minimum variance</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_min_variance</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">min_variance</span><span class="p">)</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>        <span class="k">if</span> <span class="n">clip</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>            <span class="c1"># If a clip tuple was provided, store the specified lower and upper bounds</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>            <span class="n">lb</span><span class="p">,</span> <span class="n">ub</span> <span class="o">=</span> <span class="n">clip</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_lb</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">lb</span><span class="p">)</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_ub</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">ub</span><span class="p">)</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>            <span class="c1"># If a clip tuple was not provided the bounds are stored as None</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_lb</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_ub</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Device</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;RunningNorm&quot;</span><span class="p">:</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a><span class="sd">        If the target device is a different device, then make a copy of this</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a><span class="sd">        RunningNorm instance on the target device.</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a><span class="sd">        If the target device is the same with this RunningNorm&#39;s device, then</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a><span class="sd">        return this RunningNorm itself.</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a><span class="sd">            device: The target device.</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a><span class="sd">            The RunningNorm on the target device. This can be a copy, or the</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="sd">            original RunningNorm instance itself.</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>            <span class="k">return</span> <span class="bp">self</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>            <span class="n">new_running_norm</span> <span class="o">=</span> <span class="nb">object</span><span class="o">.</span><span class="fm">__new__</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>            <span class="n">already_handled</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;_sum&quot;</span><span class="p">,</span> <span class="s2">&quot;_sum_of_squares&quot;</span><span class="p">,</span> <span class="s2">&quot;_device&quot;</span><span class="p">}</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>            <span class="n">new_running_norm</span><span class="o">.</span><span class="n">_sum</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sum</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>            <span class="n">new_running_norm</span><span class="o">.</span><span class="n">_sum_of_squares</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sum_of_squares</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>            <span class="n">new_running_norm</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">device</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>                <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">already_handled</span><span class="p">:</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>                    <span class="nb">setattr</span><span class="p">(</span><span class="n">new_running_norm</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>            <span class="k">return</span> <span class="n">new_running_norm</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Device</span><span class="p">:</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a><span class="sd">        The device in which the observation stats are held</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DType</span><span class="p">:</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a><span class="sd">        The dtype of the stored observation stats</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">shape</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a><span class="sd">        Observation shape</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">min_variance</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a><span class="sd">        Minimum variance</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_min_variance</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">low</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a><span class="sd">        The lower component of the bounds given in the `clip` tuple.</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a><span class="sd">        If `clip` was initialized as None, this is also None.</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lb</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">high</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a><span class="sd">        The higher (upper) component of the bounds given in the `clip` tuple.</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a><span class="sd">        If `clip` was initialized as None, this is also None.</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ub</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_like_its_own</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_verify</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_like_its_own</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ndim</span><span class="p">:</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>            <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">:</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a>                    <span class="sa">f</span><span class="s2">&quot;This RunningNorm instance was initialized with shape: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="si">}</span><span class="s2">.&quot;</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>                    <span class="sa">f</span><span class="s2">&quot; However, the provided tensor has an incompatible shape: </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">_shape</span><span class="si">}</span><span class="s2">.&quot;</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>                <span class="p">)</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a>        <span class="k">elif</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ndim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a>            <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">:</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a>                    <span class="sa">f</span><span class="s2">&quot;This RunningNorm instance was initialized with shape: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="si">}</span><span class="s2">.&quot;</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>                    <span class="sa">f</span><span class="s2">&quot; The provided tensor is shaped </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>                    <span class="sa">f</span><span class="s2">&quot; Accepting the tensor&#39;s leftmost dimension as the batch size,&quot;</span>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>                    <span class="sa">f</span><span class="s2">&quot; the remaining shape is incompatible: </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="si">}</span><span class="s2">&quot;</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>                <span class="p">)</span>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>                <span class="sa">f</span><span class="s2">&quot;This RunningNorm instance was initialized with shape: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="si">}</span><span class="s2">.&quot;</span>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a>                <span class="sa">f</span><span class="s2">&quot; The provided tensor is shaped </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a>                <span class="sa">f</span><span class="s2">&quot; The number of dimensions of the given tensor is incompatible.&quot;</span>
<a id="__codelineno-0-211" name="__codelineno-0-211"></a>            <span class="p">)</span>
<a id="__codelineno-0-212" name="__codelineno-0-212"></a>        <span class="k">return</span> <span class="n">x</span>
<a id="__codelineno-0-213" name="__codelineno-0-213"></a>
<a id="__codelineno-0-214" name="__codelineno-0-214"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_has_no_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<a id="__codelineno-0-215" name="__codelineno-0-215"></a>        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_sum</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_sum_of_squares</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_count</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-216" name="__codelineno-0-216"></a>
<a id="__codelineno-0-217" name="__codelineno-0-217"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_has_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<a id="__codelineno-0-218" name="__codelineno-0-218"></a>        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_sum</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_sum_of_squares</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-219" name="__codelineno-0-219"></a>
<a id="__codelineno-0-220" name="__codelineno-0-220"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-221" name="__codelineno-0-221"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-222" name="__codelineno-0-222"></a><span class="sd">        Remove all the collected observation data.</span>
<a id="__codelineno-0-223" name="__codelineno-0-223"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-224" name="__codelineno-0-224"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_sum</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-225" name="__codelineno-0-225"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_sum_of_squares</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-226" name="__codelineno-0-226"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_count</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-227" name="__codelineno-0-227"></a>
<a id="__codelineno-0-228" name="__codelineno-0-228"></a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<a id="__codelineno-0-229" name="__codelineno-0-229"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Iterable</span><span class="p">,</span> <span class="s2">&quot;RunningNorm&quot;</span><span class="p">],</span> <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Iterable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">verify</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
<a id="__codelineno-0-230" name="__codelineno-0-230"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-231" name="__codelineno-0-231"></a><span class="sd">        Update the stored stats with new observation data.</span>
<a id="__codelineno-0-232" name="__codelineno-0-232"></a>
<a id="__codelineno-0-233" name="__codelineno-0-233"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-234" name="__codelineno-0-234"></a><span class="sd">            x: The new observation(s), as a PyTorch tensor, or any Iterable</span>
<a id="__codelineno-0-235" name="__codelineno-0-235"></a><span class="sd">                that can be converted to a PyTorch tensor, or another</span>
<a id="__codelineno-0-236" name="__codelineno-0-236"></a><span class="sd">                RunningNorm instance.</span>
<a id="__codelineno-0-237" name="__codelineno-0-237"></a><span class="sd">                If given as a tensor or as an Iterable, the shape of `x` can</span>
<a id="__codelineno-0-238" name="__codelineno-0-238"></a><span class="sd">                be the same with observation shape, or it can be augmented</span>
<a id="__codelineno-0-239" name="__codelineno-0-239"></a><span class="sd">                with an extra leftmost dimension.</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a><span class="sd">                In the case of augmented dimension, `x` is interpreted not as</span>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a><span class="sd">                a single observation, but as a batch of observations.</span>
<a id="__codelineno-0-242" name="__codelineno-0-242"></a><span class="sd">                If `x` is another RunningNorm instance, the stats stored by</span>
<a id="__codelineno-0-243" name="__codelineno-0-243"></a><span class="sd">                this RunningNorm instance will be updated with all the data</span>
<a id="__codelineno-0-244" name="__codelineno-0-244"></a><span class="sd">                stored by `x`.</span>
<a id="__codelineno-0-245" name="__codelineno-0-245"></a><span class="sd">            mask: Can be given as a 1-dimensional Iterable of booleans ONLY</span>
<a id="__codelineno-0-246" name="__codelineno-0-246"></a><span class="sd">                if `x` represents a batch of observations.</span>
<a id="__codelineno-0-247" name="__codelineno-0-247"></a><span class="sd">                If a `mask` is provided, the i-th observation within the</span>
<a id="__codelineno-0-248" name="__codelineno-0-248"></a><span class="sd">                observation batch `x` will be taken into account only if</span>
<a id="__codelineno-0-249" name="__codelineno-0-249"></a><span class="sd">                the i-th item of the `mask` is True.</span>
<a id="__codelineno-0-250" name="__codelineno-0-250"></a><span class="sd">            verify: Whether or not to verify the shape of the given Iterable</span>
<a id="__codelineno-0-251" name="__codelineno-0-251"></a><span class="sd">                objects. The default is True.</span>
<a id="__codelineno-0-252" name="__codelineno-0-252"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-253" name="__codelineno-0-253"></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">RunningNorm</span><span class="p">):</span>
<a id="__codelineno-0-254" name="__codelineno-0-254"></a>            <span class="c1"># If we are to update our stats according to another RunningNorm instance</span>
<a id="__codelineno-0-255" name="__codelineno-0-255"></a>
<a id="__codelineno-0-256" name="__codelineno-0-256"></a>            <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">_count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-257" name="__codelineno-0-257"></a>                <span class="c1"># We bother only if x is non-empty</span>
<a id="__codelineno-0-258" name="__codelineno-0-258"></a>
<a id="__codelineno-0-259" name="__codelineno-0-259"></a>                <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-260" name="__codelineno-0-260"></a>                    <span class="c1"># We were given another RunningNorm, not a batch of observations.</span>
<a id="__codelineno-0-261" name="__codelineno-0-261"></a>                    <span class="c1"># So, we do not expect to receive a mask tensor.</span>
<a id="__codelineno-0-262" name="__codelineno-0-262"></a>                    <span class="c1"># If a mask was provided, then this is an unexpected way of calling this function.</span>
<a id="__codelineno-0-263" name="__codelineno-0-263"></a>                    <span class="c1"># We therefore raise an error.</span>
<a id="__codelineno-0-264" name="__codelineno-0-264"></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-265" name="__codelineno-0-265"></a>                        <span class="s2">&quot;The `mask` argument is expected as None if the first argument is a RunningNorm.&quot;</span>
<a id="__codelineno-0-266" name="__codelineno-0-266"></a>                        <span class="s2">&quot; However, `mask` is found as something other than None.&quot;</span>
<a id="__codelineno-0-267" name="__codelineno-0-267"></a>                    <span class="p">)</span>
<a id="__codelineno-0-268" name="__codelineno-0-268"></a>
<a id="__codelineno-0-269" name="__codelineno-0-269"></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">!=</span> <span class="n">x</span><span class="o">.</span><span class="n">_shape</span><span class="p">:</span>
<a id="__codelineno-0-270" name="__codelineno-0-270"></a>                    <span class="c1"># If the shapes of this RunningNorm and of the other RunningNorm</span>
<a id="__codelineno-0-271" name="__codelineno-0-271"></a>                    <span class="c1"># do not match, then we cannot use `x` for updating our stats.</span>
<a id="__codelineno-0-272" name="__codelineno-0-272"></a>                    <span class="c1"># It might be the case that `x` was initialized for another</span>
<a id="__codelineno-0-273" name="__codelineno-0-273"></a>                    <span class="c1"># task, with differently sized observations.</span>
<a id="__codelineno-0-274" name="__codelineno-0-274"></a>                    <span class="c1"># We therefore raise an error.</span>
<a id="__codelineno-0-275" name="__codelineno-0-275"></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-276" name="__codelineno-0-276"></a>                        <span class="sa">f</span><span class="s2">&quot;The RunningNorm to be updated has the shape </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="si">}</span><span class="s2">&quot;</span>
<a id="__codelineno-0-277" name="__codelineno-0-277"></a>                        <span class="sa">f</span><span class="s2">&quot; The other RunningNorm has the shape </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="si">}</span><span class="s2">&quot;</span>
<a id="__codelineno-0-278" name="__codelineno-0-278"></a>                        <span class="sa">f</span><span class="s2">&quot; These shapes are incompatible.&quot;</span>
<a id="__codelineno-0-279" name="__codelineno-0-279"></a>                    <span class="p">)</span>
<a id="__codelineno-0-280" name="__codelineno-0-280"></a>
<a id="__codelineno-0-281" name="__codelineno-0-281"></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_no_data</span><span class="p">():</span>
<a id="__codelineno-0-282" name="__codelineno-0-282"></a>                    <span class="c1"># If this RunningNorm has no data at all, then we clone the</span>
<a id="__codelineno-0-283" name="__codelineno-0-283"></a>                    <span class="c1"># data of x.</span>
<a id="__codelineno-0-284" name="__codelineno-0-284"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">_sum</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_like_its_own</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">_sum</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
<a id="__codelineno-0-285" name="__codelineno-0-285"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">_sum_of_squares</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_like_its_own</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">_sum_of_squares</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
<a id="__codelineno-0-286" name="__codelineno-0-286"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">_count</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">_count</span>
<a id="__codelineno-0-287" name="__codelineno-0-287"></a>                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_data</span><span class="p">():</span>
<a id="__codelineno-0-288" name="__codelineno-0-288"></a>                    <span class="c1"># If this RunningNorm has its own data, then we update the</span>
<a id="__codelineno-0-289" name="__codelineno-0-289"></a>                    <span class="c1"># stored data with the data stored by x.</span>
<a id="__codelineno-0-290" name="__codelineno-0-290"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">_sum</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_like_its_own</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">_sum</span><span class="p">)</span>
<a id="__codelineno-0-291" name="__codelineno-0-291"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">_sum_of_squares</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_like_its_own</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">_sum_of_squares</span><span class="p">)</span>
<a id="__codelineno-0-292" name="__codelineno-0-292"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">_count</span> <span class="o">+=</span> <span class="n">x</span><span class="o">.</span><span class="n">_count</span>
<a id="__codelineno-0-293" name="__codelineno-0-293"></a>                <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-294" name="__codelineno-0-294"></a>                    <span class="k">assert</span> <span class="kc">False</span><span class="p">,</span> <span class="s2">&quot;RunningNorm is in an invalid state! This might be a bug.&quot;</span>
<a id="__codelineno-0-295" name="__codelineno-0-295"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-296" name="__codelineno-0-296"></a>            <span class="c1"># This is the case where the received argument x is not a</span>
<a id="__codelineno-0-297" name="__codelineno-0-297"></a>            <span class="c1"># RunningNorm object, but an Iterable.</span>
<a id="__codelineno-0-298" name="__codelineno-0-298"></a>
<a id="__codelineno-0-299" name="__codelineno-0-299"></a>            <span class="k">if</span> <span class="n">verify</span><span class="p">:</span>
<a id="__codelineno-0-300" name="__codelineno-0-300"></a>                <span class="c1"># If we have the `verify` flag, then we make sure that</span>
<a id="__codelineno-0-301" name="__codelineno-0-301"></a>                <span class="c1"># x is a tensor of the correct shape</span>
<a id="__codelineno-0-302" name="__codelineno-0-302"></a>                <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_verify</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-303" name="__codelineno-0-303"></a>
<a id="__codelineno-0-304" name="__codelineno-0-304"></a>            <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ndim</span><span class="p">:</span>
<a id="__codelineno-0-305" name="__codelineno-0-305"></a>                <span class="c1"># If the shape of x is exactly the same with the observation shape</span>
<a id="__codelineno-0-306" name="__codelineno-0-306"></a>                <span class="c1"># then we assume that x represents a single observation, and not a</span>
<a id="__codelineno-0-307" name="__codelineno-0-307"></a>                <span class="c1"># batch of observations.</span>
<a id="__codelineno-0-308" name="__codelineno-0-308"></a>
<a id="__codelineno-0-309" name="__codelineno-0-309"></a>                <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-310" name="__codelineno-0-310"></a>                    <span class="c1"># Since we are dealing with a single observation,</span>
<a id="__codelineno-0-311" name="__codelineno-0-311"></a>                    <span class="c1"># we do not expect to receive a mask argument.</span>
<a id="__codelineno-0-312" name="__codelineno-0-312"></a>                    <span class="c1"># If the mask argument was provided, then this is an unexpected</span>
<a id="__codelineno-0-313" name="__codelineno-0-313"></a>                    <span class="c1"># usage of this function.</span>
<a id="__codelineno-0-314" name="__codelineno-0-314"></a>                    <span class="c1"># We therefore raise an error.</span>
<a id="__codelineno-0-315" name="__codelineno-0-315"></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-316" name="__codelineno-0-316"></a>                        <span class="s2">&quot;The `mask` argument is expected as None if the first argument is a single observation&quot;</span>
<a id="__codelineno-0-317" name="__codelineno-0-317"></a>                        <span class="s2">&quot; (i.e. not a batch of observations, with an extra leftmost dimension).&quot;</span>
<a id="__codelineno-0-318" name="__codelineno-0-318"></a>                        <span class="s2">&quot; However, `mask` is found as something other than None.&quot;</span>
<a id="__codelineno-0-319" name="__codelineno-0-319"></a>                    <span class="p">)</span>
<a id="__codelineno-0-320" name="__codelineno-0-320"></a>
<a id="__codelineno-0-321" name="__codelineno-0-321"></a>                <span class="c1"># Since x is a single observation,</span>
<a id="__codelineno-0-322" name="__codelineno-0-322"></a>                <span class="c1"># the sum of observations extracted from x is x itself,</span>
<a id="__codelineno-0-323" name="__codelineno-0-323"></a>                <span class="c1"># and the sum of squared observations extracted from x is</span>
<a id="__codelineno-0-324" name="__codelineno-0-324"></a>                <span class="c1"># the square of x itself.</span>
<a id="__codelineno-0-325" name="__codelineno-0-325"></a>                <span class="n">sum_of_x</span> <span class="o">=</span> <span class="n">x</span>
<a id="__codelineno-0-326" name="__codelineno-0-326"></a>                <span class="n">sum_of_x_squared</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">square</span><span class="p">()</span>
<a id="__codelineno-0-327" name="__codelineno-0-327"></a>                <span class="c1"># We extracted a single observation from x</span>
<a id="__codelineno-0-328" name="__codelineno-0-328"></a>                <span class="n">n</span> <span class="o">=</span> <span class="mi">1</span>
<a id="__codelineno-0-329" name="__codelineno-0-329"></a>            <span class="k">elif</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ndim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
<a id="__codelineno-0-330" name="__codelineno-0-330"></a>                <span class="c1"># If the number of dimensions of x is one more than the number</span>
<a id="__codelineno-0-331" name="__codelineno-0-331"></a>                <span class="c1"># of dimensions of this RunningNorm, then we assume that x is a batch</span>
<a id="__codelineno-0-332" name="__codelineno-0-332"></a>                <span class="c1"># of observations.</span>
<a id="__codelineno-0-333" name="__codelineno-0-333"></a>
<a id="__codelineno-0-334" name="__codelineno-0-334"></a>                <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-335" name="__codelineno-0-335"></a>                    <span class="c1"># If a mask is provided, then we first make sure that it is a tensor</span>
<a id="__codelineno-0-336" name="__codelineno-0-336"></a>                    <span class="c1"># of dtype bool in the correct device.</span>
<a id="__codelineno-0-337" name="__codelineno-0-337"></a>                    <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
<a id="__codelineno-0-338" name="__codelineno-0-338"></a>
<a id="__codelineno-0-339" name="__codelineno-0-339"></a>                    <span class="k">if</span> <span class="n">mask</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
<a id="__codelineno-0-340" name="__codelineno-0-340"></a>                        <span class="c1"># We expect the mask to be 1-dimensional.</span>
<a id="__codelineno-0-341" name="__codelineno-0-341"></a>                        <span class="c1"># If not, we raise an error.</span>
<a id="__codelineno-0-342" name="__codelineno-0-342"></a>                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-343" name="__codelineno-0-343"></a>                            <span class="sa">f</span><span class="s2">&quot;The `mask` tensor was expected as a 1-dimensional tensor.&quot;</span>
<a id="__codelineno-0-344" name="__codelineno-0-344"></a>                            <span class="sa">f</span><span class="s2">&quot; However, its shape is </span><span class="si">{</span><span class="n">mask</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span>
<a id="__codelineno-0-345" name="__codelineno-0-345"></a>                        <span class="p">)</span>
<a id="__codelineno-0-346" name="__codelineno-0-346"></a>
<a id="__codelineno-0-347" name="__codelineno-0-347"></a>                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span> <span class="o">!=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
<a id="__codelineno-0-348" name="__codelineno-0-348"></a>                        <span class="c1"># If the length of the mask is not the batch size of x,</span>
<a id="__codelineno-0-349" name="__codelineno-0-349"></a>                        <span class="c1"># then there is a mismatch.</span>
<a id="__codelineno-0-350" name="__codelineno-0-350"></a>                        <span class="c1"># We therefore raise an error.</span>
<a id="__codelineno-0-351" name="__codelineno-0-351"></a>                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-352" name="__codelineno-0-352"></a>                            <span class="sa">f</span><span class="s2">&quot;The shape of the given tensor is </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span>
<a id="__codelineno-0-353" name="__codelineno-0-353"></a>                            <span class="sa">f</span><span class="s2">&quot; Therefore, the batch size of observations is </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span>
<a id="__codelineno-0-354" name="__codelineno-0-354"></a>                            <span class="sa">f</span><span class="s2">&quot; However, the given `mask` tensor does not has an incompatible length: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
<a id="__codelineno-0-355" name="__codelineno-0-355"></a>                        <span class="p">)</span>
<a id="__codelineno-0-356" name="__codelineno-0-356"></a>
<a id="__codelineno-0-357" name="__codelineno-0-357"></a>                    <span class="c1"># We compute how many True items we have in the mask.</span>
<a id="__codelineno-0-358" name="__codelineno-0-358"></a>                    <span class="c1"># This integer gives us how many observations we extract from x.</span>
<a id="__codelineno-0-359" name="__codelineno-0-359"></a>                    <span class="n">n</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)))</span>
<a id="__codelineno-0-360" name="__codelineno-0-360"></a>
<a id="__codelineno-0-361" name="__codelineno-0-361"></a>                    <span class="c1"># We now re-cast the mask as the observation dtype (so that True items turn to 1.0</span>
<a id="__codelineno-0-362" name="__codelineno-0-362"></a>                    <span class="c1"># and False items turn to 0.0), and then increase its number of dimensions so that</span>
<a id="__codelineno-0-363" name="__codelineno-0-363"></a>                    <span class="c1"># it can operate directly with x.</span>
<a id="__codelineno-0-364" name="__codelineno-0-364"></a>                    <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_like_its_own</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">+</span> <span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))))</span>
<a id="__codelineno-0-365" name="__codelineno-0-365"></a>
<a id="__codelineno-0-366" name="__codelineno-0-366"></a>                    <span class="c1"># Finally, we multiply x with the mask. This means that the observations with corresponding</span>
<a id="__codelineno-0-367" name="__codelineno-0-367"></a>                    <span class="c1"># mask values as False are zeroed out.</span>
<a id="__codelineno-0-368" name="__codelineno-0-368"></a>                    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">mask</span>
<a id="__codelineno-0-369" name="__codelineno-0-369"></a>                <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-370" name="__codelineno-0-370"></a>                    <span class="c1"># This is the case where we did not receive a mask.</span>
<a id="__codelineno-0-371" name="__codelineno-0-371"></a>                    <span class="c1"># We can simply say that the number of observations to extract from x</span>
<a id="__codelineno-0-372" name="__codelineno-0-372"></a>                    <span class="c1"># is the size of its leftmost dimension, i.e. the batch size.</span>
<a id="__codelineno-0-373" name="__codelineno-0-373"></a>                    <span class="n">n</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-374" name="__codelineno-0-374"></a>
<a id="__codelineno-0-375" name="__codelineno-0-375"></a>                <span class="c1"># With or without a mask, we are now ready to extract the sum and sum of squares</span>
<a id="__codelineno-0-376" name="__codelineno-0-376"></a>                <span class="c1"># from x.</span>
<a id="__codelineno-0-377" name="__codelineno-0-377"></a>                <span class="n">sum_of_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-378" name="__codelineno-0-378"></a>                <span class="n">sum_of_x_squared</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">square</span><span class="p">(),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-379" name="__codelineno-0-379"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-380" name="__codelineno-0-380"></a>                <span class="c1"># This is the case where the number of dimensions of x is unrecognized.</span>
<a id="__codelineno-0-381" name="__codelineno-0-381"></a>                <span class="c1"># This case is actually already checked by the _verify(...) method earlier.</span>
<a id="__codelineno-0-382" name="__codelineno-0-382"></a>                <span class="c1"># This defensive fallback case is only for when verify=False and it turned out</span>
<a id="__codelineno-0-383" name="__codelineno-0-383"></a>                <span class="c1"># that the ndim is invalid.</span>
<a id="__codelineno-0-384" name="__codelineno-0-384"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid shape: </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<a id="__codelineno-0-385" name="__codelineno-0-385"></a>
<a id="__codelineno-0-386" name="__codelineno-0-386"></a>            <span class="c1"># At this point, we handled all the valid cases regarding the Iterable x,</span>
<a id="__codelineno-0-387" name="__codelineno-0-387"></a>            <span class="c1"># and we have our sum_of_x (sum of all observations), sum_of_squares</span>
<a id="__codelineno-0-388" name="__codelineno-0-388"></a>            <span class="c1"># (sum of all squared observations), and n (number of observations extracted</span>
<a id="__codelineno-0-389" name="__codelineno-0-389"></a>            <span class="c1"># from x).</span>
<a id="__codelineno-0-390" name="__codelineno-0-390"></a>
<a id="__codelineno-0-391" name="__codelineno-0-391"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_no_data</span><span class="p">():</span>
<a id="__codelineno-0-392" name="__codelineno-0-392"></a>                <span class="c1"># If our RunningNorm is empty, the observation data we extracted from x</span>
<a id="__codelineno-0-393" name="__codelineno-0-393"></a>                <span class="c1"># become our RunningNorm&#39;s new data.</span>
<a id="__codelineno-0-394" name="__codelineno-0-394"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_sum</span> <span class="o">=</span> <span class="n">sum_of_x</span>
<a id="__codelineno-0-395" name="__codelineno-0-395"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_sum_of_squares</span> <span class="o">=</span> <span class="n">sum_of_x_squared</span>
<a id="__codelineno-0-396" name="__codelineno-0-396"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_count</span> <span class="o">=</span> <span class="n">n</span>
<a id="__codelineno-0-397" name="__codelineno-0-397"></a>            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_data</span><span class="p">():</span>
<a id="__codelineno-0-398" name="__codelineno-0-398"></a>                <span class="c1"># If our RunningNorm is not empty, the stored data is updated with the</span>
<a id="__codelineno-0-399" name="__codelineno-0-399"></a>                <span class="c1"># data extracted from x.</span>
<a id="__codelineno-0-400" name="__codelineno-0-400"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_sum</span> <span class="o">+=</span> <span class="n">sum_of_x</span>
<a id="__codelineno-0-401" name="__codelineno-0-401"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_sum_of_squares</span> <span class="o">+=</span> <span class="n">sum_of_x_squared</span>
<a id="__codelineno-0-402" name="__codelineno-0-402"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_count</span> <span class="o">+=</span> <span class="n">n</span>
<a id="__codelineno-0-403" name="__codelineno-0-403"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-404" name="__codelineno-0-404"></a>                <span class="c1"># This is an erroneous state where the internal data looks neither</span>
<a id="__codelineno-0-405" name="__codelineno-0-405"></a>                <span class="c1"># existent nor completely empty.</span>
<a id="__codelineno-0-406" name="__codelineno-0-406"></a>                <span class="c1"># This might be the result of a bug, or maybe this instance&#39;s</span>
<a id="__codelineno-0-407" name="__codelineno-0-407"></a>                <span class="c1"># protected variables were tempered with from the outside.</span>
<a id="__codelineno-0-408" name="__codelineno-0-408"></a>                <span class="k">assert</span> <span class="kc">False</span><span class="p">,</span> <span class="s2">&quot;RunningNorm is in an invalid state! This might be a bug.&quot;</span>
<a id="__codelineno-0-409" name="__codelineno-0-409"></a>
<a id="__codelineno-0-410" name="__codelineno-0-410"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-411" name="__codelineno-0-411"></a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<a id="__codelineno-0-412" name="__codelineno-0-412"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">stats</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">CollectedStats</span><span class="p">:</span>
<a id="__codelineno-0-413" name="__codelineno-0-413"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-414" name="__codelineno-0-414"></a><span class="sd">        The collected data&#39;s mean and standard deviation (stdev) in a tuple</span>
<a id="__codelineno-0-415" name="__codelineno-0-415"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-416" name="__codelineno-0-416"></a>
<a id="__codelineno-0-417" name="__codelineno-0-417"></a>        <span class="c1"># Using the internally stored sum, sum_of_squares, and count,</span>
<a id="__codelineno-0-418" name="__codelineno-0-418"></a>        <span class="c1"># compute E[x] and E[x^2]</span>
<a id="__codelineno-0-419" name="__codelineno-0-419"></a>        <span class="n">E_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sum</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">_count</span>
<a id="__codelineno-0-420" name="__codelineno-0-420"></a>        <span class="n">E_x2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sum_of_squares</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">_count</span>
<a id="__codelineno-0-421" name="__codelineno-0-421"></a>
<a id="__codelineno-0-422" name="__codelineno-0-422"></a>        <span class="c1"># The mean is E[x]</span>
<a id="__codelineno-0-423" name="__codelineno-0-423"></a>        <span class="n">mean</span> <span class="o">=</span> <span class="n">E_x</span>
<a id="__codelineno-0-424" name="__codelineno-0-424"></a>
<a id="__codelineno-0-425" name="__codelineno-0-425"></a>        <span class="c1"># The variance is E[x^2] - (E[x])^2, elementwise clipped such that</span>
<a id="__codelineno-0-426" name="__codelineno-0-426"></a>        <span class="c1"># it cannot go below min_variance</span>
<a id="__codelineno-0-427" name="__codelineno-0-427"></a>        <span class="n">variance</span> <span class="o">=</span> <span class="n">_clamp</span><span class="p">(</span><span class="n">E_x2</span> <span class="o">-</span> <span class="n">E_x</span><span class="o">.</span><span class="n">square</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_min_variance</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<a id="__codelineno-0-428" name="__codelineno-0-428"></a>
<a id="__codelineno-0-429" name="__codelineno-0-429"></a>        <span class="c1"># Standard deviation is finally computed as the square root of the variance</span>
<a id="__codelineno-0-430" name="__codelineno-0-430"></a>        <span class="n">stdev</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">variance</span><span class="p">)</span>
<a id="__codelineno-0-431" name="__codelineno-0-431"></a>
<a id="__codelineno-0-432" name="__codelineno-0-432"></a>        <span class="c1"># Return the stats in a named tuple</span>
<a id="__codelineno-0-433" name="__codelineno-0-433"></a>        <span class="k">return</span> <span class="n">CollectedStats</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">stdev</span><span class="o">=</span><span class="n">stdev</span><span class="p">)</span>
<a id="__codelineno-0-434" name="__codelineno-0-434"></a>
<a id="__codelineno-0-435" name="__codelineno-0-435"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-436" name="__codelineno-0-436"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-437" name="__codelineno-0-437"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-438" name="__codelineno-0-438"></a><span class="sd">        The collected data&#39;s mean</span>
<a id="__codelineno-0-439" name="__codelineno-0-439"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-440" name="__codelineno-0-440"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sum</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">_count</span>
<a id="__codelineno-0-441" name="__codelineno-0-441"></a>
<a id="__codelineno-0-442" name="__codelineno-0-442"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-443" name="__codelineno-0-443"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">stdev</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-444" name="__codelineno-0-444"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-445" name="__codelineno-0-445"></a><span class="sd">        The collected data&#39;s standard deviation</span>
<a id="__codelineno-0-446" name="__codelineno-0-446"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-447" name="__codelineno-0-447"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">stdev</span>
<a id="__codelineno-0-448" name="__codelineno-0-448"></a>
<a id="__codelineno-0-449" name="__codelineno-0-449"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-450" name="__codelineno-0-450"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-451" name="__codelineno-0-451"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-452" name="__codelineno-0-452"></a><span class="sd">        The collected data&#39;s sum</span>
<a id="__codelineno-0-453" name="__codelineno-0-453"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-454" name="__codelineno-0-454"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sum</span>
<a id="__codelineno-0-455" name="__codelineno-0-455"></a>
<a id="__codelineno-0-456" name="__codelineno-0-456"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-457" name="__codelineno-0-457"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">sum_of_squares</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-458" name="__codelineno-0-458"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-459" name="__codelineno-0-459"></a><span class="sd">        Sum of squares of the collected data</span>
<a id="__codelineno-0-460" name="__codelineno-0-460"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-461" name="__codelineno-0-461"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sum_of_squares</span>
<a id="__codelineno-0-462" name="__codelineno-0-462"></a>
<a id="__codelineno-0-463" name="__codelineno-0-463"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-464" name="__codelineno-0-464"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">count</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-465" name="__codelineno-0-465"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-466" name="__codelineno-0-466"></a><span class="sd">        Number of observations encountered</span>
<a id="__codelineno-0-467" name="__codelineno-0-467"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-468" name="__codelineno-0-468"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_count</span>
<a id="__codelineno-0-469" name="__codelineno-0-469"></a>
<a id="__codelineno-0-470" name="__codelineno-0-470"></a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<a id="__codelineno-0-471" name="__codelineno-0-471"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">normalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">result_as_numpy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">verify</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">:</span>
<a id="__codelineno-0-472" name="__codelineno-0-472"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-473" name="__codelineno-0-473"></a><span class="sd">        Normalize the given observation x.</span>
<a id="__codelineno-0-474" name="__codelineno-0-474"></a>
<a id="__codelineno-0-475" name="__codelineno-0-475"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-476" name="__codelineno-0-476"></a><span class="sd">            x: The observation(s), as a PyTorch tensor, or any Iterable</span>
<a id="__codelineno-0-477" name="__codelineno-0-477"></a><span class="sd">                that is convertable to a PyTorch tensor.</span>
<a id="__codelineno-0-478" name="__codelineno-0-478"></a><span class="sd">                `x` can be a single observation, or it can be a batch</span>
<a id="__codelineno-0-479" name="__codelineno-0-479"></a><span class="sd">                of observations (with an extra leftmost dimension).</span>
<a id="__codelineno-0-480" name="__codelineno-0-480"></a><span class="sd">            result_as_numpy: Whether or not to return the normalized</span>
<a id="__codelineno-0-481" name="__codelineno-0-481"></a><span class="sd">                observation as a numpy array.</span>
<a id="__codelineno-0-482" name="__codelineno-0-482"></a><span class="sd">                If left as None (which is the default), then the returned</span>
<a id="__codelineno-0-483" name="__codelineno-0-483"></a><span class="sd">                type depends on x: a PyTorch tensor is returned if x is a</span>
<a id="__codelineno-0-484" name="__codelineno-0-484"></a><span class="sd">                PyTorch tensor, and a numpy array is returned otherwise.</span>
<a id="__codelineno-0-485" name="__codelineno-0-485"></a><span class="sd">                If True, the result is always a numpy array.</span>
<a id="__codelineno-0-486" name="__codelineno-0-486"></a><span class="sd">                If False, the result is always a PyTorch tensor.</span>
<a id="__codelineno-0-487" name="__codelineno-0-487"></a><span class="sd">            verify: Whether or not to check the type and dimensions of x.</span>
<a id="__codelineno-0-488" name="__codelineno-0-488"></a><span class="sd">                This is True by default.</span>
<a id="__codelineno-0-489" name="__codelineno-0-489"></a><span class="sd">                Note that, if `verify` is False, this function will not</span>
<a id="__codelineno-0-490" name="__codelineno-0-490"></a><span class="sd">                properly check the type of `x` and will assume that `x`</span>
<a id="__codelineno-0-491" name="__codelineno-0-491"></a><span class="sd">                is a PyTorch tensor.</span>
<a id="__codelineno-0-492" name="__codelineno-0-492"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-493" name="__codelineno-0-493"></a><span class="sd">            The normalized observation, as a PyTorch tensor or a numpy array.</span>
<a id="__codelineno-0-494" name="__codelineno-0-494"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-495" name="__codelineno-0-495"></a>
<a id="__codelineno-0-496" name="__codelineno-0-496"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_count</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-497" name="__codelineno-0-497"></a>            <span class="c1"># If this RunningNorm instance has no data yet,</span>
<a id="__codelineno-0-498" name="__codelineno-0-498"></a>            <span class="c1"># then we do not know how to do the normalization.</span>
<a id="__codelineno-0-499" name="__codelineno-0-499"></a>            <span class="c1"># We therefore raise an error.</span>
<a id="__codelineno-0-500" name="__codelineno-0-500"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot do normalization because no data is collected yet.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-501" name="__codelineno-0-501"></a>
<a id="__codelineno-0-502" name="__codelineno-0-502"></a>        <span class="k">if</span> <span class="n">verify</span><span class="p">:</span>
<a id="__codelineno-0-503" name="__codelineno-0-503"></a>            <span class="c1"># Here we verify the type and shape of x.</span>
<a id="__codelineno-0-504" name="__codelineno-0-504"></a>
<a id="__codelineno-0-505" name="__codelineno-0-505"></a>            <span class="k">if</span> <span class="n">result_as_numpy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-506" name="__codelineno-0-506"></a>                <span class="c1"># If there is not an explicit request about the return type,</span>
<a id="__codelineno-0-507" name="__codelineno-0-507"></a>                <span class="c1"># we infer the return type from the type of x:</span>
<a id="__codelineno-0-508" name="__codelineno-0-508"></a>                <span class="c1"># if x is a tensor, we return a tensor;</span>
<a id="__codelineno-0-509" name="__codelineno-0-509"></a>                <span class="c1"># otherwise, we assume x to be a CPU-bound iterable, and</span>
<a id="__codelineno-0-510" name="__codelineno-0-510"></a>                <span class="c1"># therefore we return a numpy array.</span>
<a id="__codelineno-0-511" name="__codelineno-0-511"></a>                <span class="n">result_as_numpy</span> <span class="o">=</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
<a id="__codelineno-0-512" name="__codelineno-0-512"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-513" name="__codelineno-0-513"></a>                <span class="n">result_as_numpy</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">result_as_numpy</span><span class="p">)</span>
<a id="__codelineno-0-514" name="__codelineno-0-514"></a>
<a id="__codelineno-0-515" name="__codelineno-0-515"></a>            <span class="c1"># We call _verify() to make sure that x is of correct shape</span>
<a id="__codelineno-0-516" name="__codelineno-0-516"></a>            <span class="c1"># and is properly converted to a PyTorch tensor.</span>
<a id="__codelineno-0-517" name="__codelineno-0-517"></a>            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_verify</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-518" name="__codelineno-0-518"></a>
<a id="__codelineno-0-519" name="__codelineno-0-519"></a>        <span class="c1"># We get the mean and stdev of the collected data</span>
<a id="__codelineno-0-520" name="__codelineno-0-520"></a>        <span class="n">mean</span><span class="p">,</span> <span class="n">stdev</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stats</span>
<a id="__codelineno-0-521" name="__codelineno-0-521"></a>
<a id="__codelineno-0-522" name="__codelineno-0-522"></a>        <span class="c1"># Now we compute the normalized observation, clipped according to the</span>
<a id="__codelineno-0-523" name="__codelineno-0-523"></a>        <span class="c1"># lower and upper bounds expressed by the `clip` tuple, if exists.</span>
<a id="__codelineno-0-524" name="__codelineno-0-524"></a>        <span class="n">result</span> <span class="o">=</span> <span class="n">_clamp</span><span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">stdev</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lb</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ub</span><span class="p">)</span>
<a id="__codelineno-0-525" name="__codelineno-0-525"></a>
<a id="__codelineno-0-526" name="__codelineno-0-526"></a>        <span class="k">if</span> <span class="n">result_as_numpy</span><span class="p">:</span>
<a id="__codelineno-0-527" name="__codelineno-0-527"></a>            <span class="c1"># If we are to return the result as a numpy array, we do the</span>
<a id="__codelineno-0-528" name="__codelineno-0-528"></a>            <span class="c1"># necessary conversion.</span>
<a id="__codelineno-0-529" name="__codelineno-0-529"></a>            <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<a id="__codelineno-0-530" name="__codelineno-0-530"></a>
<a id="__codelineno-0-531" name="__codelineno-0-531"></a>        <span class="c1"># Finally, return the result</span>
<a id="__codelineno-0-532" name="__codelineno-0-532"></a>        <span class="k">return</span> <span class="n">result</span>
<a id="__codelineno-0-533" name="__codelineno-0-533"></a>
<a id="__codelineno-0-534" name="__codelineno-0-534"></a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<a id="__codelineno-0-535" name="__codelineno-0-535"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">update_and_normalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Iterable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">:</span>
<a id="__codelineno-0-536" name="__codelineno-0-536"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-537" name="__codelineno-0-537"></a><span class="sd">        Update the observation stats according to x, then normalize x.</span>
<a id="__codelineno-0-538" name="__codelineno-0-538"></a>
<a id="__codelineno-0-539" name="__codelineno-0-539"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-540" name="__codelineno-0-540"></a><span class="sd">            x: The observation(s), as a PyTorch tensor, or as an Iterable</span>
<a id="__codelineno-0-541" name="__codelineno-0-541"></a><span class="sd">                which can be converted to a PyTorch tensor.</span>
<a id="__codelineno-0-542" name="__codelineno-0-542"></a><span class="sd">                The shape of x can be the same with the observaiton shape,</span>
<a id="__codelineno-0-543" name="__codelineno-0-543"></a><span class="sd">                or it can be augmented with an extra leftmost dimension</span>
<a id="__codelineno-0-544" name="__codelineno-0-544"></a><span class="sd">                to express a batch of observations.</span>
<a id="__codelineno-0-545" name="__codelineno-0-545"></a><span class="sd">            mask: Can be given as a 1-dimensional Iterable of booleans ONLY</span>
<a id="__codelineno-0-546" name="__codelineno-0-546"></a><span class="sd">                if `x` represents a batch of observations.</span>
<a id="__codelineno-0-547" name="__codelineno-0-547"></a><span class="sd">                If a `mask` is provided, the i-th observation within the</span>
<a id="__codelineno-0-548" name="__codelineno-0-548"></a><span class="sd">                observation batch `x` will be taken into account only if</span>
<a id="__codelineno-0-549" name="__codelineno-0-549"></a><span class="sd">                the the i-th item of the `mask` is True.</span>
<a id="__codelineno-0-550" name="__codelineno-0-550"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-551" name="__codelineno-0-551"></a><span class="sd">            The normalized counterpart of the observation(s) expressed by x.</span>
<a id="__codelineno-0-552" name="__codelineno-0-552"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-553" name="__codelineno-0-553"></a>        <span class="n">result_as_numpy</span> <span class="o">=</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
<a id="__codelineno-0-554" name="__codelineno-0-554"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_verify</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-555" name="__codelineno-0-555"></a>
<a id="__codelineno-0-556" name="__codelineno-0-556"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">verify</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-557" name="__codelineno-0-557"></a>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">verify</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-558" name="__codelineno-0-558"></a>
<a id="__codelineno-0-559" name="__codelineno-0-559"></a>        <span class="k">if</span> <span class="n">result_as_numpy</span><span class="p">:</span>
<a id="__codelineno-0-560" name="__codelineno-0-560"></a>            <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<a id="__codelineno-0-561" name="__codelineno-0-561"></a>
<a id="__codelineno-0-562" name="__codelineno-0-562"></a>        <span class="k">return</span> <span class="n">result</span>
<a id="__codelineno-0-563" name="__codelineno-0-563"></a>
<a id="__codelineno-0-564" name="__codelineno-0-564"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">to_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ObsNormLayer&quot;</span><span class="p">:</span>
<a id="__codelineno-0-565" name="__codelineno-0-565"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-566" name="__codelineno-0-566"></a><span class="sd">        Make a PyTorch module which normalizes the its inputs.</span>
<a id="__codelineno-0-567" name="__codelineno-0-567"></a>
<a id="__codelineno-0-568" name="__codelineno-0-568"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-569" name="__codelineno-0-569"></a><span class="sd">            An ObsNormLayer instance.</span>
<a id="__codelineno-0-570" name="__codelineno-0-570"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-571" name="__codelineno-0-571"></a>        <span class="n">mean</span><span class="p">,</span> <span class="n">stdev</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stats</span>
<a id="__codelineno-0-572" name="__codelineno-0-572"></a>        <span class="n">low</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">low</span>
<a id="__codelineno-0-573" name="__codelineno-0-573"></a>        <span class="n">high</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">high</span>
<a id="__codelineno-0-574" name="__codelineno-0-574"></a>        <span class="k">return</span> <span class="n">ObsNormLayer</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">stdev</span><span class="o">=</span><span class="n">stdev</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">high</span><span class="p">)</span>
<a id="__codelineno-0-575" name="__codelineno-0-575"></a>
<a id="__codelineno-0-576" name="__codelineno-0-576"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<a id="__codelineno-0-577" name="__codelineno-0-577"></a>        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;&lt;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">, count: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">count</span><span class="si">}</span><span class="s2">&gt;&quot;</span>
<a id="__codelineno-0-578" name="__codelineno-0-578"></a>
<a id="__codelineno-0-579" name="__codelineno-0-579"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">__copy__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;RunningNorm&quot;</span><span class="p">:</span>
<a id="__codelineno-0-580" name="__codelineno-0-580"></a>        <span class="k">return</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="evotorch.neuroevolution.net.RunningNorm.count" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">count</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#evotorch.neuroevolution.net.RunningNorm.count" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Number of observations encountered</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="evotorch.neuroevolution.net.RunningNorm.device" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">device</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#evotorch.neuroevolution.net.RunningNorm.device" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>The device in which the observation stats are held</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="evotorch.neuroevolution.net.RunningNorm.dtype" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">dtype</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#evotorch.neuroevolution.net.RunningNorm.dtype" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>The dtype of the stored observation stats</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="evotorch.neuroevolution.net.RunningNorm.high" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">high</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#evotorch.neuroevolution.net.RunningNorm.high" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>The higher (upper) component of the bounds given in the <code>clip</code> tuple.
If <code>clip</code> was initialized as None, this is also None.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="evotorch.neuroevolution.net.RunningNorm.low" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">low</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#evotorch.neuroevolution.net.RunningNorm.low" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>The lower component of the bounds given in the <code>clip</code> tuple.
If <code>clip</code> was initialized as None, this is also None.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="evotorch.neuroevolution.net.RunningNorm.mean" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mean</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#evotorch.neuroevolution.net.RunningNorm.mean" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>The collected data's mean</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="evotorch.neuroevolution.net.RunningNorm.min_variance" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">min_variance</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#evotorch.neuroevolution.net.RunningNorm.min_variance" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Minimum variance</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="evotorch.neuroevolution.net.RunningNorm.shape" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">shape</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#evotorch.neuroevolution.net.RunningNorm.shape" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Observation shape</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="evotorch.neuroevolution.net.RunningNorm.stats" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">stats</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#evotorch.neuroevolution.net.RunningNorm.stats" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>The collected data's mean and standard deviation (stdev) in a tuple</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="evotorch.neuroevolution.net.RunningNorm.stdev" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">stdev</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#evotorch.neuroevolution.net.RunningNorm.stdev" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>The collected data's standard deviation</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="evotorch.neuroevolution.net.RunningNorm.sum" class="doc doc-heading">
            <code class="highlight language-python"><span class="nb">sum</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#evotorch.neuroevolution.net.RunningNorm.sum" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>The collected data's sum</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="evotorch.neuroevolution.net.RunningNorm.sum_of_squares" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sum_of_squares</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#evotorch.neuroevolution.net.RunningNorm.sum_of_squares" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Sum of squares of the collected data</p>

    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="evotorch.neuroevolution.net.RunningNorm.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">min_variance</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">clip</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#evotorch.neuroevolution.net.RunningNorm.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p><code>__init__(...)</code>: Initialize the RunningNorm</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>shape</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="tuple">tuple</span>, <span title="int">int</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observation shape. Can be an integer or a tuple.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dtype</code>
            </td>
            <td>
                  <code><span title="evotorch.tools.DType">DType</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The dtype of the observations.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="evotorch.tools.Device">Device</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The device in which the observation stats are held.
If left as None, the device is assumed to be "cpu".</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>min_variance</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A lower bound for the variance to be used in
the normalization computations.
In other words, if the computed variance according to the
collected observations ends up lower than <code>min_variance</code>,
this <code>min_variance</code> will be used instead (in an elementwise
manner) while computing the normalized observations.
As in Salimans et al. (2017), the default is 1e-2.</p>
              </div>
            </td>
            <td>
                  <code>0.01</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>clip</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="tuple">tuple</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Can be left as None (which is the default), or can be
given as a pair of real numbers.
This is used for clipping the observations after the
normalization operation.
In Salimans et al. (2017), (-5.0, +5.0) was used.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/runningnorm.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>    <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>    <span class="n">shape</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>    <span class="n">dtype</span><span class="p">:</span> <span class="n">DType</span><span class="p">,</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>    <span class="n">min_variance</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-2</span><span class="p">,</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>    <span class="n">clip</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">tuple</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">    `__init__(...)`: Initialize the RunningNorm</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">        shape: Observation shape. Can be an integer or a tuple.</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">        dtype: The dtype of the observations.</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">        device: The device in which the observation stats are held.</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a><span class="sd">            If left as None, the device is assumed to be &quot;cpu&quot;.</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a><span class="sd">        min_variance: A lower bound for the variance to be used in</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="sd">            the normalization computations.</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a><span class="sd">            In other words, if the computed variance according to the</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a><span class="sd">            collected observations ends up lower than `min_variance`,</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a><span class="sd">            this `min_variance` will be used instead (in an elementwise</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a><span class="sd">            manner) while computing the normalized observations.</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a><span class="sd">            As in Salimans et al. (2017), the default is 1e-2.</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a><span class="sd">        clip: Can be left as None (which is the default), or can be</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a><span class="sd">            given as a pair of real numbers.</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a><span class="sd">            This is used for clipping the observations after the</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a><span class="sd">            normalization operation.</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a><span class="sd">            In Salimans et al. (2017), (-5.0, +5.0) was used.</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>    <span class="c1"># Make sure that the shape is stored as a torch.Size object.</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">):</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">shape</span><span class="p">)])</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>    <span class="c1"># Store the number of dimensions</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_ndim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">)</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>    <span class="c1"># Store the dtype and the device</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span> <span class="o">=</span> <span class="n">to_torch_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span> <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">device</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>    <span class="c1"># Initialize the internally stored data as empty</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_sum</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_sum_of_squares</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_count</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>    <span class="c1"># Store the minimum variance</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_min_variance</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">min_variance</span><span class="p">)</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>    <span class="k">if</span> <span class="n">clip</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>        <span class="c1"># If a clip tuple was provided, store the specified lower and upper bounds</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>        <span class="n">lb</span><span class="p">,</span> <span class="n">ub</span> <span class="o">=</span> <span class="n">clip</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_lb</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">lb</span><span class="p">)</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_ub</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">ub</span><span class="p">)</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>        <span class="c1"># If a clip tuple was not provided the bounds are stored as None</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_lb</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_ub</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="evotorch.neuroevolution.net.RunningNorm.normalize" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">result_as_numpy</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verify</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

<a href="#evotorch.neuroevolution.net.RunningNorm.normalize" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Normalize the given observation x.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="typing.Iterable">Iterable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The observation(s), as a PyTorch tensor, or any Iterable
that is convertable to a PyTorch tensor.
<code>x</code> can be a single observation, or it can be a batch
of observations (with an extra leftmost dimension).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>result_as_numpy</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="bool">bool</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether or not to return the normalized
observation as a numpy array.
If left as None (which is the default), then the returned
type depends on x: a PyTorch tensor is returned if x is a
PyTorch tensor, and a numpy array is returned otherwise.
If True, the result is always a numpy array.
If False, the result is always a PyTorch tensor.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>verify</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether or not to check the type and dimensions of x.
This is True by default.
Note that, if <code>verify</code> is False, this function will not
properly check the type of <code>x</code> and will assume that <code>x</code>
is a PyTorch tensor.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>
        


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/runningnorm.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-470">470</a></span>
<span class="normal"><a href="#__codelineno-0-471">471</a></span>
<span class="normal"><a href="#__codelineno-0-472">472</a></span>
<span class="normal"><a href="#__codelineno-0-473">473</a></span>
<span class="normal"><a href="#__codelineno-0-474">474</a></span>
<span class="normal"><a href="#__codelineno-0-475">475</a></span>
<span class="normal"><a href="#__codelineno-0-476">476</a></span>
<span class="normal"><a href="#__codelineno-0-477">477</a></span>
<span class="normal"><a href="#__codelineno-0-478">478</a></span>
<span class="normal"><a href="#__codelineno-0-479">479</a></span>
<span class="normal"><a href="#__codelineno-0-480">480</a></span>
<span class="normal"><a href="#__codelineno-0-481">481</a></span>
<span class="normal"><a href="#__codelineno-0-482">482</a></span>
<span class="normal"><a href="#__codelineno-0-483">483</a></span>
<span class="normal"><a href="#__codelineno-0-484">484</a></span>
<span class="normal"><a href="#__codelineno-0-485">485</a></span>
<span class="normal"><a href="#__codelineno-0-486">486</a></span>
<span class="normal"><a href="#__codelineno-0-487">487</a></span>
<span class="normal"><a href="#__codelineno-0-488">488</a></span>
<span class="normal"><a href="#__codelineno-0-489">489</a></span>
<span class="normal"><a href="#__codelineno-0-490">490</a></span>
<span class="normal"><a href="#__codelineno-0-491">491</a></span>
<span class="normal"><a href="#__codelineno-0-492">492</a></span>
<span class="normal"><a href="#__codelineno-0-493">493</a></span>
<span class="normal"><a href="#__codelineno-0-494">494</a></span>
<span class="normal"><a href="#__codelineno-0-495">495</a></span>
<span class="normal"><a href="#__codelineno-0-496">496</a></span>
<span class="normal"><a href="#__codelineno-0-497">497</a></span>
<span class="normal"><a href="#__codelineno-0-498">498</a></span>
<span class="normal"><a href="#__codelineno-0-499">499</a></span>
<span class="normal"><a href="#__codelineno-0-500">500</a></span>
<span class="normal"><a href="#__codelineno-0-501">501</a></span>
<span class="normal"><a href="#__codelineno-0-502">502</a></span>
<span class="normal"><a href="#__codelineno-0-503">503</a></span>
<span class="normal"><a href="#__codelineno-0-504">504</a></span>
<span class="normal"><a href="#__codelineno-0-505">505</a></span>
<span class="normal"><a href="#__codelineno-0-506">506</a></span>
<span class="normal"><a href="#__codelineno-0-507">507</a></span>
<span class="normal"><a href="#__codelineno-0-508">508</a></span>
<span class="normal"><a href="#__codelineno-0-509">509</a></span>
<span class="normal"><a href="#__codelineno-0-510">510</a></span>
<span class="normal"><a href="#__codelineno-0-511">511</a></span>
<span class="normal"><a href="#__codelineno-0-512">512</a></span>
<span class="normal"><a href="#__codelineno-0-513">513</a></span>
<span class="normal"><a href="#__codelineno-0-514">514</a></span>
<span class="normal"><a href="#__codelineno-0-515">515</a></span>
<span class="normal"><a href="#__codelineno-0-516">516</a></span>
<span class="normal"><a href="#__codelineno-0-517">517</a></span>
<span class="normal"><a href="#__codelineno-0-518">518</a></span>
<span class="normal"><a href="#__codelineno-0-519">519</a></span>
<span class="normal"><a href="#__codelineno-0-520">520</a></span>
<span class="normal"><a href="#__codelineno-0-521">521</a></span>
<span class="normal"><a href="#__codelineno-0-522">522</a></span>
<span class="normal"><a href="#__codelineno-0-523">523</a></span>
<span class="normal"><a href="#__codelineno-0-524">524</a></span>
<span class="normal"><a href="#__codelineno-0-525">525</a></span>
<span class="normal"><a href="#__codelineno-0-526">526</a></span>
<span class="normal"><a href="#__codelineno-0-527">527</a></span>
<span class="normal"><a href="#__codelineno-0-528">528</a></span>
<span class="normal"><a href="#__codelineno-0-529">529</a></span>
<span class="normal"><a href="#__codelineno-0-530">530</a></span>
<span class="normal"><a href="#__codelineno-0-531">531</a></span>
<span class="normal"><a href="#__codelineno-0-532">532</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-470" name="__codelineno-0-470"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<a id="__codelineno-0-471" name="__codelineno-0-471"></a><span class="k">def</span><span class="w"> </span><span class="nf">normalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">result_as_numpy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">verify</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">:</span>
<a id="__codelineno-0-472" name="__codelineno-0-472"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-473" name="__codelineno-0-473"></a><span class="sd">    Normalize the given observation x.</span>
<a id="__codelineno-0-474" name="__codelineno-0-474"></a>
<a id="__codelineno-0-475" name="__codelineno-0-475"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-476" name="__codelineno-0-476"></a><span class="sd">        x: The observation(s), as a PyTorch tensor, or any Iterable</span>
<a id="__codelineno-0-477" name="__codelineno-0-477"></a><span class="sd">            that is convertable to a PyTorch tensor.</span>
<a id="__codelineno-0-478" name="__codelineno-0-478"></a><span class="sd">            `x` can be a single observation, or it can be a batch</span>
<a id="__codelineno-0-479" name="__codelineno-0-479"></a><span class="sd">            of observations (with an extra leftmost dimension).</span>
<a id="__codelineno-0-480" name="__codelineno-0-480"></a><span class="sd">        result_as_numpy: Whether or not to return the normalized</span>
<a id="__codelineno-0-481" name="__codelineno-0-481"></a><span class="sd">            observation as a numpy array.</span>
<a id="__codelineno-0-482" name="__codelineno-0-482"></a><span class="sd">            If left as None (which is the default), then the returned</span>
<a id="__codelineno-0-483" name="__codelineno-0-483"></a><span class="sd">            type depends on x: a PyTorch tensor is returned if x is a</span>
<a id="__codelineno-0-484" name="__codelineno-0-484"></a><span class="sd">            PyTorch tensor, and a numpy array is returned otherwise.</span>
<a id="__codelineno-0-485" name="__codelineno-0-485"></a><span class="sd">            If True, the result is always a numpy array.</span>
<a id="__codelineno-0-486" name="__codelineno-0-486"></a><span class="sd">            If False, the result is always a PyTorch tensor.</span>
<a id="__codelineno-0-487" name="__codelineno-0-487"></a><span class="sd">        verify: Whether or not to check the type and dimensions of x.</span>
<a id="__codelineno-0-488" name="__codelineno-0-488"></a><span class="sd">            This is True by default.</span>
<a id="__codelineno-0-489" name="__codelineno-0-489"></a><span class="sd">            Note that, if `verify` is False, this function will not</span>
<a id="__codelineno-0-490" name="__codelineno-0-490"></a><span class="sd">            properly check the type of `x` and will assume that `x`</span>
<a id="__codelineno-0-491" name="__codelineno-0-491"></a><span class="sd">            is a PyTorch tensor.</span>
<a id="__codelineno-0-492" name="__codelineno-0-492"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-493" name="__codelineno-0-493"></a><span class="sd">        The normalized observation, as a PyTorch tensor or a numpy array.</span>
<a id="__codelineno-0-494" name="__codelineno-0-494"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-495" name="__codelineno-0-495"></a>
<a id="__codelineno-0-496" name="__codelineno-0-496"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_count</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-497" name="__codelineno-0-497"></a>        <span class="c1"># If this RunningNorm instance has no data yet,</span>
<a id="__codelineno-0-498" name="__codelineno-0-498"></a>        <span class="c1"># then we do not know how to do the normalization.</span>
<a id="__codelineno-0-499" name="__codelineno-0-499"></a>        <span class="c1"># We therefore raise an error.</span>
<a id="__codelineno-0-500" name="__codelineno-0-500"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot do normalization because no data is collected yet.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-501" name="__codelineno-0-501"></a>
<a id="__codelineno-0-502" name="__codelineno-0-502"></a>    <span class="k">if</span> <span class="n">verify</span><span class="p">:</span>
<a id="__codelineno-0-503" name="__codelineno-0-503"></a>        <span class="c1"># Here we verify the type and shape of x.</span>
<a id="__codelineno-0-504" name="__codelineno-0-504"></a>
<a id="__codelineno-0-505" name="__codelineno-0-505"></a>        <span class="k">if</span> <span class="n">result_as_numpy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-506" name="__codelineno-0-506"></a>            <span class="c1"># If there is not an explicit request about the return type,</span>
<a id="__codelineno-0-507" name="__codelineno-0-507"></a>            <span class="c1"># we infer the return type from the type of x:</span>
<a id="__codelineno-0-508" name="__codelineno-0-508"></a>            <span class="c1"># if x is a tensor, we return a tensor;</span>
<a id="__codelineno-0-509" name="__codelineno-0-509"></a>            <span class="c1"># otherwise, we assume x to be a CPU-bound iterable, and</span>
<a id="__codelineno-0-510" name="__codelineno-0-510"></a>            <span class="c1"># therefore we return a numpy array.</span>
<a id="__codelineno-0-511" name="__codelineno-0-511"></a>            <span class="n">result_as_numpy</span> <span class="o">=</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
<a id="__codelineno-0-512" name="__codelineno-0-512"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-513" name="__codelineno-0-513"></a>            <span class="n">result_as_numpy</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">result_as_numpy</span><span class="p">)</span>
<a id="__codelineno-0-514" name="__codelineno-0-514"></a>
<a id="__codelineno-0-515" name="__codelineno-0-515"></a>        <span class="c1"># We call _verify() to make sure that x is of correct shape</span>
<a id="__codelineno-0-516" name="__codelineno-0-516"></a>        <span class="c1"># and is properly converted to a PyTorch tensor.</span>
<a id="__codelineno-0-517" name="__codelineno-0-517"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_verify</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-518" name="__codelineno-0-518"></a>
<a id="__codelineno-0-519" name="__codelineno-0-519"></a>    <span class="c1"># We get the mean and stdev of the collected data</span>
<a id="__codelineno-0-520" name="__codelineno-0-520"></a>    <span class="n">mean</span><span class="p">,</span> <span class="n">stdev</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stats</span>
<a id="__codelineno-0-521" name="__codelineno-0-521"></a>
<a id="__codelineno-0-522" name="__codelineno-0-522"></a>    <span class="c1"># Now we compute the normalized observation, clipped according to the</span>
<a id="__codelineno-0-523" name="__codelineno-0-523"></a>    <span class="c1"># lower and upper bounds expressed by the `clip` tuple, if exists.</span>
<a id="__codelineno-0-524" name="__codelineno-0-524"></a>    <span class="n">result</span> <span class="o">=</span> <span class="n">_clamp</span><span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">stdev</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lb</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ub</span><span class="p">)</span>
<a id="__codelineno-0-525" name="__codelineno-0-525"></a>
<a id="__codelineno-0-526" name="__codelineno-0-526"></a>    <span class="k">if</span> <span class="n">result_as_numpy</span><span class="p">:</span>
<a id="__codelineno-0-527" name="__codelineno-0-527"></a>        <span class="c1"># If we are to return the result as a numpy array, we do the</span>
<a id="__codelineno-0-528" name="__codelineno-0-528"></a>        <span class="c1"># necessary conversion.</span>
<a id="__codelineno-0-529" name="__codelineno-0-529"></a>        <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<a id="__codelineno-0-530" name="__codelineno-0-530"></a>
<a id="__codelineno-0-531" name="__codelineno-0-531"></a>    <span class="c1"># Finally, return the result</span>
<a id="__codelineno-0-532" name="__codelineno-0-532"></a>    <span class="k">return</span> <span class="n">result</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="evotorch.neuroevolution.net.RunningNorm.reset" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">reset</span><span class="p">()</span></code>

<a href="#evotorch.neuroevolution.net.RunningNorm.reset" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Remove all the collected observation data.</p>


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/runningnorm.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-220">220</a></span>
<span class="normal"><a href="#__codelineno-0-221">221</a></span>
<span class="normal"><a href="#__codelineno-0-222">222</a></span>
<span class="normal"><a href="#__codelineno-0-223">223</a></span>
<span class="normal"><a href="#__codelineno-0-224">224</a></span>
<span class="normal"><a href="#__codelineno-0-225">225</a></span>
<span class="normal"><a href="#__codelineno-0-226">226</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-220" name="__codelineno-0-220"></a><span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-221" name="__codelineno-0-221"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-222" name="__codelineno-0-222"></a><span class="sd">    Remove all the collected observation data.</span>
<a id="__codelineno-0-223" name="__codelineno-0-223"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-224" name="__codelineno-0-224"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_sum</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-225" name="__codelineno-0-225"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_sum_of_squares</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-226" name="__codelineno-0-226"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_count</span> <span class="o">=</span> <span class="mi">0</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="evotorch.neuroevolution.net.RunningNorm.to" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></code>

<a href="#evotorch.neuroevolution.net.RunningNorm.to" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>If the target device is a different device, then make a copy of this
RunningNorm instance on the target device.
If the target device is the same with this RunningNorm's device, then
return this RunningNorm itself.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
                  <code><span title="evotorch.tools.Device">Device</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The target device.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>
        


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/runningnorm.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-114" name="__codelineno-0-114"></a><span class="k">def</span><span class="w"> </span><span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Device</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;RunningNorm&quot;</span><span class="p">:</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a><span class="sd">    If the target device is a different device, then make a copy of this</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a><span class="sd">    RunningNorm instance on the target device.</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a><span class="sd">    If the target device is the same with this RunningNorm&#39;s device, then</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a><span class="sd">    return this RunningNorm itself.</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a><span class="sd">        device: The target device.</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a><span class="sd">        The RunningNorm on the target device. This can be a copy, or the</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="sd">        original RunningNorm instance itself.</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>        <span class="k">return</span> <span class="bp">self</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>        <span class="n">new_running_norm</span> <span class="o">=</span> <span class="nb">object</span><span class="o">.</span><span class="fm">__new__</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>        <span class="n">already_handled</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;_sum&quot;</span><span class="p">,</span> <span class="s2">&quot;_sum_of_squares&quot;</span><span class="p">,</span> <span class="s2">&quot;_device&quot;</span><span class="p">}</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>        <span class="n">new_running_norm</span><span class="o">.</span><span class="n">_sum</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sum</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>        <span class="n">new_running_norm</span><span class="o">.</span><span class="n">_sum_of_squares</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sum_of_squares</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>        <span class="n">new_running_norm</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">device</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>            <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">already_handled</span><span class="p">:</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>                <span class="nb">setattr</span><span class="p">(</span><span class="n">new_running_norm</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>        <span class="k">return</span> <span class="n">new_running_norm</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="evotorch.neuroevolution.net.RunningNorm.to_layer" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">to_layer</span><span class="p">()</span></code>

<a href="#evotorch.neuroevolution.net.RunningNorm.to_layer" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Make a PyTorch module which normalizes the its inputs.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" title="ObsNormLayer (evotorch.neuroevolution.net.runningnorm.ObsNormLayer)" href="runningnorm/#evotorch.neuroevolution.net.runningnorm.ObsNormLayer">ObsNormLayer</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>An ObsNormLayer instance.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/runningnorm.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-564">564</a></span>
<span class="normal"><a href="#__codelineno-0-565">565</a></span>
<span class="normal"><a href="#__codelineno-0-566">566</a></span>
<span class="normal"><a href="#__codelineno-0-567">567</a></span>
<span class="normal"><a href="#__codelineno-0-568">568</a></span>
<span class="normal"><a href="#__codelineno-0-569">569</a></span>
<span class="normal"><a href="#__codelineno-0-570">570</a></span>
<span class="normal"><a href="#__codelineno-0-571">571</a></span>
<span class="normal"><a href="#__codelineno-0-572">572</a></span>
<span class="normal"><a href="#__codelineno-0-573">573</a></span>
<span class="normal"><a href="#__codelineno-0-574">574</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-564" name="__codelineno-0-564"></a><span class="k">def</span><span class="w"> </span><span class="nf">to_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ObsNormLayer&quot;</span><span class="p">:</span>
<a id="__codelineno-0-565" name="__codelineno-0-565"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-566" name="__codelineno-0-566"></a><span class="sd">    Make a PyTorch module which normalizes the its inputs.</span>
<a id="__codelineno-0-567" name="__codelineno-0-567"></a>
<a id="__codelineno-0-568" name="__codelineno-0-568"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-569" name="__codelineno-0-569"></a><span class="sd">        An ObsNormLayer instance.</span>
<a id="__codelineno-0-570" name="__codelineno-0-570"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-571" name="__codelineno-0-571"></a>    <span class="n">mean</span><span class="p">,</span> <span class="n">stdev</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stats</span>
<a id="__codelineno-0-572" name="__codelineno-0-572"></a>    <span class="n">low</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">low</span>
<a id="__codelineno-0-573" name="__codelineno-0-573"></a>    <span class="n">high</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">high</span>
<a id="__codelineno-0-574" name="__codelineno-0-574"></a>    <span class="k">return</span> <span class="n">ObsNormLayer</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">stdev</span><span class="o">=</span><span class="n">stdev</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">high</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="evotorch.neuroevolution.net.RunningNorm.update" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">update</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">verify</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

<a href="#evotorch.neuroevolution.net.RunningNorm.update" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Update the stored stats with new observation data.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="typing.Iterable">Iterable</span>, <a class="autorefs autorefs-internal" title="RunningNorm (evotorch.neuroevolution.net.runningnorm.RunningNorm)" href="runningnorm/#evotorch.neuroevolution.net.runningnorm.RunningNorm">RunningNorm</a>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The new observation(s), as a PyTorch tensor, or any Iterable
that can be converted to a PyTorch tensor, or another
RunningNorm instance.
If given as a tensor or as an Iterable, the shape of <code>x</code> can
be the same with observation shape, or it can be augmented
with an extra leftmost dimension.
In the case of augmented dimension, <code>x</code> is interpreted not as
a single observation, but as a batch of observations.
If <code>x</code> is another RunningNorm instance, the stats stored by
this RunningNorm instance will be updated with all the data
stored by <code>x</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.Iterable">Iterable</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Can be given as a 1-dimensional Iterable of booleans ONLY
if <code>x</code> represents a batch of observations.
If a <code>mask</code> is provided, the i-th observation within the
observation batch <code>x</code> will be taken into account only if
the i-th item of the <code>mask</code> is True.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>verify</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether or not to verify the shape of the given Iterable
objects. The default is True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/runningnorm.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-228">228</a></span>
<span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span>
<span class="normal"><a href="#__codelineno-0-255">255</a></span>
<span class="normal"><a href="#__codelineno-0-256">256</a></span>
<span class="normal"><a href="#__codelineno-0-257">257</a></span>
<span class="normal"><a href="#__codelineno-0-258">258</a></span>
<span class="normal"><a href="#__codelineno-0-259">259</a></span>
<span class="normal"><a href="#__codelineno-0-260">260</a></span>
<span class="normal"><a href="#__codelineno-0-261">261</a></span>
<span class="normal"><a href="#__codelineno-0-262">262</a></span>
<span class="normal"><a href="#__codelineno-0-263">263</a></span>
<span class="normal"><a href="#__codelineno-0-264">264</a></span>
<span class="normal"><a href="#__codelineno-0-265">265</a></span>
<span class="normal"><a href="#__codelineno-0-266">266</a></span>
<span class="normal"><a href="#__codelineno-0-267">267</a></span>
<span class="normal"><a href="#__codelineno-0-268">268</a></span>
<span class="normal"><a href="#__codelineno-0-269">269</a></span>
<span class="normal"><a href="#__codelineno-0-270">270</a></span>
<span class="normal"><a href="#__codelineno-0-271">271</a></span>
<span class="normal"><a href="#__codelineno-0-272">272</a></span>
<span class="normal"><a href="#__codelineno-0-273">273</a></span>
<span class="normal"><a href="#__codelineno-0-274">274</a></span>
<span class="normal"><a href="#__codelineno-0-275">275</a></span>
<span class="normal"><a href="#__codelineno-0-276">276</a></span>
<span class="normal"><a href="#__codelineno-0-277">277</a></span>
<span class="normal"><a href="#__codelineno-0-278">278</a></span>
<span class="normal"><a href="#__codelineno-0-279">279</a></span>
<span class="normal"><a href="#__codelineno-0-280">280</a></span>
<span class="normal"><a href="#__codelineno-0-281">281</a></span>
<span class="normal"><a href="#__codelineno-0-282">282</a></span>
<span class="normal"><a href="#__codelineno-0-283">283</a></span>
<span class="normal"><a href="#__codelineno-0-284">284</a></span>
<span class="normal"><a href="#__codelineno-0-285">285</a></span>
<span class="normal"><a href="#__codelineno-0-286">286</a></span>
<span class="normal"><a href="#__codelineno-0-287">287</a></span>
<span class="normal"><a href="#__codelineno-0-288">288</a></span>
<span class="normal"><a href="#__codelineno-0-289">289</a></span>
<span class="normal"><a href="#__codelineno-0-290">290</a></span>
<span class="normal"><a href="#__codelineno-0-291">291</a></span>
<span class="normal"><a href="#__codelineno-0-292">292</a></span>
<span class="normal"><a href="#__codelineno-0-293">293</a></span>
<span class="normal"><a href="#__codelineno-0-294">294</a></span>
<span class="normal"><a href="#__codelineno-0-295">295</a></span>
<span class="normal"><a href="#__codelineno-0-296">296</a></span>
<span class="normal"><a href="#__codelineno-0-297">297</a></span>
<span class="normal"><a href="#__codelineno-0-298">298</a></span>
<span class="normal"><a href="#__codelineno-0-299">299</a></span>
<span class="normal"><a href="#__codelineno-0-300">300</a></span>
<span class="normal"><a href="#__codelineno-0-301">301</a></span>
<span class="normal"><a href="#__codelineno-0-302">302</a></span>
<span class="normal"><a href="#__codelineno-0-303">303</a></span>
<span class="normal"><a href="#__codelineno-0-304">304</a></span>
<span class="normal"><a href="#__codelineno-0-305">305</a></span>
<span class="normal"><a href="#__codelineno-0-306">306</a></span>
<span class="normal"><a href="#__codelineno-0-307">307</a></span>
<span class="normal"><a href="#__codelineno-0-308">308</a></span>
<span class="normal"><a href="#__codelineno-0-309">309</a></span>
<span class="normal"><a href="#__codelineno-0-310">310</a></span>
<span class="normal"><a href="#__codelineno-0-311">311</a></span>
<span class="normal"><a href="#__codelineno-0-312">312</a></span>
<span class="normal"><a href="#__codelineno-0-313">313</a></span>
<span class="normal"><a href="#__codelineno-0-314">314</a></span>
<span class="normal"><a href="#__codelineno-0-315">315</a></span>
<span class="normal"><a href="#__codelineno-0-316">316</a></span>
<span class="normal"><a href="#__codelineno-0-317">317</a></span>
<span class="normal"><a href="#__codelineno-0-318">318</a></span>
<span class="normal"><a href="#__codelineno-0-319">319</a></span>
<span class="normal"><a href="#__codelineno-0-320">320</a></span>
<span class="normal"><a href="#__codelineno-0-321">321</a></span>
<span class="normal"><a href="#__codelineno-0-322">322</a></span>
<span class="normal"><a href="#__codelineno-0-323">323</a></span>
<span class="normal"><a href="#__codelineno-0-324">324</a></span>
<span class="normal"><a href="#__codelineno-0-325">325</a></span>
<span class="normal"><a href="#__codelineno-0-326">326</a></span>
<span class="normal"><a href="#__codelineno-0-327">327</a></span>
<span class="normal"><a href="#__codelineno-0-328">328</a></span>
<span class="normal"><a href="#__codelineno-0-329">329</a></span>
<span class="normal"><a href="#__codelineno-0-330">330</a></span>
<span class="normal"><a href="#__codelineno-0-331">331</a></span>
<span class="normal"><a href="#__codelineno-0-332">332</a></span>
<span class="normal"><a href="#__codelineno-0-333">333</a></span>
<span class="normal"><a href="#__codelineno-0-334">334</a></span>
<span class="normal"><a href="#__codelineno-0-335">335</a></span>
<span class="normal"><a href="#__codelineno-0-336">336</a></span>
<span class="normal"><a href="#__codelineno-0-337">337</a></span>
<span class="normal"><a href="#__codelineno-0-338">338</a></span>
<span class="normal"><a href="#__codelineno-0-339">339</a></span>
<span class="normal"><a href="#__codelineno-0-340">340</a></span>
<span class="normal"><a href="#__codelineno-0-341">341</a></span>
<span class="normal"><a href="#__codelineno-0-342">342</a></span>
<span class="normal"><a href="#__codelineno-0-343">343</a></span>
<span class="normal"><a href="#__codelineno-0-344">344</a></span>
<span class="normal"><a href="#__codelineno-0-345">345</a></span>
<span class="normal"><a href="#__codelineno-0-346">346</a></span>
<span class="normal"><a href="#__codelineno-0-347">347</a></span>
<span class="normal"><a href="#__codelineno-0-348">348</a></span>
<span class="normal"><a href="#__codelineno-0-349">349</a></span>
<span class="normal"><a href="#__codelineno-0-350">350</a></span>
<span class="normal"><a href="#__codelineno-0-351">351</a></span>
<span class="normal"><a href="#__codelineno-0-352">352</a></span>
<span class="normal"><a href="#__codelineno-0-353">353</a></span>
<span class="normal"><a href="#__codelineno-0-354">354</a></span>
<span class="normal"><a href="#__codelineno-0-355">355</a></span>
<span class="normal"><a href="#__codelineno-0-356">356</a></span>
<span class="normal"><a href="#__codelineno-0-357">357</a></span>
<span class="normal"><a href="#__codelineno-0-358">358</a></span>
<span class="normal"><a href="#__codelineno-0-359">359</a></span>
<span class="normal"><a href="#__codelineno-0-360">360</a></span>
<span class="normal"><a href="#__codelineno-0-361">361</a></span>
<span class="normal"><a href="#__codelineno-0-362">362</a></span>
<span class="normal"><a href="#__codelineno-0-363">363</a></span>
<span class="normal"><a href="#__codelineno-0-364">364</a></span>
<span class="normal"><a href="#__codelineno-0-365">365</a></span>
<span class="normal"><a href="#__codelineno-0-366">366</a></span>
<span class="normal"><a href="#__codelineno-0-367">367</a></span>
<span class="normal"><a href="#__codelineno-0-368">368</a></span>
<span class="normal"><a href="#__codelineno-0-369">369</a></span>
<span class="normal"><a href="#__codelineno-0-370">370</a></span>
<span class="normal"><a href="#__codelineno-0-371">371</a></span>
<span class="normal"><a href="#__codelineno-0-372">372</a></span>
<span class="normal"><a href="#__codelineno-0-373">373</a></span>
<span class="normal"><a href="#__codelineno-0-374">374</a></span>
<span class="normal"><a href="#__codelineno-0-375">375</a></span>
<span class="normal"><a href="#__codelineno-0-376">376</a></span>
<span class="normal"><a href="#__codelineno-0-377">377</a></span>
<span class="normal"><a href="#__codelineno-0-378">378</a></span>
<span class="normal"><a href="#__codelineno-0-379">379</a></span>
<span class="normal"><a href="#__codelineno-0-380">380</a></span>
<span class="normal"><a href="#__codelineno-0-381">381</a></span>
<span class="normal"><a href="#__codelineno-0-382">382</a></span>
<span class="normal"><a href="#__codelineno-0-383">383</a></span>
<span class="normal"><a href="#__codelineno-0-384">384</a></span>
<span class="normal"><a href="#__codelineno-0-385">385</a></span>
<span class="normal"><a href="#__codelineno-0-386">386</a></span>
<span class="normal"><a href="#__codelineno-0-387">387</a></span>
<span class="normal"><a href="#__codelineno-0-388">388</a></span>
<span class="normal"><a href="#__codelineno-0-389">389</a></span>
<span class="normal"><a href="#__codelineno-0-390">390</a></span>
<span class="normal"><a href="#__codelineno-0-391">391</a></span>
<span class="normal"><a href="#__codelineno-0-392">392</a></span>
<span class="normal"><a href="#__codelineno-0-393">393</a></span>
<span class="normal"><a href="#__codelineno-0-394">394</a></span>
<span class="normal"><a href="#__codelineno-0-395">395</a></span>
<span class="normal"><a href="#__codelineno-0-396">396</a></span>
<span class="normal"><a href="#__codelineno-0-397">397</a></span>
<span class="normal"><a href="#__codelineno-0-398">398</a></span>
<span class="normal"><a href="#__codelineno-0-399">399</a></span>
<span class="normal"><a href="#__codelineno-0-400">400</a></span>
<span class="normal"><a href="#__codelineno-0-401">401</a></span>
<span class="normal"><a href="#__codelineno-0-402">402</a></span>
<span class="normal"><a href="#__codelineno-0-403">403</a></span>
<span class="normal"><a href="#__codelineno-0-404">404</a></span>
<span class="normal"><a href="#__codelineno-0-405">405</a></span>
<span class="normal"><a href="#__codelineno-0-406">406</a></span>
<span class="normal"><a href="#__codelineno-0-407">407</a></span>
<span class="normal"><a href="#__codelineno-0-408">408</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-228" name="__codelineno-0-228"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<a id="__codelineno-0-229" name="__codelineno-0-229"></a><span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Iterable</span><span class="p">,</span> <span class="s2">&quot;RunningNorm&quot;</span><span class="p">],</span> <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Iterable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">verify</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
<a id="__codelineno-0-230" name="__codelineno-0-230"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-231" name="__codelineno-0-231"></a><span class="sd">    Update the stored stats with new observation data.</span>
<a id="__codelineno-0-232" name="__codelineno-0-232"></a>
<a id="__codelineno-0-233" name="__codelineno-0-233"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-234" name="__codelineno-0-234"></a><span class="sd">        x: The new observation(s), as a PyTorch tensor, or any Iterable</span>
<a id="__codelineno-0-235" name="__codelineno-0-235"></a><span class="sd">            that can be converted to a PyTorch tensor, or another</span>
<a id="__codelineno-0-236" name="__codelineno-0-236"></a><span class="sd">            RunningNorm instance.</span>
<a id="__codelineno-0-237" name="__codelineno-0-237"></a><span class="sd">            If given as a tensor or as an Iterable, the shape of `x` can</span>
<a id="__codelineno-0-238" name="__codelineno-0-238"></a><span class="sd">            be the same with observation shape, or it can be augmented</span>
<a id="__codelineno-0-239" name="__codelineno-0-239"></a><span class="sd">            with an extra leftmost dimension.</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a><span class="sd">            In the case of augmented dimension, `x` is interpreted not as</span>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a><span class="sd">            a single observation, but as a batch of observations.</span>
<a id="__codelineno-0-242" name="__codelineno-0-242"></a><span class="sd">            If `x` is another RunningNorm instance, the stats stored by</span>
<a id="__codelineno-0-243" name="__codelineno-0-243"></a><span class="sd">            this RunningNorm instance will be updated with all the data</span>
<a id="__codelineno-0-244" name="__codelineno-0-244"></a><span class="sd">            stored by `x`.</span>
<a id="__codelineno-0-245" name="__codelineno-0-245"></a><span class="sd">        mask: Can be given as a 1-dimensional Iterable of booleans ONLY</span>
<a id="__codelineno-0-246" name="__codelineno-0-246"></a><span class="sd">            if `x` represents a batch of observations.</span>
<a id="__codelineno-0-247" name="__codelineno-0-247"></a><span class="sd">            If a `mask` is provided, the i-th observation within the</span>
<a id="__codelineno-0-248" name="__codelineno-0-248"></a><span class="sd">            observation batch `x` will be taken into account only if</span>
<a id="__codelineno-0-249" name="__codelineno-0-249"></a><span class="sd">            the i-th item of the `mask` is True.</span>
<a id="__codelineno-0-250" name="__codelineno-0-250"></a><span class="sd">        verify: Whether or not to verify the shape of the given Iterable</span>
<a id="__codelineno-0-251" name="__codelineno-0-251"></a><span class="sd">            objects. The default is True.</span>
<a id="__codelineno-0-252" name="__codelineno-0-252"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-253" name="__codelineno-0-253"></a>    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">RunningNorm</span><span class="p">):</span>
<a id="__codelineno-0-254" name="__codelineno-0-254"></a>        <span class="c1"># If we are to update our stats according to another RunningNorm instance</span>
<a id="__codelineno-0-255" name="__codelineno-0-255"></a>
<a id="__codelineno-0-256" name="__codelineno-0-256"></a>        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">_count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-257" name="__codelineno-0-257"></a>            <span class="c1"># We bother only if x is non-empty</span>
<a id="__codelineno-0-258" name="__codelineno-0-258"></a>
<a id="__codelineno-0-259" name="__codelineno-0-259"></a>            <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-260" name="__codelineno-0-260"></a>                <span class="c1"># We were given another RunningNorm, not a batch of observations.</span>
<a id="__codelineno-0-261" name="__codelineno-0-261"></a>                <span class="c1"># So, we do not expect to receive a mask tensor.</span>
<a id="__codelineno-0-262" name="__codelineno-0-262"></a>                <span class="c1"># If a mask was provided, then this is an unexpected way of calling this function.</span>
<a id="__codelineno-0-263" name="__codelineno-0-263"></a>                <span class="c1"># We therefore raise an error.</span>
<a id="__codelineno-0-264" name="__codelineno-0-264"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-265" name="__codelineno-0-265"></a>                    <span class="s2">&quot;The `mask` argument is expected as None if the first argument is a RunningNorm.&quot;</span>
<a id="__codelineno-0-266" name="__codelineno-0-266"></a>                    <span class="s2">&quot; However, `mask` is found as something other than None.&quot;</span>
<a id="__codelineno-0-267" name="__codelineno-0-267"></a>                <span class="p">)</span>
<a id="__codelineno-0-268" name="__codelineno-0-268"></a>
<a id="__codelineno-0-269" name="__codelineno-0-269"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">!=</span> <span class="n">x</span><span class="o">.</span><span class="n">_shape</span><span class="p">:</span>
<a id="__codelineno-0-270" name="__codelineno-0-270"></a>                <span class="c1"># If the shapes of this RunningNorm and of the other RunningNorm</span>
<a id="__codelineno-0-271" name="__codelineno-0-271"></a>                <span class="c1"># do not match, then we cannot use `x` for updating our stats.</span>
<a id="__codelineno-0-272" name="__codelineno-0-272"></a>                <span class="c1"># It might be the case that `x` was initialized for another</span>
<a id="__codelineno-0-273" name="__codelineno-0-273"></a>                <span class="c1"># task, with differently sized observations.</span>
<a id="__codelineno-0-274" name="__codelineno-0-274"></a>                <span class="c1"># We therefore raise an error.</span>
<a id="__codelineno-0-275" name="__codelineno-0-275"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-276" name="__codelineno-0-276"></a>                    <span class="sa">f</span><span class="s2">&quot;The RunningNorm to be updated has the shape </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="si">}</span><span class="s2">&quot;</span>
<a id="__codelineno-0-277" name="__codelineno-0-277"></a>                    <span class="sa">f</span><span class="s2">&quot; The other RunningNorm has the shape </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="si">}</span><span class="s2">&quot;</span>
<a id="__codelineno-0-278" name="__codelineno-0-278"></a>                    <span class="sa">f</span><span class="s2">&quot; These shapes are incompatible.&quot;</span>
<a id="__codelineno-0-279" name="__codelineno-0-279"></a>                <span class="p">)</span>
<a id="__codelineno-0-280" name="__codelineno-0-280"></a>
<a id="__codelineno-0-281" name="__codelineno-0-281"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_no_data</span><span class="p">():</span>
<a id="__codelineno-0-282" name="__codelineno-0-282"></a>                <span class="c1"># If this RunningNorm has no data at all, then we clone the</span>
<a id="__codelineno-0-283" name="__codelineno-0-283"></a>                <span class="c1"># data of x.</span>
<a id="__codelineno-0-284" name="__codelineno-0-284"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_sum</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_like_its_own</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">_sum</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
<a id="__codelineno-0-285" name="__codelineno-0-285"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_sum_of_squares</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_like_its_own</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">_sum_of_squares</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
<a id="__codelineno-0-286" name="__codelineno-0-286"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_count</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">_count</span>
<a id="__codelineno-0-287" name="__codelineno-0-287"></a>            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_data</span><span class="p">():</span>
<a id="__codelineno-0-288" name="__codelineno-0-288"></a>                <span class="c1"># If this RunningNorm has its own data, then we update the</span>
<a id="__codelineno-0-289" name="__codelineno-0-289"></a>                <span class="c1"># stored data with the data stored by x.</span>
<a id="__codelineno-0-290" name="__codelineno-0-290"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_sum</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_like_its_own</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">_sum</span><span class="p">)</span>
<a id="__codelineno-0-291" name="__codelineno-0-291"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_sum_of_squares</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_like_its_own</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">_sum_of_squares</span><span class="p">)</span>
<a id="__codelineno-0-292" name="__codelineno-0-292"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_count</span> <span class="o">+=</span> <span class="n">x</span><span class="o">.</span><span class="n">_count</span>
<a id="__codelineno-0-293" name="__codelineno-0-293"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-294" name="__codelineno-0-294"></a>                <span class="k">assert</span> <span class="kc">False</span><span class="p">,</span> <span class="s2">&quot;RunningNorm is in an invalid state! This might be a bug.&quot;</span>
<a id="__codelineno-0-295" name="__codelineno-0-295"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-296" name="__codelineno-0-296"></a>        <span class="c1"># This is the case where the received argument x is not a</span>
<a id="__codelineno-0-297" name="__codelineno-0-297"></a>        <span class="c1"># RunningNorm object, but an Iterable.</span>
<a id="__codelineno-0-298" name="__codelineno-0-298"></a>
<a id="__codelineno-0-299" name="__codelineno-0-299"></a>        <span class="k">if</span> <span class="n">verify</span><span class="p">:</span>
<a id="__codelineno-0-300" name="__codelineno-0-300"></a>            <span class="c1"># If we have the `verify` flag, then we make sure that</span>
<a id="__codelineno-0-301" name="__codelineno-0-301"></a>            <span class="c1"># x is a tensor of the correct shape</span>
<a id="__codelineno-0-302" name="__codelineno-0-302"></a>            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_verify</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-303" name="__codelineno-0-303"></a>
<a id="__codelineno-0-304" name="__codelineno-0-304"></a>        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ndim</span><span class="p">:</span>
<a id="__codelineno-0-305" name="__codelineno-0-305"></a>            <span class="c1"># If the shape of x is exactly the same with the observation shape</span>
<a id="__codelineno-0-306" name="__codelineno-0-306"></a>            <span class="c1"># then we assume that x represents a single observation, and not a</span>
<a id="__codelineno-0-307" name="__codelineno-0-307"></a>            <span class="c1"># batch of observations.</span>
<a id="__codelineno-0-308" name="__codelineno-0-308"></a>
<a id="__codelineno-0-309" name="__codelineno-0-309"></a>            <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-310" name="__codelineno-0-310"></a>                <span class="c1"># Since we are dealing with a single observation,</span>
<a id="__codelineno-0-311" name="__codelineno-0-311"></a>                <span class="c1"># we do not expect to receive a mask argument.</span>
<a id="__codelineno-0-312" name="__codelineno-0-312"></a>                <span class="c1"># If the mask argument was provided, then this is an unexpected</span>
<a id="__codelineno-0-313" name="__codelineno-0-313"></a>                <span class="c1"># usage of this function.</span>
<a id="__codelineno-0-314" name="__codelineno-0-314"></a>                <span class="c1"># We therefore raise an error.</span>
<a id="__codelineno-0-315" name="__codelineno-0-315"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-316" name="__codelineno-0-316"></a>                    <span class="s2">&quot;The `mask` argument is expected as None if the first argument is a single observation&quot;</span>
<a id="__codelineno-0-317" name="__codelineno-0-317"></a>                    <span class="s2">&quot; (i.e. not a batch of observations, with an extra leftmost dimension).&quot;</span>
<a id="__codelineno-0-318" name="__codelineno-0-318"></a>                    <span class="s2">&quot; However, `mask` is found as something other than None.&quot;</span>
<a id="__codelineno-0-319" name="__codelineno-0-319"></a>                <span class="p">)</span>
<a id="__codelineno-0-320" name="__codelineno-0-320"></a>
<a id="__codelineno-0-321" name="__codelineno-0-321"></a>            <span class="c1"># Since x is a single observation,</span>
<a id="__codelineno-0-322" name="__codelineno-0-322"></a>            <span class="c1"># the sum of observations extracted from x is x itself,</span>
<a id="__codelineno-0-323" name="__codelineno-0-323"></a>            <span class="c1"># and the sum of squared observations extracted from x is</span>
<a id="__codelineno-0-324" name="__codelineno-0-324"></a>            <span class="c1"># the square of x itself.</span>
<a id="__codelineno-0-325" name="__codelineno-0-325"></a>            <span class="n">sum_of_x</span> <span class="o">=</span> <span class="n">x</span>
<a id="__codelineno-0-326" name="__codelineno-0-326"></a>            <span class="n">sum_of_x_squared</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">square</span><span class="p">()</span>
<a id="__codelineno-0-327" name="__codelineno-0-327"></a>            <span class="c1"># We extracted a single observation from x</span>
<a id="__codelineno-0-328" name="__codelineno-0-328"></a>            <span class="n">n</span> <span class="o">=</span> <span class="mi">1</span>
<a id="__codelineno-0-329" name="__codelineno-0-329"></a>        <span class="k">elif</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ndim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
<a id="__codelineno-0-330" name="__codelineno-0-330"></a>            <span class="c1"># If the number of dimensions of x is one more than the number</span>
<a id="__codelineno-0-331" name="__codelineno-0-331"></a>            <span class="c1"># of dimensions of this RunningNorm, then we assume that x is a batch</span>
<a id="__codelineno-0-332" name="__codelineno-0-332"></a>            <span class="c1"># of observations.</span>
<a id="__codelineno-0-333" name="__codelineno-0-333"></a>
<a id="__codelineno-0-334" name="__codelineno-0-334"></a>            <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-335" name="__codelineno-0-335"></a>                <span class="c1"># If a mask is provided, then we first make sure that it is a tensor</span>
<a id="__codelineno-0-336" name="__codelineno-0-336"></a>                <span class="c1"># of dtype bool in the correct device.</span>
<a id="__codelineno-0-337" name="__codelineno-0-337"></a>                <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
<a id="__codelineno-0-338" name="__codelineno-0-338"></a>
<a id="__codelineno-0-339" name="__codelineno-0-339"></a>                <span class="k">if</span> <span class="n">mask</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
<a id="__codelineno-0-340" name="__codelineno-0-340"></a>                    <span class="c1"># We expect the mask to be 1-dimensional.</span>
<a id="__codelineno-0-341" name="__codelineno-0-341"></a>                    <span class="c1"># If not, we raise an error.</span>
<a id="__codelineno-0-342" name="__codelineno-0-342"></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-343" name="__codelineno-0-343"></a>                        <span class="sa">f</span><span class="s2">&quot;The `mask` tensor was expected as a 1-dimensional tensor.&quot;</span>
<a id="__codelineno-0-344" name="__codelineno-0-344"></a>                        <span class="sa">f</span><span class="s2">&quot; However, its shape is </span><span class="si">{</span><span class="n">mask</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span>
<a id="__codelineno-0-345" name="__codelineno-0-345"></a>                    <span class="p">)</span>
<a id="__codelineno-0-346" name="__codelineno-0-346"></a>
<a id="__codelineno-0-347" name="__codelineno-0-347"></a>                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span> <span class="o">!=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
<a id="__codelineno-0-348" name="__codelineno-0-348"></a>                    <span class="c1"># If the length of the mask is not the batch size of x,</span>
<a id="__codelineno-0-349" name="__codelineno-0-349"></a>                    <span class="c1"># then there is a mismatch.</span>
<a id="__codelineno-0-350" name="__codelineno-0-350"></a>                    <span class="c1"># We therefore raise an error.</span>
<a id="__codelineno-0-351" name="__codelineno-0-351"></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-352" name="__codelineno-0-352"></a>                        <span class="sa">f</span><span class="s2">&quot;The shape of the given tensor is </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span>
<a id="__codelineno-0-353" name="__codelineno-0-353"></a>                        <span class="sa">f</span><span class="s2">&quot; Therefore, the batch size of observations is </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span>
<a id="__codelineno-0-354" name="__codelineno-0-354"></a>                        <span class="sa">f</span><span class="s2">&quot; However, the given `mask` tensor does not has an incompatible length: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
<a id="__codelineno-0-355" name="__codelineno-0-355"></a>                    <span class="p">)</span>
<a id="__codelineno-0-356" name="__codelineno-0-356"></a>
<a id="__codelineno-0-357" name="__codelineno-0-357"></a>                <span class="c1"># We compute how many True items we have in the mask.</span>
<a id="__codelineno-0-358" name="__codelineno-0-358"></a>                <span class="c1"># This integer gives us how many observations we extract from x.</span>
<a id="__codelineno-0-359" name="__codelineno-0-359"></a>                <span class="n">n</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)))</span>
<a id="__codelineno-0-360" name="__codelineno-0-360"></a>
<a id="__codelineno-0-361" name="__codelineno-0-361"></a>                <span class="c1"># We now re-cast the mask as the observation dtype (so that True items turn to 1.0</span>
<a id="__codelineno-0-362" name="__codelineno-0-362"></a>                <span class="c1"># and False items turn to 0.0), and then increase its number of dimensions so that</span>
<a id="__codelineno-0-363" name="__codelineno-0-363"></a>                <span class="c1"># it can operate directly with x.</span>
<a id="__codelineno-0-364" name="__codelineno-0-364"></a>                <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_like_its_own</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">+</span> <span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))))</span>
<a id="__codelineno-0-365" name="__codelineno-0-365"></a>
<a id="__codelineno-0-366" name="__codelineno-0-366"></a>                <span class="c1"># Finally, we multiply x with the mask. This means that the observations with corresponding</span>
<a id="__codelineno-0-367" name="__codelineno-0-367"></a>                <span class="c1"># mask values as False are zeroed out.</span>
<a id="__codelineno-0-368" name="__codelineno-0-368"></a>                <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">mask</span>
<a id="__codelineno-0-369" name="__codelineno-0-369"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-370" name="__codelineno-0-370"></a>                <span class="c1"># This is the case where we did not receive a mask.</span>
<a id="__codelineno-0-371" name="__codelineno-0-371"></a>                <span class="c1"># We can simply say that the number of observations to extract from x</span>
<a id="__codelineno-0-372" name="__codelineno-0-372"></a>                <span class="c1"># is the size of its leftmost dimension, i.e. the batch size.</span>
<a id="__codelineno-0-373" name="__codelineno-0-373"></a>                <span class="n">n</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-374" name="__codelineno-0-374"></a>
<a id="__codelineno-0-375" name="__codelineno-0-375"></a>            <span class="c1"># With or without a mask, we are now ready to extract the sum and sum of squares</span>
<a id="__codelineno-0-376" name="__codelineno-0-376"></a>            <span class="c1"># from x.</span>
<a id="__codelineno-0-377" name="__codelineno-0-377"></a>            <span class="n">sum_of_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-378" name="__codelineno-0-378"></a>            <span class="n">sum_of_x_squared</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">square</span><span class="p">(),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-379" name="__codelineno-0-379"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-380" name="__codelineno-0-380"></a>            <span class="c1"># This is the case where the number of dimensions of x is unrecognized.</span>
<a id="__codelineno-0-381" name="__codelineno-0-381"></a>            <span class="c1"># This case is actually already checked by the _verify(...) method earlier.</span>
<a id="__codelineno-0-382" name="__codelineno-0-382"></a>            <span class="c1"># This defensive fallback case is only for when verify=False and it turned out</span>
<a id="__codelineno-0-383" name="__codelineno-0-383"></a>            <span class="c1"># that the ndim is invalid.</span>
<a id="__codelineno-0-384" name="__codelineno-0-384"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid shape: </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<a id="__codelineno-0-385" name="__codelineno-0-385"></a>
<a id="__codelineno-0-386" name="__codelineno-0-386"></a>        <span class="c1"># At this point, we handled all the valid cases regarding the Iterable x,</span>
<a id="__codelineno-0-387" name="__codelineno-0-387"></a>        <span class="c1"># and we have our sum_of_x (sum of all observations), sum_of_squares</span>
<a id="__codelineno-0-388" name="__codelineno-0-388"></a>        <span class="c1"># (sum of all squared observations), and n (number of observations extracted</span>
<a id="__codelineno-0-389" name="__codelineno-0-389"></a>        <span class="c1"># from x).</span>
<a id="__codelineno-0-390" name="__codelineno-0-390"></a>
<a id="__codelineno-0-391" name="__codelineno-0-391"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_no_data</span><span class="p">():</span>
<a id="__codelineno-0-392" name="__codelineno-0-392"></a>            <span class="c1"># If our RunningNorm is empty, the observation data we extracted from x</span>
<a id="__codelineno-0-393" name="__codelineno-0-393"></a>            <span class="c1"># become our RunningNorm&#39;s new data.</span>
<a id="__codelineno-0-394" name="__codelineno-0-394"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_sum</span> <span class="o">=</span> <span class="n">sum_of_x</span>
<a id="__codelineno-0-395" name="__codelineno-0-395"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_sum_of_squares</span> <span class="o">=</span> <span class="n">sum_of_x_squared</span>
<a id="__codelineno-0-396" name="__codelineno-0-396"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_count</span> <span class="o">=</span> <span class="n">n</span>
<a id="__codelineno-0-397" name="__codelineno-0-397"></a>        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_data</span><span class="p">():</span>
<a id="__codelineno-0-398" name="__codelineno-0-398"></a>            <span class="c1"># If our RunningNorm is not empty, the stored data is updated with the</span>
<a id="__codelineno-0-399" name="__codelineno-0-399"></a>            <span class="c1"># data extracted from x.</span>
<a id="__codelineno-0-400" name="__codelineno-0-400"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_sum</span> <span class="o">+=</span> <span class="n">sum_of_x</span>
<a id="__codelineno-0-401" name="__codelineno-0-401"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_sum_of_squares</span> <span class="o">+=</span> <span class="n">sum_of_x_squared</span>
<a id="__codelineno-0-402" name="__codelineno-0-402"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_count</span> <span class="o">+=</span> <span class="n">n</span>
<a id="__codelineno-0-403" name="__codelineno-0-403"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-404" name="__codelineno-0-404"></a>            <span class="c1"># This is an erroneous state where the internal data looks neither</span>
<a id="__codelineno-0-405" name="__codelineno-0-405"></a>            <span class="c1"># existent nor completely empty.</span>
<a id="__codelineno-0-406" name="__codelineno-0-406"></a>            <span class="c1"># This might be the result of a bug, or maybe this instance&#39;s</span>
<a id="__codelineno-0-407" name="__codelineno-0-407"></a>            <span class="c1"># protected variables were tempered with from the outside.</span>
<a id="__codelineno-0-408" name="__codelineno-0-408"></a>            <span class="k">assert</span> <span class="kc">False</span><span class="p">,</span> <span class="s2">&quot;RunningNorm is in an invalid state! This might be a bug.&quot;</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="evotorch.neuroevolution.net.RunningNorm.update_and_normalize" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">update_and_normalize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#evotorch.neuroevolution.net.RunningNorm.update_and_normalize" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Update the observation stats according to x, then normalize x.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="typing.Iterable">Iterable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The observation(s), as a PyTorch tensor, or as an Iterable
which can be converted to a PyTorch tensor.
The shape of x can be the same with the observaiton shape,
or it can be augmented with an extra leftmost dimension
to express a batch of observations.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.Iterable">Iterable</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Can be given as a 1-dimensional Iterable of booleans ONLY
if <code>x</code> represents a batch of observations.
If a <code>mask</code> is provided, the i-th observation within the
observation batch <code>x</code> will be taken into account only if
the the i-th item of the <code>mask</code> is True.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>
        


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/runningnorm.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-534">534</a></span>
<span class="normal"><a href="#__codelineno-0-535">535</a></span>
<span class="normal"><a href="#__codelineno-0-536">536</a></span>
<span class="normal"><a href="#__codelineno-0-537">537</a></span>
<span class="normal"><a href="#__codelineno-0-538">538</a></span>
<span class="normal"><a href="#__codelineno-0-539">539</a></span>
<span class="normal"><a href="#__codelineno-0-540">540</a></span>
<span class="normal"><a href="#__codelineno-0-541">541</a></span>
<span class="normal"><a href="#__codelineno-0-542">542</a></span>
<span class="normal"><a href="#__codelineno-0-543">543</a></span>
<span class="normal"><a href="#__codelineno-0-544">544</a></span>
<span class="normal"><a href="#__codelineno-0-545">545</a></span>
<span class="normal"><a href="#__codelineno-0-546">546</a></span>
<span class="normal"><a href="#__codelineno-0-547">547</a></span>
<span class="normal"><a href="#__codelineno-0-548">548</a></span>
<span class="normal"><a href="#__codelineno-0-549">549</a></span>
<span class="normal"><a href="#__codelineno-0-550">550</a></span>
<span class="normal"><a href="#__codelineno-0-551">551</a></span>
<span class="normal"><a href="#__codelineno-0-552">552</a></span>
<span class="normal"><a href="#__codelineno-0-553">553</a></span>
<span class="normal"><a href="#__codelineno-0-554">554</a></span>
<span class="normal"><a href="#__codelineno-0-555">555</a></span>
<span class="normal"><a href="#__codelineno-0-556">556</a></span>
<span class="normal"><a href="#__codelineno-0-557">557</a></span>
<span class="normal"><a href="#__codelineno-0-558">558</a></span>
<span class="normal"><a href="#__codelineno-0-559">559</a></span>
<span class="normal"><a href="#__codelineno-0-560">560</a></span>
<span class="normal"><a href="#__codelineno-0-561">561</a></span>
<span class="normal"><a href="#__codelineno-0-562">562</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-534" name="__codelineno-0-534"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<a id="__codelineno-0-535" name="__codelineno-0-535"></a><span class="k">def</span><span class="w"> </span><span class="nf">update_and_normalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Iterable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">:</span>
<a id="__codelineno-0-536" name="__codelineno-0-536"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-537" name="__codelineno-0-537"></a><span class="sd">    Update the observation stats according to x, then normalize x.</span>
<a id="__codelineno-0-538" name="__codelineno-0-538"></a>
<a id="__codelineno-0-539" name="__codelineno-0-539"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-540" name="__codelineno-0-540"></a><span class="sd">        x: The observation(s), as a PyTorch tensor, or as an Iterable</span>
<a id="__codelineno-0-541" name="__codelineno-0-541"></a><span class="sd">            which can be converted to a PyTorch tensor.</span>
<a id="__codelineno-0-542" name="__codelineno-0-542"></a><span class="sd">            The shape of x can be the same with the observaiton shape,</span>
<a id="__codelineno-0-543" name="__codelineno-0-543"></a><span class="sd">            or it can be augmented with an extra leftmost dimension</span>
<a id="__codelineno-0-544" name="__codelineno-0-544"></a><span class="sd">            to express a batch of observations.</span>
<a id="__codelineno-0-545" name="__codelineno-0-545"></a><span class="sd">        mask: Can be given as a 1-dimensional Iterable of booleans ONLY</span>
<a id="__codelineno-0-546" name="__codelineno-0-546"></a><span class="sd">            if `x` represents a batch of observations.</span>
<a id="__codelineno-0-547" name="__codelineno-0-547"></a><span class="sd">            If a `mask` is provided, the i-th observation within the</span>
<a id="__codelineno-0-548" name="__codelineno-0-548"></a><span class="sd">            observation batch `x` will be taken into account only if</span>
<a id="__codelineno-0-549" name="__codelineno-0-549"></a><span class="sd">            the the i-th item of the `mask` is True.</span>
<a id="__codelineno-0-550" name="__codelineno-0-550"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-551" name="__codelineno-0-551"></a><span class="sd">        The normalized counterpart of the observation(s) expressed by x.</span>
<a id="__codelineno-0-552" name="__codelineno-0-552"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-553" name="__codelineno-0-553"></a>    <span class="n">result_as_numpy</span> <span class="o">=</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
<a id="__codelineno-0-554" name="__codelineno-0-554"></a>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_verify</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-555" name="__codelineno-0-555"></a>
<a id="__codelineno-0-556" name="__codelineno-0-556"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">verify</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-557" name="__codelineno-0-557"></a>    <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">verify</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-558" name="__codelineno-0-558"></a>
<a id="__codelineno-0-559" name="__codelineno-0-559"></a>    <span class="k">if</span> <span class="n">result_as_numpy</span><span class="p">:</span>
<a id="__codelineno-0-560" name="__codelineno-0-560"></a>        <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<a id="__codelineno-0-561" name="__codelineno-0-561"></a>
<a id="__codelineno-0-562" name="__codelineno-0-562"></a>    <span class="k">return</span> <span class="n">result</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="evotorch.neuroevolution.net.RunningStat" class="doc doc-heading">
            <code>RunningStat</code>


<a href="#evotorch.neuroevolution.net.RunningStat" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">


        <p>Tool for efficiently computing the mean and stdev of arrays.
The arrays themselves are not stored separately,
instead, they are accumulated.</p>
<p>This RunningStat is implemented as a wrapper around RunningNorm.
The difference is that the interface of RunningStat is simplified
to expect only numpy arrays, and expect only non-vectorized
observations.
With this simplified interface, RunningStat is meant to be used
by GymNE, on classical non-vectorized gym tasks.</p>







              <details class="quote">
                <summary>Source code in <code>evotorch/neuroevolution/net/runningstat.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-25"> 25</a></span>
<span class="normal"><a href="#__codelineno-0-26"> 26</a></span>
<span class="normal"><a href="#__codelineno-0-27"> 27</a></span>
<span class="normal"><a href="#__codelineno-0-28"> 28</a></span>
<span class="normal"><a href="#__codelineno-0-29"> 29</a></span>
<span class="normal"><a href="#__codelineno-0-30"> 30</a></span>
<span class="normal"><a href="#__codelineno-0-31"> 31</a></span>
<span class="normal"><a href="#__codelineno-0-32"> 32</a></span>
<span class="normal"><a href="#__codelineno-0-33"> 33</a></span>
<span class="normal"><a href="#__codelineno-0-34"> 34</a></span>
<span class="normal"><a href="#__codelineno-0-35"> 35</a></span>
<span class="normal"><a href="#__codelineno-0-36"> 36</a></span>
<span class="normal"><a href="#__codelineno-0-37"> 37</a></span>
<span class="normal"><a href="#__codelineno-0-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-0-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-0-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-0-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-0-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-0-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-0-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-0-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-0-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="k">class</span><span class="w"> </span><span class="nc">RunningStat</span><span class="p">:</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">    Tool for efficiently computing the mean and stdev of arrays.</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">    The arrays themselves are not stored separately,</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">    instead, they are accumulated.</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">    This RunningStat is implemented as a wrapper around RunningNorm.</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">    The difference is that the interface of RunningStat is simplified</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">    to expect only numpy arrays, and expect only non-vectorized</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">    observations.</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="sd">    With this simplified interface, RunningStat is meant to be used</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">    by GymNE, on classical non-vectorized gym tasks.</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="sd">        `__init__(...)`: Initialize the RunningStat.</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RunningNorm</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="sd">        Reset the RunningStat to its initial state.</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">count</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="sd">        Get the number of arrays accumulated.</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>            <span class="k">return</span> <span class="mi">0</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span><span class="o">.</span><span class="n">count</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">        Get the sum of all accumulated arrays.</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span><span class="o">.</span><span class="n">sum</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">sum_of_squares</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a><span class="sd">        Get the sum of squares of all accumulated arrays.</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span><span class="o">.</span><span class="n">sum_of_squares</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a><span class="sd">        Get the mean of all accumulated arrays.</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">stdev</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a><span class="sd">        Get the standard deviation of all accumulated arrays.</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span><span class="o">.</span><span class="n">stdev</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="s2">&quot;RunningStat&quot;</span><span class="p">]):</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="sd">        Accumulate more data into the RunningStat object.</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">        If the argument is an array, that array is added</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="sd">        as one more data element.</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="sd">        If the argument is another RunningStat instance,</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="sd">        all the stats accumulated by that RunningStat object</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="sd">        are added into this RunningStat object.</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">RunningStat</span><span class="p">):</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>            <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">_rn</span><span class="p">)</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>                <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">_rn</span><span class="p">)</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>                <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span> <span class="o">=</span> <span class="n">RunningNorm</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">normalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">list</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a><span class="sd">        Normalize the array x according to the accumulated stats.</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>            <span class="k">return</span> <span class="n">x</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">__copy__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>        <span class="k">return</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;&lt;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">, count: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">count</span><span class="si">}</span><span class="s2">&gt;&quot;</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="s2">&quot;RunningStat&quot;</span><span class="p">:</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a><span class="sd">        If the target device is cpu, return this RunningStat instance itself.</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="sd">        A RunningStat object is meant to work with numpy arrays. Therefore,</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a><span class="sd">        any device other than the cpu will trigger an error.</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a><span class="sd">            device: The target device. Only cpu is supported.</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a><span class="sd">            The original RunningStat.</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">):</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>            <span class="k">return</span> <span class="bp">self</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>                <span class="sa">f</span><span class="s2">&quot;The received target device is </span><span class="si">{</span><span class="nb">repr</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="si">}</span><span class="s2">. However, RunningStat can only work on a cpu.&quot;</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>            <span class="p">)</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">to_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a><span class="sd">        Make a PyTorch module which normalizes the its inputs.</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a><span class="sd">            An ObsNormLayer instance.</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span><span class="o">.</span><span class="n">to_layer</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="evotorch.neuroevolution.net.RunningStat.count" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">count</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#evotorch.neuroevolution.net.RunningStat.count" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get the number of arrays accumulated.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="evotorch.neuroevolution.net.RunningStat.mean" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mean</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#evotorch.neuroevolution.net.RunningStat.mean" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get the mean of all accumulated arrays.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="evotorch.neuroevolution.net.RunningStat.stdev" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">stdev</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#evotorch.neuroevolution.net.RunningStat.stdev" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get the standard deviation of all accumulated arrays.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="evotorch.neuroevolution.net.RunningStat.sum" class="doc doc-heading">
            <code class="highlight language-python"><span class="nb">sum</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#evotorch.neuroevolution.net.RunningStat.sum" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get the sum of all accumulated arrays.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="evotorch.neuroevolution.net.RunningStat.sum_of_squares" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sum_of_squares</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#evotorch.neuroevolution.net.RunningStat.sum_of_squares" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get the sum of squares of all accumulated arrays.</p>

    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="evotorch.neuroevolution.net.RunningStat.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">()</span></code>

<a href="#evotorch.neuroevolution.net.RunningStat.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p><code>__init__(...)</code>: Initialize the RunningStat.</p>


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/runningstat.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span>
<span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-39" name="__codelineno-0-39"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="sd">    `__init__(...)`: Initialize the RunningStat.</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RunningNorm</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="evotorch.neuroevolution.net.RunningStat.normalize" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

<a href="#evotorch.neuroevolution.net.RunningStat.normalize" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Normalize the array x according to the accumulated stats.</p>


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/runningstat.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-111" name="__codelineno-0-111"></a><span class="k">def</span><span class="w"> </span><span class="nf">normalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">list</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a><span class="sd">    Normalize the array x according to the accumulated stats.</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>        <span class="k">return</span> <span class="n">x</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="evotorch.neuroevolution.net.RunningStat.reset" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">reset</span><span class="p">()</span></code>

<a href="#evotorch.neuroevolution.net.RunningStat.reset" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Reset the RunningStat to its initial state.</p>


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/runningstat.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="sd">    Reset the RunningStat to its initial state.</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="evotorch.neuroevolution.net.RunningStat.to" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></code>

<a href="#evotorch.neuroevolution.net.RunningStat.to" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>If the target device is cpu, return this RunningStat instance itself.
A RunningStat object is meant to work with numpy arrays. Therefore,
any device other than the cpu will trigger an error.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="torch.device">device</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The target device. Only cpu is supported.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>
        


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/runningstat.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-127" name="__codelineno-0-127"></a><span class="k">def</span><span class="w"> </span><span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="s2">&quot;RunningStat&quot;</span><span class="p">:</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a><span class="sd">    If the target device is cpu, return this RunningStat instance itself.</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="sd">    A RunningStat object is meant to work with numpy arrays. Therefore,</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a><span class="sd">    any device other than the cpu will trigger an error.</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a><span class="sd">        device: The target device. Only cpu is supported.</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a><span class="sd">        The original RunningStat.</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">):</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>        <span class="k">return</span> <span class="bp">self</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>            <span class="sa">f</span><span class="s2">&quot;The received target device is </span><span class="si">{</span><span class="nb">repr</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="si">}</span><span class="s2">. However, RunningStat can only work on a cpu.&quot;</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="evotorch.neuroevolution.net.RunningStat.to_layer" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">to_layer</span><span class="p">()</span></code>

<a href="#evotorch.neuroevolution.net.RunningStat.to_layer" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Make a PyTorch module which normalizes the its inputs.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.nn.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>An ObsNormLayer instance.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/runningstat.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-145" name="__codelineno-0-145"></a><span class="k">def</span><span class="w"> </span><span class="nf">to_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a><span class="sd">    Make a PyTorch module which normalizes the its inputs.</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a><span class="sd">        An ObsNormLayer instance.</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span><span class="o">.</span><span class="n">to_layer</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="evotorch.neuroevolution.net.RunningStat.update" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">update</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

<a href="#evotorch.neuroevolution.net.RunningStat.update" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Accumulate more data into the RunningStat object.
If the argument is an array, that array is added
as one more data element.
If the argument is another RunningStat instance,
all the stats accumulated by that RunningStat object
are added into this RunningStat object.</p>


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/runningstat.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-90" name="__codelineno-0-90"></a><span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="s2">&quot;RunningStat&quot;</span><span class="p">]):</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="sd">    Accumulate more data into the RunningStat object.</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">    If the argument is an array, that array is added</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="sd">    as one more data element.</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="sd">    If the argument is another RunningStat instance,</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="sd">    all the stats accumulated by that RunningStat object</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="sd">    are added into this RunningStat object.</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">RunningStat</span><span class="p">):</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">_rn</span><span class="p">)</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">_rn</span><span class="p">)</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span> <span class="o">=</span> <span class="n">RunningNorm</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_rn</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="evotorch.neuroevolution.net.StatefulModule" class="doc doc-heading">
            <code>StatefulModule</code>


<a href="#evotorch.neuroevolution.net.StatefulModule" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


        <p>A wrapper that provides a stateful interface for recurrent torch modules.</p>
<p>If the torch module to be wrapped is non-recurrent and its forward method
has a single input (the input tensor) and a single output (the output
tensor), then this wrapper module acts as a no-op wrapper.</p>
<p>If the torch module to be wrapped is recurrent and its forward method has
two inputs (the input tensor and an optional second argument for the hidden
state) and two outputs (the output tensor and the new hidden state), then
this wrapper brings a new forward-passing interface. In this new interface,
the forward method has a single input (the input tensor) and a single
output (the output tensor). The hidden states, instead of being
explicitly requested via a second argument and returned as a second
result, are stored and used by the wrapper.
When a new series of inputs is to be used, one has to call the <code>reset()</code>
method of this wrapper.</p>







              <details class="quote">
                <summary>Source code in <code>evotorch/neuroevolution/net/statefulmodule.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-21">21</a></span>
<span class="normal"><a href="#__codelineno-0-22">22</a></span>
<span class="normal"><a href="#__codelineno-0-23">23</a></span>
<span class="normal"><a href="#__codelineno-0-24">24</a></span>
<span class="normal"><a href="#__codelineno-0-25">25</a></span>
<span class="normal"><a href="#__codelineno-0-26">26</a></span>
<span class="normal"><a href="#__codelineno-0-27">27</a></span>
<span class="normal"><a href="#__codelineno-0-28">28</a></span>
<span class="normal"><a href="#__codelineno-0-29">29</a></span>
<span class="normal"><a href="#__codelineno-0-30">30</a></span>
<span class="normal"><a href="#__codelineno-0-31">31</a></span>
<span class="normal"><a href="#__codelineno-0-32">32</a></span>
<span class="normal"><a href="#__codelineno-0-33">33</a></span>
<span class="normal"><a href="#__codelineno-0-34">34</a></span>
<span class="normal"><a href="#__codelineno-0-35">35</a></span>
<span class="normal"><a href="#__codelineno-0-36">36</a></span>
<span class="normal"><a href="#__codelineno-0-37">37</a></span>
<span class="normal"><a href="#__codelineno-0-38">38</a></span>
<span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span>
<span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span>
<span class="normal"><a href="#__codelineno-0-55">55</a></span>
<span class="normal"><a href="#__codelineno-0-56">56</a></span>
<span class="normal"><a href="#__codelineno-0-57">57</a></span>
<span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span>
<span class="normal"><a href="#__codelineno-0-66">66</a></span>
<span class="normal"><a href="#__codelineno-0-67">67</a></span>
<span class="normal"><a href="#__codelineno-0-68">68</a></span>
<span class="normal"><a href="#__codelineno-0-69">69</a></span>
<span class="normal"><a href="#__codelineno-0-70">70</a></span>
<span class="normal"><a href="#__codelineno-0-71">71</a></span>
<span class="normal"><a href="#__codelineno-0-72">72</a></span>
<span class="normal"><a href="#__codelineno-0-73">73</a></span>
<span class="normal"><a href="#__codelineno-0-74">74</a></span>
<span class="normal"><a href="#__codelineno-0-75">75</a></span>
<span class="normal"><a href="#__codelineno-0-76">76</a></span>
<span class="normal"><a href="#__codelineno-0-77">77</a></span>
<span class="normal"><a href="#__codelineno-0-78">78</a></span>
<span class="normal"><a href="#__codelineno-0-79">79</a></span>
<span class="normal"><a href="#__codelineno-0-80">80</a></span>
<span class="normal"><a href="#__codelineno-0-81">81</a></span>
<span class="normal"><a href="#__codelineno-0-82">82</a></span>
<span class="normal"><a href="#__codelineno-0-83">83</a></span>
<span class="normal"><a href="#__codelineno-0-84">84</a></span>
<span class="normal"><a href="#__codelineno-0-85">85</a></span>
<span class="normal"><a href="#__codelineno-0-86">86</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="k">class</span><span class="w"> </span><span class="nc">StatefulModule</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="sd">    A wrapper that provides a stateful interface for recurrent torch modules.</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="sd">    If the torch module to be wrapped is non-recurrent and its forward method</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="sd">    has a single input (the input tensor) and a single output (the output</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">    tensor), then this wrapper module acts as a no-op wrapper.</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">    If the torch module to be wrapped is recurrent and its forward method has</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">    two inputs (the input tensor and an optional second argument for the hidden</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">    state) and two outputs (the output tensor and the new hidden state), then</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">    this wrapper brings a new forward-passing interface. In this new interface,</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">    the forward method has a single input (the input tensor) and a single</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">    output (the output tensor). The hidden states, instead of being</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="sd">    explicitly requested via a second argument and returned as a second</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">    result, are stored and used by the wrapper.</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="sd">    When a new series of inputs is to be used, one has to call the `reset()`</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="sd">    method of this wrapper.</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">wrapped_module</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">        `__init__(...)`: Initialize the StatefulModule.</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="sd">            wrapped_module: The `torch.nn.Module` instance to wrap.</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>        <span class="c1"># Declare the variable that will store the hidden state of wrapped_module, if any.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_hidden</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>        <span class="c1"># Store the module that is wrapped.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">wrapped_module</span> <span class="o">=</span> <span class="n">wrapped_module</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hidden</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>            <span class="c1"># If there is no stored hidden state, then only pass the input tensor to the wrapped module.</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wrapped_module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>            <span class="c1"># If there is a hidden state saved from the previous call to this `forward(...)` method, then pass the</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a>            <span class="c1"># input tensor and this stored hidden state.</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wrapped_module</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hidden</span><span class="p">)</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>            <span class="c1"># If the result of the wrapped module is a tuple, then we assume that the wrapped module returned an</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>            <span class="c1"># output tensor and a hidden state. We assume the first element of this tuple as the output tensor,</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>            <span class="c1"># and the second element as the new hidden state.</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>            <span class="c1"># We set the variable y to the output tensor, and we store the new hidden state via the attribute</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>            <span class="c1"># `_hidden`.</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>            <span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hidden</span> <span class="o">=</span> <span class="n">out</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>            <span class="c1"># If the result of the wrapped module is not a tuple, then we assume that the wrapped module returned</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>            <span class="c1"># only the output tensor. We set the variable y to the output tensor, and set the attribute `_hidden`</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>            <span class="c1"># as None to indicate that there was no hidden state received.</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>            <span class="n">y</span> <span class="o">=</span> <span class="n">out</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_hidden</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>        <span class="c1"># We return y, which stores the output received by the wrapped module.</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>        <span class="k">return</span> <span class="n">y</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a><span class="sd">        Reset the hidden state, if any.</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_hidden</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="evotorch.neuroevolution.net.StatefulModule.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">wrapped_module</span><span class="p">)</span></code>

<a href="#evotorch.neuroevolution.net.StatefulModule.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p><code>__init__(...)</code>: Initialize the StatefulModule.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>wrapped_module</code>
            </td>
            <td>
                  <code><span title="torch.nn.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The <code>torch.nn.Module</code> instance to wrap.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/statefulmodule.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">wrapped_module</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">    `__init__(...)`: Initialize the StatefulModule.</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="sd">        wrapped_module: The `torch.nn.Module` instance to wrap.</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>    <span class="c1"># Declare the variable that will store the hidden state of wrapped_module, if any.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_hidden</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>    <span class="c1"># Store the module that is wrapped.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">wrapped_module</span> <span class="o">=</span> <span class="n">wrapped_module</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="evotorch.neuroevolution.net.StatefulModule.reset" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">reset</span><span class="p">()</span></code>

<a href="#evotorch.neuroevolution.net.StatefulModule.reset" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Reset the hidden state, if any.</p>


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/statefulmodule.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-82">82</a></span>
<span class="normal"><a href="#__codelineno-0-83">83</a></span>
<span class="normal"><a href="#__codelineno-0-84">84</a></span>
<span class="normal"><a href="#__codelineno-0-85">85</a></span>
<span class="normal"><a href="#__codelineno-0-86">86</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-82" name="__codelineno-0-82"></a><span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a><span class="sd">    Reset the hidden state, if any.</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_hidden</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>


<div class="doc doc-object doc-function">


<h2 id="evotorch.neuroevolution.net.count_parameters" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">count_parameters</span><span class="p">(</span><span class="n">net</span><span class="p">)</span></code>

<a href="#evotorch.neuroevolution.net.count_parameters" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Get the number of parameters the network.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>net</code>
            </td>
            <td>
                  <code><span title="torch.nn.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The torch module whose parameters will be counted.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>
        


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/misc.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-73">73</a></span>
<span class="normal"><a href="#__codelineno-0-74">74</a></span>
<span class="normal"><a href="#__codelineno-0-75">75</a></span>
<span class="normal"><a href="#__codelineno-0-76">76</a></span>
<span class="normal"><a href="#__codelineno-0-77">77</a></span>
<span class="normal"><a href="#__codelineno-0-78">78</a></span>
<span class="normal"><a href="#__codelineno-0-79">79</a></span>
<span class="normal"><a href="#__codelineno-0-80">80</a></span>
<span class="normal"><a href="#__codelineno-0-81">81</a></span>
<span class="normal"><a href="#__codelineno-0-82">82</a></span>
<span class="normal"><a href="#__codelineno-0-83">83</a></span>
<span class="normal"><a href="#__codelineno-0-84">84</a></span>
<span class="normal"><a href="#__codelineno-0-85">85</a></span>
<span class="normal"><a href="#__codelineno-0-86">86</a></span>
<span class="normal"><a href="#__codelineno-0-87">87</a></span>
<span class="normal"><a href="#__codelineno-0-88">88</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-73" name="__codelineno-0-73"></a><span class="k">def</span><span class="w"> </span><span class="nf">count_parameters</span><span class="p">(</span><span class="n">net</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a><span class="sd">    Get the number of parameters the network.</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a><span class="sd">        net: The torch module whose parameters will be counted.</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a><span class="sd">        The number of parameters, as an integer.</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>        <span class="n">count</span> <span class="o">+=</span> <span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>    <span class="k">return</span> <span class="n">count</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="evotorch.neuroevolution.net.device_of_module" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">device_of_module</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#evotorch.neuroevolution.net.device_of_module" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Get the device in which the module exists.</p>
<p>This function looks at the first parameter of the module, and returns
its device. This function is not meant to be used on modules whose
parameters exist on different devices.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>m</code>
            </td>
            <td>
                  <code><span title="torch.nn.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The module whose device is being queried.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>default</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="torch.device">device</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The fallback device to return if the module has no
parameters. If this is left as None, the fallback device
is assumed to be "cpu".</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>
        


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/misc.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="k">def</span><span class="w"> </span><span class="nf">device_of_module</span><span class="p">(</span><span class="n">m</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">default</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">    Get the device in which the module exists.</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="sd">    This function looks at the first parameter of the module, and returns</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="sd">    its device. This function is not meant to be used on modules whose</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="sd">    parameters exist on different devices.</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a><span class="sd">        m: The module whose device is being queried.</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a><span class="sd">        default: The fallback device to return if the module has no</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a><span class="sd">            parameters. If this is left as None, the fallback device</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a><span class="sd">            is assumed to be &quot;cpu&quot;.</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a><span class="sd">        The device of the module, determined from its first parameter.</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>    <span class="k">if</span> <span class="n">default</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>        <span class="n">default</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>    <span class="n">device</span> <span class="o">=</span> <span class="n">default</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>        <span class="n">device</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">device</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>        <span class="k">break</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>    <span class="k">return</span> <span class="n">device</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="evotorch.neuroevolution.net.fill_parameters" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">fill_parameters</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">vector</span><span class="p">)</span></code>

<a href="#evotorch.neuroevolution.net.fill_parameters" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Fill the parameters of a torch module (net) from a vector.</p>
<p>No gradient information is kept.</p>
<p>The vector's length must be exactly the same with the number
of parameters of the PyTorch module.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>net</code>
            </td>
            <td>
                  <code><span title="torch.nn.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The torch module whose parameter values will be filled.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>vector</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A 1-D torch tensor which stores the parameter values.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/misc.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-25">25</a></span>
<span class="normal"><a href="#__codelineno-0-26">26</a></span>
<span class="normal"><a href="#__codelineno-0-27">27</a></span>
<span class="normal"><a href="#__codelineno-0-28">28</a></span>
<span class="normal"><a href="#__codelineno-0-29">29</a></span>
<span class="normal"><a href="#__codelineno-0-30">30</a></span>
<span class="normal"><a href="#__codelineno-0-31">31</a></span>
<span class="normal"><a href="#__codelineno-0-32">32</a></span>
<span class="normal"><a href="#__codelineno-0-33">33</a></span>
<span class="normal"><a href="#__codelineno-0-34">34</a></span>
<span class="normal"><a href="#__codelineno-0-35">35</a></span>
<span class="normal"><a href="#__codelineno-0-36">36</a></span>
<span class="normal"><a href="#__codelineno-0-37">37</a></span>
<span class="normal"><a href="#__codelineno-0-38">38</a></span>
<span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span>
<span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="k">def</span><span class="w"> </span><span class="nf">fill_parameters</span><span class="p">(</span><span class="n">net</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">vector</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Fill the parameters of a torch module (net) from a vector.</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">    No gradient information is kept.</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">    The vector&#39;s length must be exactly the same with the number</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">    of parameters of the PyTorch module.</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="sd">        net: The torch module whose parameter values will be filled.</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">        vector: A 1-D torch tensor which stores the parameter values.</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>    <span class="n">address</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>        <span class="n">d</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>        <span class="n">d</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">vector</span><span class="p">[</span><span class="n">address</span> <span class="p">:</span> <span class="n">address</span> <span class="o">+</span> <span class="n">n</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">d</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>        <span class="n">address</span> <span class="o">+=</span> <span class="n">n</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>    <span class="k">if</span> <span class="n">address</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vector</span><span class="p">):</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>        <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="s2">&quot;The parameter vector is larger than expected&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="evotorch.neuroevolution.net.make_functional_module" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">make_functional_module</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">disable_autograd_tracking</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#evotorch.neuroevolution.net.make_functional_module" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Wrap a torch module so that it has a functional interface.</p>
<p>Similar to <code>functorch.make_functional(...)</code>, this function turns a
<code>torch.nn.Module</code> instance to a function which expects a new leftmost
argument representing the parameters of the network.
Unlike with <code>functorch.make_functional(...)</code>, the parameters of the
network are expected in a 1-dimensional (i.e. flattened) tensor.</p>
<p>PyTorch modules with buffers can be wrapped by this class, but it is
assumed that those buffers are constant. If the wrapped module changes
the value(s) of its buffer(s) during its forward passes, most probably
things will NOT work right.</p>
<p>As an example, let us consider the following linear layer.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
</code></pre></div>
<p>The functional counterpart of <code>net</code> can be obtained via:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">evotorch.neuroevolution.net</span><span class="w"> </span><span class="kn">import</span> <span class="n">make_functional_module</span>
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="n">fnet</span> <span class="o">=</span> <span class="n">make_functional_module</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
</code></pre></div>
<p>Now, <code>fnet</code> is a callable object which expects network parameters
and network inputs. Let us call <code>fnet</code> with randomly generated network
parameters and with a randomly generated input tensor.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="n">param_length</span> <span class="o">=</span> <span class="n">fnet</span><span class="o">.</span><span class="n">parameter_length</span>
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="n">random_parameters</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">param_length</span><span class="p">)</span>
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="n">random_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>
<a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="n">result</span> <span class="o">=</span> <span class="n">fnet</span><span class="p">(</span><span class="n">random_parameters</span><span class="p">,</span> <span class="n">random_input</span><span class="p">)</span>
</code></pre></div>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>net</code>
            </td>
            <td>
                  <code><span title="torch.nn.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The <code>torch.nn.Module</code> instance to be wrapped by a functional
interface.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>disable_autograd_tracking</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If given as True, all operations
regarding the wrapped module will be performed in the context
<code>torch.no_grad()</code>, forcefully disabling the autograd.
If given as False, autograd will not be affected.
The default is False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>
        


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/functional.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span>
<span class="normal"><a href="#__codelineno-0-211">211</a></span>
<span class="normal"><a href="#__codelineno-0-212">212</a></span>
<span class="normal"><a href="#__codelineno-0-213">213</a></span>
<span class="normal"><a href="#__codelineno-0-214">214</a></span>
<span class="normal"><a href="#__codelineno-0-215">215</a></span>
<span class="normal"><a href="#__codelineno-0-216">216</a></span>
<span class="normal"><a href="#__codelineno-0-217">217</a></span>
<span class="normal"><a href="#__codelineno-0-218">218</a></span>
<span class="normal"><a href="#__codelineno-0-219">219</a></span>
<span class="normal"><a href="#__codelineno-0-220">220</a></span>
<span class="normal"><a href="#__codelineno-0-221">221</a></span>
<span class="normal"><a href="#__codelineno-0-222">222</a></span>
<span class="normal"><a href="#__codelineno-0-223">223</a></span>
<span class="normal"><a href="#__codelineno-0-224">224</a></span>
<span class="normal"><a href="#__codelineno-0-225">225</a></span>
<span class="normal"><a href="#__codelineno-0-226">226</a></span>
<span class="normal"><a href="#__codelineno-0-227">227</a></span>
<span class="normal"><a href="#__codelineno-0-228">228</a></span>
<span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span>
<span class="normal"><a href="#__codelineno-0-255">255</a></span>
<span class="normal"><a href="#__codelineno-0-256">256</a></span>
<span class="normal"><a href="#__codelineno-0-257">257</a></span>
<span class="normal"><a href="#__codelineno-0-258">258</a></span>
<span class="normal"><a href="#__codelineno-0-259">259</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-203" name="__codelineno-0-203"></a><span class="k">def</span><span class="w"> </span><span class="nf">make_functional_module</span><span class="p">(</span><span class="n">net</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">disable_autograd_tracking</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModuleExpectingFlatParameters</span><span class="p">:</span>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a><span class="sd">    Wrap a torch module so that it has a functional interface.</span>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a><span class="sd">    Similar to `functorch.make_functional(...)`, this function turns a</span>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a><span class="sd">    `torch.nn.Module` instance to a function which expects a new leftmost</span>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a><span class="sd">    argument representing the parameters of the network.</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a><span class="sd">    Unlike with `functorch.make_functional(...)`, the parameters of the</span>
<a id="__codelineno-0-211" name="__codelineno-0-211"></a><span class="sd">    network are expected in a 1-dimensional (i.e. flattened) tensor.</span>
<a id="__codelineno-0-212" name="__codelineno-0-212"></a>
<a id="__codelineno-0-213" name="__codelineno-0-213"></a><span class="sd">    PyTorch modules with buffers can be wrapped by this class, but it is</span>
<a id="__codelineno-0-214" name="__codelineno-0-214"></a><span class="sd">    assumed that those buffers are constant. If the wrapped module changes</span>
<a id="__codelineno-0-215" name="__codelineno-0-215"></a><span class="sd">    the value(s) of its buffer(s) during its forward passes, most probably</span>
<a id="__codelineno-0-216" name="__codelineno-0-216"></a><span class="sd">    things will NOT work right.</span>
<a id="__codelineno-0-217" name="__codelineno-0-217"></a>
<a id="__codelineno-0-218" name="__codelineno-0-218"></a><span class="sd">    As an example, let us consider the following linear layer.</span>
<a id="__codelineno-0-219" name="__codelineno-0-219"></a>
<a id="__codelineno-0-220" name="__codelineno-0-220"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-221" name="__codelineno-0-221"></a><span class="sd">    import torch</span>
<a id="__codelineno-0-222" name="__codelineno-0-222"></a><span class="sd">    from torch import nn</span>
<a id="__codelineno-0-223" name="__codelineno-0-223"></a>
<a id="__codelineno-0-224" name="__codelineno-0-224"></a><span class="sd">    net = nn.Linear(3, 8)</span>
<a id="__codelineno-0-225" name="__codelineno-0-225"></a><span class="sd">    ```</span>
<a id="__codelineno-0-226" name="__codelineno-0-226"></a>
<a id="__codelineno-0-227" name="__codelineno-0-227"></a><span class="sd">    The functional counterpart of `net` can be obtained via:</span>
<a id="__codelineno-0-228" name="__codelineno-0-228"></a>
<a id="__codelineno-0-229" name="__codelineno-0-229"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-230" name="__codelineno-0-230"></a><span class="sd">    from evotorch.neuroevolution.net import make_functional_module</span>
<a id="__codelineno-0-231" name="__codelineno-0-231"></a>
<a id="__codelineno-0-232" name="__codelineno-0-232"></a><span class="sd">    fnet = make_functional_module(net)</span>
<a id="__codelineno-0-233" name="__codelineno-0-233"></a><span class="sd">    ```</span>
<a id="__codelineno-0-234" name="__codelineno-0-234"></a>
<a id="__codelineno-0-235" name="__codelineno-0-235"></a><span class="sd">    Now, `fnet` is a callable object which expects network parameters</span>
<a id="__codelineno-0-236" name="__codelineno-0-236"></a><span class="sd">    and network inputs. Let us call `fnet` with randomly generated network</span>
<a id="__codelineno-0-237" name="__codelineno-0-237"></a><span class="sd">    parameters and with a randomly generated input tensor.</span>
<a id="__codelineno-0-238" name="__codelineno-0-238"></a>
<a id="__codelineno-0-239" name="__codelineno-0-239"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a><span class="sd">    param_length = fnet.parameter_length</span>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a><span class="sd">    random_parameters = torch.randn(param_length)</span>
<a id="__codelineno-0-242" name="__codelineno-0-242"></a><span class="sd">    random_input = torch.randn(3)</span>
<a id="__codelineno-0-243" name="__codelineno-0-243"></a>
<a id="__codelineno-0-244" name="__codelineno-0-244"></a><span class="sd">    result = fnet(random_parameters, random_input)</span>
<a id="__codelineno-0-245" name="__codelineno-0-245"></a><span class="sd">    ```</span>
<a id="__codelineno-0-246" name="__codelineno-0-246"></a>
<a id="__codelineno-0-247" name="__codelineno-0-247"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-248" name="__codelineno-0-248"></a><span class="sd">        net: The `torch.nn.Module` instance to be wrapped by a functional</span>
<a id="__codelineno-0-249" name="__codelineno-0-249"></a><span class="sd">            interface.</span>
<a id="__codelineno-0-250" name="__codelineno-0-250"></a><span class="sd">        disable_autograd_tracking: If given as True, all operations</span>
<a id="__codelineno-0-251" name="__codelineno-0-251"></a><span class="sd">            regarding the wrapped module will be performed in the context</span>
<a id="__codelineno-0-252" name="__codelineno-0-252"></a><span class="sd">            `torch.no_grad()`, forcefully disabling the autograd.</span>
<a id="__codelineno-0-253" name="__codelineno-0-253"></a><span class="sd">            If given as False, autograd will not be affected.</span>
<a id="__codelineno-0-254" name="__codelineno-0-254"></a><span class="sd">            The default is False.</span>
<a id="__codelineno-0-255" name="__codelineno-0-255"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-256" name="__codelineno-0-256"></a><span class="sd">        The functional wrapper, as an instance of</span>
<a id="__codelineno-0-257" name="__codelineno-0-257"></a><span class="sd">        `evotorch.neuroevolution.net.ModuleExpectingFlatParameters`.</span>
<a id="__codelineno-0-258" name="__codelineno-0-258"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-259" name="__codelineno-0-259"></a>    <span class="k">return</span> <span class="n">ModuleExpectingFlatParameters</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">disable_autograd_tracking</span><span class="o">=</span><span class="n">disable_autograd_tracking</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="evotorch.neuroevolution.net.parameter_vector" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">parameter_vector</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#evotorch.neuroevolution.net.parameter_vector" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Get all the parameters of a torch module (net) into a vector</p>
<p>No gradient information is kept.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>net</code>
            </td>
            <td>
                  <code><span title="torch.nn.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The torch module whose parameters will be extracted.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="evotorch.tools.misc.Device">Device</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The device in which the parameter vector will be constructed.
If the network has parameter across multiple devices,
you can specify this argument so that concatenation of all the
parameters will be successful.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>
        


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/misc.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span>
<span class="normal"><a href="#__codelineno-0-55">55</a></span>
<span class="normal"><a href="#__codelineno-0-56">56</a></span>
<span class="normal"><a href="#__codelineno-0-57">57</a></span>
<span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span>
<span class="normal"><a href="#__codelineno-0-66">66</a></span>
<span class="normal"><a href="#__codelineno-0-67">67</a></span>
<span class="normal"><a href="#__codelineno-0-68">68</a></span>
<span class="normal"><a href="#__codelineno-0-69">69</a></span>
<span class="normal"><a href="#__codelineno-0-70">70</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="k">def</span><span class="w"> </span><span class="nf">parameter_vector</span><span class="p">(</span><span class="n">net</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Get all the parameters of a torch module (net) into a vector</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">    No gradient information is kept.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">        net: The torch module whose parameters will be extracted.</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">        device: The device in which the parameter vector will be constructed.</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">            If the network has parameter across multiple devices,</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">            you can specify this argument so that concatenation of all the</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">            parameters will be successful.</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">        The parameters of the module in a 1-D tensor.</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>    <span class="n">dev_kwarg</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="n">device</span><span class="p">}</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>    <span class="n">all_vectors</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>        <span class="n">all_vectors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="o">**</span><span class="n">dev_kwarg</span><span class="p">))</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">all_vectors</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="evotorch.neuroevolution.net.str_to_net" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">str_to_net</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="o">**</span><span class="n">constants</span><span class="p">)</span></code>

<a href="#evotorch.neuroevolution.net.str_to_net" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Read a string representation of a neural net structure,
and return a <code>torch.nn.Module</code> instance out of it.</p>
<p>Let us imagine that one wants to describe the following
neural network structure:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">evotorch.neuroevolution.net</span><span class="w"> </span><span class="kn">import</span> <span class="n">MultiLayered</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="n">net</span> <span class="o">=</span> <span class="n">MultiLayered</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
</code></pre></div>
<p>By using <code>str_to_net(...)</code> one can construct an equivalent
module via:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">evotorch.neuroevolution.net</span><span class="w"> </span><span class="kn">import</span> <span class="n">str_to_net</span>
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="n">net</span> <span class="o">=</span> <span class="n">str_to_net</span><span class="p">(</span><span class="s2">&quot;Linear(8, 16) &gt;&gt; Tanh() &gt;&gt; Linear(16, 4, bias=False) &gt;&gt; ReLU()&quot;</span><span class="p">)</span>
</code></pre></div>
<p>The string can also be multi-line:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="n">net</span> <span class="o">=</span> <span class="n">str_to_net</span><span class="p">(</span>
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="sd">    Linear(8, 16)</span>
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="sd">    &gt;&gt; Tanh()</span>
<a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="sd">    &gt;&gt; Linear(16, 4, bias=False)</span>
<a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a><span class="sd">    &gt;&gt; ReLU()</span>
<a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a><span class="sd">    &#39;&#39;&#39;</span>
<a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a><span class="p">)</span>
</code></pre></div>
<p>One can also define constants for using them in strings:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="n">net</span> <span class="o">=</span> <span class="n">str_to_net</span><span class="p">(</span>
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a><span class="sd">    Linear(input_size, hidden_size)</span>
<a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a><span class="sd">    &gt;&gt; Tanh()</span>
<a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a><span class="sd">    &gt;&gt; Linear(hidden_size, output_size, bias=False)</span>
<a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a><span class="sd">    &gt;&gt; ReLU()</span>
<a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a><span class="sd">    &#39;&#39;&#39;</span><span class="p">,</span>
<a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a>    <span class="n">input_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
<a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a>    <span class="n">hidden_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
<a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>    <span class="n">output_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a><span class="p">)</span>
</code></pre></div>
<p>In the neural net structure string, when one refers to a module type,
say, <code>Linear</code>, first the name <code>Linear</code> is searched for in the namespace
<code>evotorch.neuroevolution.net.layers</code>, and then in the namespace <code>torch.nn</code>.
In the case of <code>Linear</code>, the searched name exists in <code>torch.nn</code>,
and therefore, the layer type to be instantiated is accepted as
<code>torch.nn.Linear</code>.
Instead of <code>Linear</code>, if one had used the name, say,
<code>StructuredControlNet</code>, then, the layer type to be instantiated
would be <code>evotorch.neuroevolution.net.layers.StructuredControlNet</code>.</p>
<p>The namespace <code>evotorch.neuroevolution.net.layers</code> contains its own
implementations for RNN and LSTM. These recurrent layer implementations
work similarly to their counterparts <code>torch.nn.RNN</code> and <code>torch.nn.LSTM</code>,
except that EvoTorch's implementations do not expect the data with extra
leftmost dimensions for batching and for timesteps. Instead, they expect
to receive a single input and a single current hidden state, and produce
a single output and a single new hidden state. These recurrent layer
implementations of EvoTorch can be used within a neural net structure
string. Therefore, the following examples are valid:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="n">rnn1</span> <span class="o">=</span> <span class="n">str_to_net</span><span class="p">(</span><span class="s2">&quot;RNN(4, 8) &gt;&gt; Linear(8, 2)&quot;</span><span class="p">)</span>
<a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>
<a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a><span class="n">rnn2</span> <span class="o">=</span> <span class="n">str_to_net</span><span class="p">(</span>
<a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a><span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a><span class="sd">    Linear(4, 10)</span>
<a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a><span class="sd">    &gt;&gt; Tanh()</span>
<a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a><span class="sd">    &gt;&gt; RNN(input_size=10, hidden_size=24, nonlinearity=&#39;tanh&#39;</span>
<a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a><span class="sd">    &gt;&gt; Linear(24, 2)</span>
<a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a><span class="sd">    &#39;&#39;&#39;</span>
<a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a><span class="p">)</span>
<a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a>
<a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a><span class="n">lstm1</span> <span class="o">=</span> <span class="n">str_to_net</span><span class="p">(</span><span class="s2">&quot;LSTM(4, 32) &gt;&gt; Linear(32, 2)&quot;</span><span class="p">)</span>
<a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a>
<a id="__codelineno-4-14" name="__codelineno-4-14" href="#__codelineno-4-14"></a><span class="n">lstm2</span> <span class="o">=</span> <span class="n">str_to_net</span><span class="p">(</span><span class="s2">&quot;LSTM(input_size=4, hidden_size=32) &gt;&gt; Linear(32, 2)&quot;</span><span class="p">)</span>
</code></pre></div>
<p><strong>Notes regarding usage with <code>evotorch.neuroevolution.GymNE</code>
or with <code>evotorch.neuroevolution.VecGymNE</code>:</strong></p>
<p>While instantiating a <code>GymNE</code> or a <code>VecGymNE</code>, one can specify a neural
net structure string as the policy. Therefore, while filling the policy
string for a <code>GymNE</code>, all these rules mentioned above apply. Additionally,
while using <code>str_to_net(...)</code> internally, <code>GymNE</code> and <code>VecGymNE</code> define
these extra constants:
<code>obs_length</code> (length of the observation vector),
<code>act_length</code> (length of the action vector for continuous-action
environments, or number of actions for discrete-action
environments), and
<code>obs_shape</code> (shape of the observation as a tuple, assuming that the
observation space is of type <code>gym.spaces.Box</code>, usable within the string
like <code>obs_shape[0]</code>, <code>obs_shape[1]</code>, etc., or simply <code>obs_shape</code> to refer
to the entire tuple).</p>
<p>Therefore, while instantiating a <code>GymNE</code> or a <code>VecGymNE</code>, one can define a
single-hidden-layered policy via this string:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>&quot;Linear(obs_length, 16) &gt;&gt; Tanh() &gt;&gt; Linear(16, act_length) &gt;&gt; Tanh()&quot;
</code></pre></div>
<p>In the policy string above, one might choose to omit the last <code>Tanh()</code>, as
<code>GymNE</code> and <code>VecGymNE</code> will clip the final output of the policy to conform
to the action boundaries defined by the target reinforcement learning
environment, and such a clipping operation might be seen as using an
activation function similar to hard-tanh anyway.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>s</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The string which expresses the neural net structure.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>
        


            <details class="quote">
              <summary>Source code in <code>evotorch/neuroevolution/net/parser.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-218">218</a></span>
<span class="normal"><a href="#__codelineno-0-219">219</a></span>
<span class="normal"><a href="#__codelineno-0-220">220</a></span>
<span class="normal"><a href="#__codelineno-0-221">221</a></span>
<span class="normal"><a href="#__codelineno-0-222">222</a></span>
<span class="normal"><a href="#__codelineno-0-223">223</a></span>
<span class="normal"><a href="#__codelineno-0-224">224</a></span>
<span class="normal"><a href="#__codelineno-0-225">225</a></span>
<span class="normal"><a href="#__codelineno-0-226">226</a></span>
<span class="normal"><a href="#__codelineno-0-227">227</a></span>
<span class="normal"><a href="#__codelineno-0-228">228</a></span>
<span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span>
<span class="normal"><a href="#__codelineno-0-255">255</a></span>
<span class="normal"><a href="#__codelineno-0-256">256</a></span>
<span class="normal"><a href="#__codelineno-0-257">257</a></span>
<span class="normal"><a href="#__codelineno-0-258">258</a></span>
<span class="normal"><a href="#__codelineno-0-259">259</a></span>
<span class="normal"><a href="#__codelineno-0-260">260</a></span>
<span class="normal"><a href="#__codelineno-0-261">261</a></span>
<span class="normal"><a href="#__codelineno-0-262">262</a></span>
<span class="normal"><a href="#__codelineno-0-263">263</a></span>
<span class="normal"><a href="#__codelineno-0-264">264</a></span>
<span class="normal"><a href="#__codelineno-0-265">265</a></span>
<span class="normal"><a href="#__codelineno-0-266">266</a></span>
<span class="normal"><a href="#__codelineno-0-267">267</a></span>
<span class="normal"><a href="#__codelineno-0-268">268</a></span>
<span class="normal"><a href="#__codelineno-0-269">269</a></span>
<span class="normal"><a href="#__codelineno-0-270">270</a></span>
<span class="normal"><a href="#__codelineno-0-271">271</a></span>
<span class="normal"><a href="#__codelineno-0-272">272</a></span>
<span class="normal"><a href="#__codelineno-0-273">273</a></span>
<span class="normal"><a href="#__codelineno-0-274">274</a></span>
<span class="normal"><a href="#__codelineno-0-275">275</a></span>
<span class="normal"><a href="#__codelineno-0-276">276</a></span>
<span class="normal"><a href="#__codelineno-0-277">277</a></span>
<span class="normal"><a href="#__codelineno-0-278">278</a></span>
<span class="normal"><a href="#__codelineno-0-279">279</a></span>
<span class="normal"><a href="#__codelineno-0-280">280</a></span>
<span class="normal"><a href="#__codelineno-0-281">281</a></span>
<span class="normal"><a href="#__codelineno-0-282">282</a></span>
<span class="normal"><a href="#__codelineno-0-283">283</a></span>
<span class="normal"><a href="#__codelineno-0-284">284</a></span>
<span class="normal"><a href="#__codelineno-0-285">285</a></span>
<span class="normal"><a href="#__codelineno-0-286">286</a></span>
<span class="normal"><a href="#__codelineno-0-287">287</a></span>
<span class="normal"><a href="#__codelineno-0-288">288</a></span>
<span class="normal"><a href="#__codelineno-0-289">289</a></span>
<span class="normal"><a href="#__codelineno-0-290">290</a></span>
<span class="normal"><a href="#__codelineno-0-291">291</a></span>
<span class="normal"><a href="#__codelineno-0-292">292</a></span>
<span class="normal"><a href="#__codelineno-0-293">293</a></span>
<span class="normal"><a href="#__codelineno-0-294">294</a></span>
<span class="normal"><a href="#__codelineno-0-295">295</a></span>
<span class="normal"><a href="#__codelineno-0-296">296</a></span>
<span class="normal"><a href="#__codelineno-0-297">297</a></span>
<span class="normal"><a href="#__codelineno-0-298">298</a></span>
<span class="normal"><a href="#__codelineno-0-299">299</a></span>
<span class="normal"><a href="#__codelineno-0-300">300</a></span>
<span class="normal"><a href="#__codelineno-0-301">301</a></span>
<span class="normal"><a href="#__codelineno-0-302">302</a></span>
<span class="normal"><a href="#__codelineno-0-303">303</a></span>
<span class="normal"><a href="#__codelineno-0-304">304</a></span>
<span class="normal"><a href="#__codelineno-0-305">305</a></span>
<span class="normal"><a href="#__codelineno-0-306">306</a></span>
<span class="normal"><a href="#__codelineno-0-307">307</a></span>
<span class="normal"><a href="#__codelineno-0-308">308</a></span>
<span class="normal"><a href="#__codelineno-0-309">309</a></span>
<span class="normal"><a href="#__codelineno-0-310">310</a></span>
<span class="normal"><a href="#__codelineno-0-311">311</a></span>
<span class="normal"><a href="#__codelineno-0-312">312</a></span>
<span class="normal"><a href="#__codelineno-0-313">313</a></span>
<span class="normal"><a href="#__codelineno-0-314">314</a></span>
<span class="normal"><a href="#__codelineno-0-315">315</a></span>
<span class="normal"><a href="#__codelineno-0-316">316</a></span>
<span class="normal"><a href="#__codelineno-0-317">317</a></span>
<span class="normal"><a href="#__codelineno-0-318">318</a></span>
<span class="normal"><a href="#__codelineno-0-319">319</a></span>
<span class="normal"><a href="#__codelineno-0-320">320</a></span>
<span class="normal"><a href="#__codelineno-0-321">321</a></span>
<span class="normal"><a href="#__codelineno-0-322">322</a></span>
<span class="normal"><a href="#__codelineno-0-323">323</a></span>
<span class="normal"><a href="#__codelineno-0-324">324</a></span>
<span class="normal"><a href="#__codelineno-0-325">325</a></span>
<span class="normal"><a href="#__codelineno-0-326">326</a></span>
<span class="normal"><a href="#__codelineno-0-327">327</a></span>
<span class="normal"><a href="#__codelineno-0-328">328</a></span>
<span class="normal"><a href="#__codelineno-0-329">329</a></span>
<span class="normal"><a href="#__codelineno-0-330">330</a></span>
<span class="normal"><a href="#__codelineno-0-331">331</a></span>
<span class="normal"><a href="#__codelineno-0-332">332</a></span>
<span class="normal"><a href="#__codelineno-0-333">333</a></span>
<span class="normal"><a href="#__codelineno-0-334">334</a></span>
<span class="normal"><a href="#__codelineno-0-335">335</a></span>
<span class="normal"><a href="#__codelineno-0-336">336</a></span>
<span class="normal"><a href="#__codelineno-0-337">337</a></span>
<span class="normal"><a href="#__codelineno-0-338">338</a></span>
<span class="normal"><a href="#__codelineno-0-339">339</a></span>
<span class="normal"><a href="#__codelineno-0-340">340</a></span>
<span class="normal"><a href="#__codelineno-0-341">341</a></span>
<span class="normal"><a href="#__codelineno-0-342">342</a></span>
<span class="normal"><a href="#__codelineno-0-343">343</a></span>
<span class="normal"><a href="#__codelineno-0-344">344</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-218" name="__codelineno-0-218"></a><span class="k">def</span><span class="w"> </span><span class="nf">str_to_net</span><span class="p">(</span><span class="n">s</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">constants</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
<a id="__codelineno-0-219" name="__codelineno-0-219"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-220" name="__codelineno-0-220"></a><span class="sd">    Read a string representation of a neural net structure,</span>
<a id="__codelineno-0-221" name="__codelineno-0-221"></a><span class="sd">    and return a `torch.nn.Module` instance out of it.</span>
<a id="__codelineno-0-222" name="__codelineno-0-222"></a>
<a id="__codelineno-0-223" name="__codelineno-0-223"></a><span class="sd">    Let us imagine that one wants to describe the following</span>
<a id="__codelineno-0-224" name="__codelineno-0-224"></a><span class="sd">    neural network structure:</span>
<a id="__codelineno-0-225" name="__codelineno-0-225"></a>
<a id="__codelineno-0-226" name="__codelineno-0-226"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-227" name="__codelineno-0-227"></a><span class="sd">    from torch import nn</span>
<a id="__codelineno-0-228" name="__codelineno-0-228"></a><span class="sd">    from evotorch.neuroevolution.net import MultiLayered</span>
<a id="__codelineno-0-229" name="__codelineno-0-229"></a>
<a id="__codelineno-0-230" name="__codelineno-0-230"></a><span class="sd">    net = MultiLayered(nn.Linear(8, 16), nn.Tanh(), nn.Linear(16, 4, bias=False), nn.ReLU())</span>
<a id="__codelineno-0-231" name="__codelineno-0-231"></a><span class="sd">    ```</span>
<a id="__codelineno-0-232" name="__codelineno-0-232"></a>
<a id="__codelineno-0-233" name="__codelineno-0-233"></a><span class="sd">    By using `str_to_net(...)` one can construct an equivalent</span>
<a id="__codelineno-0-234" name="__codelineno-0-234"></a><span class="sd">    module via:</span>
<a id="__codelineno-0-235" name="__codelineno-0-235"></a>
<a id="__codelineno-0-236" name="__codelineno-0-236"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-237" name="__codelineno-0-237"></a><span class="sd">    from evotorch.neuroevolution.net import str_to_net</span>
<a id="__codelineno-0-238" name="__codelineno-0-238"></a>
<a id="__codelineno-0-239" name="__codelineno-0-239"></a><span class="sd">    net = str_to_net(&quot;Linear(8, 16) &gt;&gt; Tanh() &gt;&gt; Linear(16, 4, bias=False) &gt;&gt; ReLU()&quot;)</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a><span class="sd">    ```</span>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a>
<a id="__codelineno-0-242" name="__codelineno-0-242"></a><span class="sd">    The string can also be multi-line:</span>
<a id="__codelineno-0-243" name="__codelineno-0-243"></a>
<a id="__codelineno-0-244" name="__codelineno-0-244"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-245" name="__codelineno-0-245"></a><span class="sd">    net = str_to_net(</span>
<a id="__codelineno-0-246" name="__codelineno-0-246"></a><span class="sd">        &#39;&#39;&#39;</span>
<a id="__codelineno-0-247" name="__codelineno-0-247"></a><span class="sd">        Linear(8, 16)</span>
<a id="__codelineno-0-248" name="__codelineno-0-248"></a><span class="sd">        &gt;&gt; Tanh()</span>
<a id="__codelineno-0-249" name="__codelineno-0-249"></a><span class="sd">        &gt;&gt; Linear(16, 4, bias=False)</span>
<a id="__codelineno-0-250" name="__codelineno-0-250"></a><span class="sd">        &gt;&gt; ReLU()</span>
<a id="__codelineno-0-251" name="__codelineno-0-251"></a><span class="sd">        &#39;&#39;&#39;</span>
<a id="__codelineno-0-252" name="__codelineno-0-252"></a><span class="sd">    )</span>
<a id="__codelineno-0-253" name="__codelineno-0-253"></a><span class="sd">    ```</span>
<a id="__codelineno-0-254" name="__codelineno-0-254"></a>
<a id="__codelineno-0-255" name="__codelineno-0-255"></a><span class="sd">    One can also define constants for using them in strings:</span>
<a id="__codelineno-0-256" name="__codelineno-0-256"></a>
<a id="__codelineno-0-257" name="__codelineno-0-257"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-258" name="__codelineno-0-258"></a><span class="sd">    net = str_to_net(</span>
<a id="__codelineno-0-259" name="__codelineno-0-259"></a><span class="sd">        &#39;&#39;&#39;</span>
<a id="__codelineno-0-260" name="__codelineno-0-260"></a><span class="sd">        Linear(input_size, hidden_size)</span>
<a id="__codelineno-0-261" name="__codelineno-0-261"></a><span class="sd">        &gt;&gt; Tanh()</span>
<a id="__codelineno-0-262" name="__codelineno-0-262"></a><span class="sd">        &gt;&gt; Linear(hidden_size, output_size, bias=False)</span>
<a id="__codelineno-0-263" name="__codelineno-0-263"></a><span class="sd">        &gt;&gt; ReLU()</span>
<a id="__codelineno-0-264" name="__codelineno-0-264"></a><span class="sd">        &#39;&#39;&#39;,</span>
<a id="__codelineno-0-265" name="__codelineno-0-265"></a><span class="sd">        input_size=8,</span>
<a id="__codelineno-0-266" name="__codelineno-0-266"></a><span class="sd">        hidden_size=16,</span>
<a id="__codelineno-0-267" name="__codelineno-0-267"></a><span class="sd">        output_size=4,</span>
<a id="__codelineno-0-268" name="__codelineno-0-268"></a><span class="sd">    )</span>
<a id="__codelineno-0-269" name="__codelineno-0-269"></a><span class="sd">    ```</span>
<a id="__codelineno-0-270" name="__codelineno-0-270"></a>
<a id="__codelineno-0-271" name="__codelineno-0-271"></a><span class="sd">    In the neural net structure string, when one refers to a module type,</span>
<a id="__codelineno-0-272" name="__codelineno-0-272"></a><span class="sd">    say, `Linear`, first the name `Linear` is searched for in the namespace</span>
<a id="__codelineno-0-273" name="__codelineno-0-273"></a><span class="sd">    `evotorch.neuroevolution.net.layers`, and then in the namespace `torch.nn`.</span>
<a id="__codelineno-0-274" name="__codelineno-0-274"></a><span class="sd">    In the case of `Linear`, the searched name exists in `torch.nn`,</span>
<a id="__codelineno-0-275" name="__codelineno-0-275"></a><span class="sd">    and therefore, the layer type to be instantiated is accepted as</span>
<a id="__codelineno-0-276" name="__codelineno-0-276"></a><span class="sd">    `torch.nn.Linear`.</span>
<a id="__codelineno-0-277" name="__codelineno-0-277"></a><span class="sd">    Instead of `Linear`, if one had used the name, say,</span>
<a id="__codelineno-0-278" name="__codelineno-0-278"></a><span class="sd">    `StructuredControlNet`, then, the layer type to be instantiated</span>
<a id="__codelineno-0-279" name="__codelineno-0-279"></a><span class="sd">    would be `evotorch.neuroevolution.net.layers.StructuredControlNet`.</span>
<a id="__codelineno-0-280" name="__codelineno-0-280"></a>
<a id="__codelineno-0-281" name="__codelineno-0-281"></a><span class="sd">    The namespace `evotorch.neuroevolution.net.layers` contains its own</span>
<a id="__codelineno-0-282" name="__codelineno-0-282"></a><span class="sd">    implementations for RNN and LSTM. These recurrent layer implementations</span>
<a id="__codelineno-0-283" name="__codelineno-0-283"></a><span class="sd">    work similarly to their counterparts `torch.nn.RNN` and `torch.nn.LSTM`,</span>
<a id="__codelineno-0-284" name="__codelineno-0-284"></a><span class="sd">    except that EvoTorch&#39;s implementations do not expect the data with extra</span>
<a id="__codelineno-0-285" name="__codelineno-0-285"></a><span class="sd">    leftmost dimensions for batching and for timesteps. Instead, they expect</span>
<a id="__codelineno-0-286" name="__codelineno-0-286"></a><span class="sd">    to receive a single input and a single current hidden state, and produce</span>
<a id="__codelineno-0-287" name="__codelineno-0-287"></a><span class="sd">    a single output and a single new hidden state. These recurrent layer</span>
<a id="__codelineno-0-288" name="__codelineno-0-288"></a><span class="sd">    implementations of EvoTorch can be used within a neural net structure</span>
<a id="__codelineno-0-289" name="__codelineno-0-289"></a><span class="sd">    string. Therefore, the following examples are valid:</span>
<a id="__codelineno-0-290" name="__codelineno-0-290"></a>
<a id="__codelineno-0-291" name="__codelineno-0-291"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-292" name="__codelineno-0-292"></a><span class="sd">    rnn1 = str_to_net(&quot;RNN(4, 8) &gt;&gt; Linear(8, 2)&quot;)</span>
<a id="__codelineno-0-293" name="__codelineno-0-293"></a>
<a id="__codelineno-0-294" name="__codelineno-0-294"></a><span class="sd">    rnn2 = str_to_net(</span>
<a id="__codelineno-0-295" name="__codelineno-0-295"></a><span class="sd">        &#39;&#39;&#39;</span>
<a id="__codelineno-0-296" name="__codelineno-0-296"></a><span class="sd">        Linear(4, 10)</span>
<a id="__codelineno-0-297" name="__codelineno-0-297"></a><span class="sd">        &gt;&gt; Tanh()</span>
<a id="__codelineno-0-298" name="__codelineno-0-298"></a><span class="sd">        &gt;&gt; RNN(input_size=10, hidden_size=24, nonlinearity=&#39;tanh&#39;</span>
<a id="__codelineno-0-299" name="__codelineno-0-299"></a><span class="sd">        &gt;&gt; Linear(24, 2)</span>
<a id="__codelineno-0-300" name="__codelineno-0-300"></a><span class="sd">        &#39;&#39;&#39;</span>
<a id="__codelineno-0-301" name="__codelineno-0-301"></a><span class="sd">    )</span>
<a id="__codelineno-0-302" name="__codelineno-0-302"></a>
<a id="__codelineno-0-303" name="__codelineno-0-303"></a><span class="sd">    lstm1 = str_to_net(&quot;LSTM(4, 32) &gt;&gt; Linear(32, 2)&quot;)</span>
<a id="__codelineno-0-304" name="__codelineno-0-304"></a>
<a id="__codelineno-0-305" name="__codelineno-0-305"></a><span class="sd">    lstm2 = str_to_net(&quot;LSTM(input_size=4, hidden_size=32) &gt;&gt; Linear(32, 2)&quot;)</span>
<a id="__codelineno-0-306" name="__codelineno-0-306"></a><span class="sd">    ```</span>
<a id="__codelineno-0-307" name="__codelineno-0-307"></a>
<a id="__codelineno-0-308" name="__codelineno-0-308"></a><span class="sd">    **Notes regarding usage with `evotorch.neuroevolution.GymNE`</span>
<a id="__codelineno-0-309" name="__codelineno-0-309"></a><span class="sd">    or with `evotorch.neuroevolution.VecGymNE`:**</span>
<a id="__codelineno-0-310" name="__codelineno-0-310"></a>
<a id="__codelineno-0-311" name="__codelineno-0-311"></a><span class="sd">    While instantiating a `GymNE` or a `VecGymNE`, one can specify a neural</span>
<a id="__codelineno-0-312" name="__codelineno-0-312"></a><span class="sd">    net structure string as the policy. Therefore, while filling the policy</span>
<a id="__codelineno-0-313" name="__codelineno-0-313"></a><span class="sd">    string for a `GymNE`, all these rules mentioned above apply. Additionally,</span>
<a id="__codelineno-0-314" name="__codelineno-0-314"></a><span class="sd">    while using `str_to_net(...)` internally, `GymNE` and `VecGymNE` define</span>
<a id="__codelineno-0-315" name="__codelineno-0-315"></a><span class="sd">    these extra constants:</span>
<a id="__codelineno-0-316" name="__codelineno-0-316"></a><span class="sd">    `obs_length` (length of the observation vector),</span>
<a id="__codelineno-0-317" name="__codelineno-0-317"></a><span class="sd">    `act_length` (length of the action vector for continuous-action</span>
<a id="__codelineno-0-318" name="__codelineno-0-318"></a><span class="sd">    environments, or number of actions for discrete-action</span>
<a id="__codelineno-0-319" name="__codelineno-0-319"></a><span class="sd">    environments), and</span>
<a id="__codelineno-0-320" name="__codelineno-0-320"></a><span class="sd">    `obs_shape` (shape of the observation as a tuple, assuming that the</span>
<a id="__codelineno-0-321" name="__codelineno-0-321"></a><span class="sd">    observation space is of type `gym.spaces.Box`, usable within the string</span>
<a id="__codelineno-0-322" name="__codelineno-0-322"></a><span class="sd">    like `obs_shape[0]`, `obs_shape[1]`, etc., or simply `obs_shape` to refer</span>
<a id="__codelineno-0-323" name="__codelineno-0-323"></a><span class="sd">    to the entire tuple).</span>
<a id="__codelineno-0-324" name="__codelineno-0-324"></a>
<a id="__codelineno-0-325" name="__codelineno-0-325"></a><span class="sd">    Therefore, while instantiating a `GymNE` or a `VecGymNE`, one can define a</span>
<a id="__codelineno-0-326" name="__codelineno-0-326"></a><span class="sd">    single-hidden-layered policy via this string:</span>
<a id="__codelineno-0-327" name="__codelineno-0-327"></a>
<a id="__codelineno-0-328" name="__codelineno-0-328"></a><span class="sd">    ```</span>
<a id="__codelineno-0-329" name="__codelineno-0-329"></a><span class="sd">    &quot;Linear(obs_length, 16) &gt;&gt; Tanh() &gt;&gt; Linear(16, act_length) &gt;&gt; Tanh()&quot;</span>
<a id="__codelineno-0-330" name="__codelineno-0-330"></a><span class="sd">    ```</span>
<a id="__codelineno-0-331" name="__codelineno-0-331"></a>
<a id="__codelineno-0-332" name="__codelineno-0-332"></a><span class="sd">    In the policy string above, one might choose to omit the last `Tanh()`, as</span>
<a id="__codelineno-0-333" name="__codelineno-0-333"></a><span class="sd">    `GymNE` and `VecGymNE` will clip the final output of the policy to conform</span>
<a id="__codelineno-0-334" name="__codelineno-0-334"></a><span class="sd">    to the action boundaries defined by the target reinforcement learning</span>
<a id="__codelineno-0-335" name="__codelineno-0-335"></a><span class="sd">    environment, and such a clipping operation might be seen as using an</span>
<a id="__codelineno-0-336" name="__codelineno-0-336"></a><span class="sd">    activation function similar to hard-tanh anyway.</span>
<a id="__codelineno-0-337" name="__codelineno-0-337"></a>
<a id="__codelineno-0-338" name="__codelineno-0-338"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-339" name="__codelineno-0-339"></a><span class="sd">        s: The string which expresses the neural net structure.</span>
<a id="__codelineno-0-340" name="__codelineno-0-340"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-341" name="__codelineno-0-341"></a><span class="sd">        The PyTorch module of the specified structure.</span>
<a id="__codelineno-0-342" name="__codelineno-0-342"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-343" name="__codelineno-0-343"></a>    <span class="n">s</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;(</span><span class="se">\n</span><span class="si">{</span><span class="n">s</span><span class="si">}</span><span class="se">\n</span><span class="s2">)&quot;</span>
<a id="__codelineno-0-344" name="__codelineno-0-344"></a>    <span class="k">return</span> <span class="n">_process_expr</span><span class="p">(</span><span class="n">ast</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;eval&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">body</span><span class="p">,</span> <span class="n">constants</span><span class="o">=</span><span class="n">constants</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2022 NNAISENSE SA
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../../..", "features": ["content.code.annotate", "navigation.indexes", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest"], "search": "../../../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
        <script src="../../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>